{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T06:36:10.887136Z",
     "start_time": "2024-10-18T06:36:10.875065Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from transformers import logging as transformers_logging\n",
    "from tabulate import tabulate\n",
    "transformers_logging.set_verbosity_error()\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:36:10.918343Z",
     "start_time": "2024-10-18T06:36:10.907132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_to_keep = [\"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"with\", \"how\", \"before\", \"after\",\"same\"]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])"
   ],
   "id": "a2ac0c91ab7407d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:36:11.735619Z",
     "start_time": "2024-10-18T06:36:10.973960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NERParser:\n",
    "    def __init__(self, model_name: str = \"dslim/bert-base-NER\", lowercase: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the NER parser with a model and optionally configure the lowercase preprocessing.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "        \n",
    "        # Load the tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, do_lower_case=self.lowercase)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set up the NER pipeline\n",
    "        self.nlp_pipeline = pipeline(\n",
    "            \"ner\", \n",
    "            model=self.model, \n",
    "            tokenizer=self.tokenizer, \n",
    "            device=self.device, \n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "\n",
    "    def get_device(self):\n",
    "        \"\"\"\n",
    "        Determines whether to use MPS, CUDA, or CPU depending on the available hardware.\n",
    "        \"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"MPS device found, using MPS backend.\\n\")\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            print(f\"CUDA device found, using CUDA backend. Device: {torch.cuda.get_device_name(0)}\\n\")\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            print(\"Neither MPS nor CUDA found, using CPU.\\n\")\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    \n",
    "    def parse_ner_results(self, ner_results: list):\n",
    "        \"\"\"\n",
    "        Parse the NER results and extract entities related to 'PER' (persons) and 'MISC' (potential movie titles).\n",
    "        \"\"\"\n",
    "        per_entities, misc_entities = [], []\n",
    "        \n",
    "        for entity in ner_results:\n",
    "            # Extraction of all Persons\n",
    "            if entity['entity_group'] == 'PER':\n",
    "                per_entities.append(entity['word'])\n",
    "            # Extraction of all Misc that could indicate movies\n",
    "            elif entity['entity_group'] == 'MISC':\n",
    "                misc_entities.append(entity['word'])\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    \n",
    "    def process_query(self, query: str):\n",
    "        \"\"\"\n",
    "        Processes a text query, runs NER, and returns the extracted actors and movie names.\n",
    "        \"\"\"\n",
    "        # Optionally lowercase the input if configured\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        \n",
    "        # Run the NER pipeline\n",
    "        ner_results = self.nlp_pipeline(query)\n",
    "\n",
    "        # Parse the results to extract actors and movies\n",
    "        per_entities, misc_entities = self.parse_ner_results(ner_results)\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "ner_parser = NERParser(lowercase=False)"
   ],
   "id": "d49cf7e85debd577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither MPS nor CUDA found, using CPU.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:04.461084Z",
     "start_time": "2024-10-18T06:45:04.443916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataBase:\n",
    "    \"\"\"Handles the extraction of context data for given people and movies from a database, with fuzzy matching for names.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.db = pd.read_pickle(os.path.join(os.getcwd(), r\"exports/extended_graph_triples.pkl\"))\n",
    "        self.reverse_index = pd.read_pickle(os.path.join(os.getcwd(), r\"exports/reverse_index.pkl\"))\n",
    "        self.reverse_index['normalized_subject_label'] = self.reverse_index['subject_label'].apply(self.normalize_string)\n",
    "        \n",
    "        with open(r\"exports/entity_db.json\", encoding=\"utf-8\") as f: \n",
    "            self.entities = json.load(f)\n",
    "            self.entity_list = list(subject.lower() for subject, types in self.entities.values())\n",
    "        \n",
    "        # otherwise exact matching will fail\n",
    "        self.db['subject_id'] = self.db['subject_id'].astype(str).str.strip()\n",
    "\n",
    "\n",
    "    def normalize_string(self, s):\n",
    "        \"\"\"Cleans the input entity to a uniform naming convention, by removing non ascii characters, encoding it to utf, setting it to lowercase, and removing redundant spaces\"\"\"\n",
    "        s = s.lower()\n",
    "        s = unicodedata.normalize('NFKD', s)\n",
    "        s = s.encode('ascii', 'ignore').decode('utf-8')\n",
    "        s = re.sub(r'[^\\w\\s]', '', s)\n",
    "        s = ' '.join(s.split())\n",
    "        return s\n",
    "\n",
    "\n",
    "    def get_context(self, people: list, movies: list):\n",
    "        \"\"\"Fetch context data for the given people and movies from the database.\n",
    "        First tries matching with the entire people or movie string. If that fails,\n",
    "        it processes each person or movie individually.\n",
    "\n",
    "        Args:\n",
    "            people (list): List of people names to search.\n",
    "            movies (list): List of movie titles to search.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing context for the given people and movies.\n",
    "        \"\"\"\n",
    "        combined_people = \" \".join(people) if people else \"\"\n",
    "        combined_movies = \" \".join(movies) if movies else \"\"\n",
    "        \n",
    "        context_person = pd.DataFrame()\n",
    "        context_movie = pd.DataFrame()\n",
    "\n",
    "        if combined_people:\n",
    "            context_person = self._fetch_relevant(combined_people)\n",
    "        \n",
    "        if combined_movies:\n",
    "            context_movie = self._fetch_relevant(combined_movies)\n",
    "        \n",
    "        if context_person.empty and people:\n",
    "            person_results = [self._fetch_relevant(p) for p in people]\n",
    "            if any(not res.empty for res in person_results):\n",
    "                context_person = pd.concat(person_results, axis=1)\n",
    "\n",
    "        if context_movie.empty and movies:\n",
    "            movie_results = [self._fetch_relevant(m) for m in movies]\n",
    "            if any(not res.empty for res in movie_results):\n",
    "                context_movie = pd.concat(movie_results, axis=1)\n",
    "\n",
    "        if not context_person.empty and not context_movie.empty:\n",
    "            return pd.concat([context_person, context_movie], axis=1)\n",
    "        \n",
    "        elif not context_person.empty:\n",
    "            return context_person\n",
    "        \n",
    "        elif not context_movie.empty:\n",
    "            return context_movie\n",
    "        \n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "    def fetch_by_id_lst(self, subject_ids: list):\n",
    "        relevant = self.db[self.db.subject_id.isin(subject_ids)].dropna(axis=1)\n",
    "        \n",
    "        if relevant.empty:\n",
    "            print(f\"No context data found for any in '{subject_ids}'.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        pivot_df = relevant.pivot_table(\n",
    "            index='subject_id',\n",
    "            columns='predicate_label',\n",
    "            values='object_label',\n",
    "            aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "        )\n",
    "    \n",
    "        pivot_df.reset_index(inplace=True)\n",
    "    \n",
    "        return pivot_df\n",
    "\n",
    "    def _fetch_relevant(self, name: str):\n",
    "        \"\"\"Fetch relevant information for a given name (either combined or individual) from the database.\n",
    "        Uses fuzzy matching if no exact match is found.\n",
    "\n",
    "        Args:\n",
    "            name (str): The name of the person or movie to search for.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Relevant data for the name, or an empty DataFrame if no match is found.\n",
    "        \"\"\"\n",
    "        \n",
    "        name = self.normalize_string(name)\n",
    "        \n",
    "        start = time.time_ns()\n",
    "        matches = process.extractOne(name, self.reverse_index.normalized_subject_label, scorer=fuzz.ratio)\n",
    "        print(f\"Time taken for fuzzy matching: {(time.time_ns() - start) / 1e6} ms\")\n",
    "        \n",
    "        if not matches or not matches[1] > 90:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        match_label = matches[0]\n",
    "        print(f\"Matched '{name}' to '{match_label}' with a score of {matches[1]}.\")\n",
    "        \n",
    "        start = time.time_ns()\n",
    "        lst_of_ids = self.reverse_index.get(self.reverse_index.normalized_subject_label == match_label, []).subject_id.to_list()\n",
    "        print(f\"Time taken for reverse index lookup: {(time.time_ns() - start) / 1e6} ms\")\n",
    "        \n",
    "        if len(lst_of_ids) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        start = time.time_ns()\n",
    "        relevant = self.db[self.db.subject_id.isin(lst_of_ids)].dropna(axis=1)\n",
    "        print(f\"Time taken for fetching data: {(time.time_ns() - start) / 1e6} ms\")\n",
    "\n",
    "        if relevant.empty:\n",
    "            print(f\"No context data found for '{match_label}'. Performing partial match search.\")\n",
    "            start = time.time_ns()\n",
    "            relevant = self.db[self.db.subject_label.str.lower().str.startswith(name.lower())].dropna(axis=1)\n",
    "            print(f\"Time taken for partial match search: {(time.time_ns() - start) / 1e6} ms\")\n",
    "            \n",
    "        if relevant.empty:\n",
    "            print(f\"No context data found for '{match_label}', even with partial match search.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        start = time.time_ns()\n",
    "        pivot_df = relevant.pivot_table(\n",
    "            index='subject_id',\n",
    "            columns='predicate_label',\n",
    "            values='object_label',\n",
    "            aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "        )\n",
    "    \n",
    "        pivot_df.reset_index(inplace=True)\n",
    "        print(f\"Time taken for pivot table creation: {(time.time_ns() - start) / 1e6} ms\")\n",
    "    \n",
    "        return pivot_df"
   ],
   "id": "d17e5503d50ffd8c",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:05.217178Z",
     "start_time": "2024-10-18T06:45:05.209730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QueryEmbedder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._glove_embeddings = self._load_glove_embeddings(\"exports/glove.6B/glove.6B.300d.txt\")\n",
    "        \n",
    "    def _load_glove_embeddings(self, file_path):\n",
    "        embeddings = {}\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings[word] = vector\n",
    "        return embeddings\n",
    "    \n",
    "    def embed_phrase(self, phrase):\n",
    "        words = phrase.split()\n",
    "        word_vectors = [self._glove_embeddings[word.lower()] for word in words if word.lower() in self._glove_embeddings]\n",
    "        \n",
    "        if len(word_vectors) == 0:\n",
    "            return np.zeros(300)\n",
    "        \n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    "
   ],
   "id": "ad421631fb9f85b0",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:05.581585Z",
     "start_time": "2024-10-18T06:45:05.573950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LLM():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", top_k=1)\n",
    "    \n",
    "    def _query(self, query, context_df):\n",
    "        \n",
    "        context = \"\"\n",
    "        for index, row in context_df.iterrows():\n",
    "            row_context = \" \".join([f\"{col}: {row[col]}\" for col in context_df[top_columns].columns])\n",
    "            context += row_context + \" \"\n",
    "        \n",
    "        output = self.qa_model(question=query, context=context)\n",
    "        \n",
    "        answer_str = str()\n",
    "        if isinstance(output, list):\n",
    "            answer_str = \", \".join([result['answer'] for result in output])\n",
    "            \n",
    "        elif isinstance(output, dict):\n",
    "            answer_str = output['answer']\n",
    "        \n",
    "        if not answer_str:\n",
    "            answer_str = \"No answer found.\"\n",
    "        \n",
    "        return answer_str"
   ],
   "id": "e0ce5b9bfb93651f",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:06.045325Z",
     "start_time": "2024-10-18T06:45:06.037593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_query(query, person, movies):\n",
    "        \n",
    "    person_list = [word.lower() for p in person for word in p.split(\" \")] if len(person) else []\n",
    "    movie_list = [word.lower() for m in movies for word in m.split(\" \")] if len(movies) else []\n",
    "        \n",
    "    if not len(query):\n",
    "        return []\n",
    "    \n",
    "    relevant = []\n",
    "    for word in query.replace(\". \", \" \").lower().split(\" \"):\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in person_list or cleaned_word in movie_list or cleaned_word == \"\":\n",
    "            continue\n",
    "        \n",
    "        relevant.append(cleaned_word)\n",
    "        \n",
    "    return relevant"
   ],
   "id": "2651cd7b962598c9",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:06.409546Z",
     "start_time": "2024-10-18T06:45:06.399582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 \n",
    "    \n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, top_n=5):\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    return [col for col, sim in sorted_columns[:top_n]]"
   ],
   "id": "93858e6040c9c835",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:40.306787Z",
     "start_time": "2024-10-18T06:45:07.152199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DataBase()\n",
    "\n",
    "qe = QueryEmbedder()\n",
    "\n",
    "llm = LLM()"
   ],
   "id": "71ebcb4ff84a1fe4",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:44.969390Z",
     "start_time": "2024-10-18T06:45:42.853123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# query = \"Who directed The Bridge on the River Kwai?\"\n",
    "query = \"Who is the director of Good Will Hunting?\"\n",
    "\n",
    "normalized_query = query.lower()\n",
    "\n",
    "matches = process.extract(normalized_query, db.entity_list, scorer=fuzz.partial_ratio, limit=100)\n",
    "\n",
    "adjusted_matches = []\n",
    "for match in matches:\n",
    "    name = match[0]\n",
    "    score = match[1]\n",
    "    matched_id = next(key for key, value in db.entities.items() if value[0] == name)\n",
    "        \n",
    "    length_ratio = len(name) / len(normalized_query)\n",
    "    adjusted_score = score * length_ratio\n",
    "    adjusted_matches.append((matched_id, name, adjusted_score))\n",
    "\n",
    "threshold = 30\n",
    "\n",
    "matched_names = [(name, score) for id, name, score in adjusted_matches if score >= threshold]\n",
    "\n",
    "matched_entities = [id for id, name, score in adjusted_matches if score >= threshold]\n",
    "\n",
    "print(tabulate(matched_names, headers=[\"Name\", \"Score\"], tablefmt=\"grid\"))"
   ],
   "id": "b7975593c212a460",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "| Name              |   Score |\n",
      "+===================+=========+\n",
      "| good will hunting | 41.4634 |\n",
      "+-------------------+---------+\n",
      "| who gets the dog  | 30.662  |\n",
      "+-------------------+---------+\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:45:58.968160Z",
     "start_time": "2024-10-18T06:45:58.794644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context = db.fetch_by_id_lst(matched_entities)\n",
    "context.head()"
   ],
   "id": "f64a89b6c62d95e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicate_label                                subject_id aspect ratio  \\\n",
       "0                  http://www.wikidata.org/entity/Q193835   widescreen   \n",
       "1                http://www.wikidata.org/entity/Q27958314          NaN   \n",
       "\n",
       "predicate_label                          assessment  \\\n",
       "0                reverse bechdel test, bechdel test   \n",
       "1                                               NaN   \n",
       "\n",
       "predicate_label                                     award received box office  \\\n",
       "0                academy award for best supporting actor, acade...  225900000   \n",
       "1                                                              NaN        NaN   \n",
       "\n",
       "predicate_label                                        cast member  color  \\\n",
       "0                harmony korine, stellan skarsgard, ben affleck...  color   \n",
       "1                                                              NaN    NaN   \n",
       "\n",
       "predicate_label         country of origin ddis:rating  \\\n",
       "0                united states of america         8.3   \n",
       "1                united states of america         NaN   \n",
       "\n",
       "predicate_label                                           ddis:tag  ...  \\\n",
       "0                inspiring, feel-good, humor, flashback, psycho...  ...   \n",
       "1                                                              NaN  ...   \n",
       "\n",
       "predicate_label nmhh film rating           node description  \\\n",
       "0                    category iv  1997 film by Gus Van Sant   \n",
       "1                            NaN                  2016 film   \n",
       "\n",
       "predicate_label         node label  \\\n",
       "0                Good Will Hunting   \n",
       "1                Who Gets the Dog?   \n",
       "\n",
       "predicate_label                                      nominated for  \\\n",
       "0                academy award for best film editing, academy a...   \n",
       "1                                                              NaN   \n",
       "\n",
       "predicate_label   notable work original language of film or tv show  \\\n",
       "0                minnie driver                              english   \n",
       "1                          NaN                              english   \n",
       "\n",
       "predicate_label     production company publication date rars rating  \\\n",
       "0                miramax, a band apart       1997-12-05         NaN   \n",
       "1                  epic pictures group       2016-09-13          12   \n",
       "\n",
       "predicate_label             screenwriter  \n",
       "0                matt damon, ben affleck  \n",
       "1                                    NaN  \n",
       "\n",
       "[2 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicate_label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>aspect ratio</th>\n",
       "      <th>assessment</th>\n",
       "      <th>award received</th>\n",
       "      <th>box office</th>\n",
       "      <th>cast member</th>\n",
       "      <th>color</th>\n",
       "      <th>country of origin</th>\n",
       "      <th>ddis:rating</th>\n",
       "      <th>ddis:tag</th>\n",
       "      <th>...</th>\n",
       "      <th>nmhh film rating</th>\n",
       "      <th>node description</th>\n",
       "      <th>node label</th>\n",
       "      <th>nominated for</th>\n",
       "      <th>notable work</th>\n",
       "      <th>original language of film or tv show</th>\n",
       "      <th>production company</th>\n",
       "      <th>publication date</th>\n",
       "      <th>rars rating</th>\n",
       "      <th>screenwriter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q193835</td>\n",
       "      <td>widescreen</td>\n",
       "      <td>reverse bechdel test, bechdel test</td>\n",
       "      <td>academy award for best supporting actor, acade...</td>\n",
       "      <td>225900000</td>\n",
       "      <td>harmony korine, stellan skarsgard, ben affleck...</td>\n",
       "      <td>color</td>\n",
       "      <td>united states of america</td>\n",
       "      <td>8.3</td>\n",
       "      <td>inspiring, feel-good, humor, flashback, psycho...</td>\n",
       "      <td>...</td>\n",
       "      <td>category iv</td>\n",
       "      <td>1997 film by Gus Van Sant</td>\n",
       "      <td>Good Will Hunting</td>\n",
       "      <td>academy award for best film editing, academy a...</td>\n",
       "      <td>minnie driver</td>\n",
       "      <td>english</td>\n",
       "      <td>miramax, a band apart</td>\n",
       "      <td>1997-12-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>matt damon, ben affleck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q27958314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states of america</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016 film</td>\n",
       "      <td>Who Gets the Dog?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>epic pictures group</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:46:01.530168Z",
     "start_time": "2024-10-18T06:46:00.815722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "person, movies = ner_parser.process_query(query)\n",
    "\n",
    "context = db.get_context(person,movies)\n",
    "column_embeddings = {col: qe.embed_phrase(col) for col in context.columns}\n",
    "\n",
    "filtered_query = filter_query(query, person, movies)\n",
    "query_embeddings = [qe.embed_phrase(word) for word in filtered_query]\n",
    "\n",
    "context.head()\n"
   ],
   "id": "f20c91e8550b5e1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for fuzzy matching: 0.0 ms\n",
      "Matched 'good' to 'good' with a score of 100.0.\n",
      "Time taken for reverse index lookup: 14.6609 ms\n",
      "Time taken for fetching data: 15.865 ms\n",
      "No context data found for 'good'. Performing partial match search.\n",
      "Time taken for partial match search: 490.0803 ms\n",
      "Time taken for pivot table creation: 112.915 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predicate_label                                subject_id after a work by  \\\n",
       "0                http://www.wikidata.org/entity/Q10797504             NaN   \n",
       "1                http://www.wikidata.org/entity/Q11972368             NaN   \n",
       "2                http://www.wikidata.org/entity/Q12124618             NaN   \n",
       "3                http://www.wikidata.org/entity/Q14833945             NaN   \n",
       "4                 http://www.wikidata.org/entity/Q1537484             NaN   \n",
       "\n",
       "predicate_label art director aspect ratio    assessment author award received  \\\n",
       "0                        NaN          NaN           NaN    NaN            NaN   \n",
       "1                        NaN          NaN           NaN    NaN            NaN   \n",
       "2                        NaN          NaN  bechdel test    NaN            NaN   \n",
       "3                        NaN          NaN  bechdel test    NaN            NaN   \n",
       "4                        NaN          NaN           NaN    NaN            NaN   \n",
       "\n",
       "predicate_label based on bbfc rating box office  ... production designer  \\\n",
       "0                    NaN         NaN        NaN  ...                 NaN   \n",
       "1                    NaN         NaN        NaN  ...                 NaN   \n",
       "2                    NaN         NaN        NaN  ...                 NaN   \n",
       "3                    NaN         NaN        NaN  ...                 NaN   \n",
       "4                    NaN         NaN        NaN  ...                 NaN   \n",
       "\n",
       "predicate_label publication date rcq classification rtc film rating  \\\n",
       "0                            NaN                NaN             NaN   \n",
       "1                            NaN                NaN             NaN   \n",
       "2                     2012-05-31                NaN             NaN   \n",
       "3                     2014-01-01                NaN             b15   \n",
       "4                     2001-01-01                NaN             NaN   \n",
       "\n",
       "predicate_label                   screenwriter set during recurring event  \\\n",
       "0                                          NaN                        NaN   \n",
       "1                                          NaN                        NaN   \n",
       "2                              glenn patterson                        NaN   \n",
       "3                kelly masterson, marcus sakey                        NaN   \n",
       "4                                          NaN                        NaN   \n",
       "\n",
       "predicate_label set in period significant event        subclass of  \\\n",
       "0                         NaN               NaN  binary opposition   \n",
       "1                         NaN               NaN                NaN   \n",
       "2                         NaN               NaN                NaN   \n",
       "3                         NaN               NaN                NaN   \n",
       "4                         NaN               NaN                NaN   \n",
       "\n",
       "predicate_label takes place in fictional universe  \n",
       "0                                             NaN  \n",
       "1                                             NaN  \n",
       "2                                             NaN  \n",
       "3                                             NaN  \n",
       "4                                             NaN  \n",
       "\n",
       "[5 rows x 93 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicate_label</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>after a work by</th>\n",
       "      <th>art director</th>\n",
       "      <th>aspect ratio</th>\n",
       "      <th>assessment</th>\n",
       "      <th>author</th>\n",
       "      <th>award received</th>\n",
       "      <th>based on</th>\n",
       "      <th>bbfc rating</th>\n",
       "      <th>box office</th>\n",
       "      <th>...</th>\n",
       "      <th>production designer</th>\n",
       "      <th>publication date</th>\n",
       "      <th>rcq classification</th>\n",
       "      <th>rtc film rating</th>\n",
       "      <th>screenwriter</th>\n",
       "      <th>set during recurring event</th>\n",
       "      <th>set in period</th>\n",
       "      <th>significant event</th>\n",
       "      <th>subclass of</th>\n",
       "      <th>takes place in fictional universe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q10797504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>binary opposition</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q11972368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q12124618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bechdel test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>glenn patterson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.wikidata.org/entity/Q14833945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bechdel test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b15</td>\n",
       "      <td>kelly masterson, marcus sakey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.wikidata.org/entity/Q1537484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:46:03.614990Z",
     "start_time": "2024-10-18T06:46:03.601852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_columns = find_closest_columns(query_embeddings, column_embeddings, top_n=10)\n",
    "filtered_context_df = context[top_columns]"
   ],
   "id": "eca896190324e2a4",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:46:09.830681Z",
     "start_time": "2024-10-18T06:46:04.845690Z"
    }
   },
   "cell_type": "code",
   "source": "llm._query(query, filtered_context_df)",
   "id": "b92daea468f8ae0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jason priestley'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:36:59.834082Z",
     "start_time": "2024-10-18T06:36:59.812874Z"
    }
   },
   "cell_type": "code",
   "source": "person",
   "id": "388f79f6b396409b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T06:37:00.230768Z",
     "start_time": "2024-10-18T06:37:00.226381Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ff52b8ff7a3153eb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
