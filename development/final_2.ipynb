{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:19.815511Z",
     "start_time": "2024-10-20T10:14:17.475472Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "import torch\n",
    "from torch import py_int\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline, AutoModel\n",
    "from transformers import logging as transformers_logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tabulate import tabulate\n",
    "transformers_logging.set_verbosity_error()\n",
    "import json\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "# Silencing TqdmWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinbrundler/Desktop/ATAI/movie-bot/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:20.230765Z",
     "start_time": "2024-10-20T10:14:19.822470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_to_keep = [\"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"with\", \"how\", \"before\", \"after\",\"same\"]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])"
   ],
   "id": "a2ac0c91ab7407d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kevinbrundler/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:20.855192Z",
     "start_time": "2024-10-20T10:14:20.324653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NERParser:\n",
    "    def __init__(self, model_name: str = \"dslim/bert-base-NER\", lowercase: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the NER parser with a model and optionally configure the lowercase preprocessing.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "        \n",
    "        # Load the tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, do_lower_case=self.lowercase)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set up the NER pipeline\n",
    "        self.nlp_pipeline = pipeline(\n",
    "            \"ner\", \n",
    "            model=self.model, \n",
    "            tokenizer=self.tokenizer, \n",
    "            device=self.device, \n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "\n",
    "    def get_device(self):\n",
    "        \"\"\"\n",
    "        Determines whether to use MPS, CUDA, or CPU depending on the available hardware.\n",
    "        \"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"MPS device found, using MPS backend.\\n\")\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            print(f\"CUDA device found, using CUDA backend. Device: {torch.cuda.get_device_name(0)}\\n\")\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            print(\"Neither MPS nor CUDA found, using CPU.\\n\")\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    \n",
    "    def parse_ner_results(self, ner_results: list):\n",
    "        \"\"\"\n",
    "        Parse the NER results and extract entities related to 'PER' (persons) and 'MISC' (potential movie titles).\n",
    "        \"\"\"\n",
    "        per_entities, misc_entities = [], []\n",
    "        \n",
    "        for entity in ner_results:\n",
    "            # Extraction of all Persons\n",
    "            if entity['entity_group'] == 'PER':\n",
    "                per_entities.append(entity['word'])\n",
    "            # Extraction of all Misc that could indicate movies\n",
    "            elif entity['entity_group'] == 'MISC':\n",
    "                misc_entities.append(entity['word'])\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    \n",
    "    def process_query(self, query: str):\n",
    "        \"\"\"\n",
    "        Processes a text query, runs NER, and returns the extracted actors and movie names.\n",
    "        \"\"\"\n",
    "        # Optionally lowercase the input if configured\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        \n",
    "        # Run the NER pipeline\n",
    "        ner_results = self.nlp_pipeline(query)\n",
    "\n",
    "        # Parse the results to extract actors and movies\n",
    "        per_entities, misc_entities = self.parse_ner_results(ner_results)\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "ner_parser = NERParser(lowercase=False)"
   ],
   "id": "d49cf7e85debd577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:20.866423Z",
     "start_time": "2024-10-20T10:14:20.862802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataBase:\n",
    "    \"\"\"Handles the extraction of context data for given people and movies from a database, with fuzzy matching for names.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.db = pd.read_pickle(os.path.join(os.getcwd(), r\"exports/extended_graph_triples.pkl\"))\n",
    "        \n",
    "        with open(r\"exports/entity_db.json\", encoding=\"utf-8\") as f: \n",
    "            self.entities = json.load(f)\n",
    "            self.entity_list = list(subject.lower() for subject, types in self.entities.values())\n",
    "        \n",
    "        # otherwise exact matching will fail\n",
    "        self.db['subject_id'] = self.db['subject_id'].astype(str).str.strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_string(s):\n",
    "        \"\"\"Cleans the input entity to a uniform naming convention, by removing non ascii characters, encoding it to utf, setting it to lowercase, and removing redundant spaces\"\"\"\n",
    "        s = s.lower()\n",
    "        s = unicodedata.normalize('NFKD', s)\n",
    "        s = s.encode('ascii', 'ignore').decode('utf-8')\n",
    "        s = re.sub(r'[^\\w\\s]', '', s)\n",
    "        s = ' '.join(s.split())\n",
    "        return s\n",
    "    \n",
    "    def fetch(self, entity_lst, search_column):\n",
    "        \n",
    "        relevant = self.db[self.db[search_column].isin(entity_lst)].dropna(axis=1)\n",
    "           \n",
    "        if relevant.empty:\n",
    "            print(f\"No context data found for given information.\")\n",
    "            return pd.DataFrame()          \n",
    "        \n",
    "        pivot_df = relevant.pivot_table(\n",
    "            index='subject_id',\n",
    "            columns='predicate_label',\n",
    "            values='object_label',\n",
    "            aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "        )\n",
    "    \n",
    "        pivot_df.reset_index(inplace=True)\n",
    "    \n",
    "        return pivot_df"
   ],
   "id": "d17e5503d50ffd8c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:20.873353Z",
     "start_time": "2024-10-20T10:14:20.870644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QueryEmbedder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._glove_embeddings = self._load_glove_embeddings(\"exports/glove.6B/glove.6B.300d.txt\")\n",
    "        \n",
    "    def _load_glove_embeddings(self, file_path):\n",
    "        embeddings = {}\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings[word] = vector\n",
    "        return embeddings\n",
    "    \n",
    "    def embed_phrase(self, phrase):\n",
    "        words = phrase.split()\n",
    "        word_vectors = [self._glove_embeddings[word.lower()] for word in words if word.lower() in self._glove_embeddings]\n",
    "        \n",
    "        if len(word_vectors) == 0:\n",
    "            return np.zeros(300)\n",
    "        \n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    "
   ],
   "id": "ad421631fb9f85b0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:20.881658Z",
     "start_time": "2024-10-20T10:14:20.877610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QueryEmbedderContextualized:\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2', device=None):\n",
    "        \"\"\"\n",
    "        Initializes the QueryEmbedder with a SentenceTransformer model for sentence embeddings.\n",
    "        \"\"\"\n",
    "        self.device = self.get_device()\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "        self.cache = {}\n",
    "    \n",
    "    \n",
    "    def get_device(self):\n",
    "        \"\"\"\n",
    "        Determines whether to use MPS, CUDA, or CPU depending on the available hardware.\n",
    "        \"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"MPS device found, using MPS backend.\\n\")\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            print(f\"CUDA device found, using CUDA backend. Device: {torch.cuda.get_device_name(0)}\\n\")\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            print(\"Neither MPS nor CUDA found, using CPU.\\n\")\n",
    "            return torch.device(\"cpu\")\n",
    "    \n",
    "    def embed_phrase(self, phrases):\n",
    "        \"\"\"\n",
    "        Generates embeddings for given phrases using SentenceTransformer.\n",
    "\n",
    "        Args:\n",
    "            phrases (str or List[str]): The input phrase(s) to embed.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The embedding vector(s) for the phrase(s).\n",
    "        \"\"\"\n",
    "        # Ensure phrases is a list\n",
    "        if isinstance(phrases, str):\n",
    "            phrases = [phrases]\n",
    "        elif not isinstance(phrases, list):\n",
    "            raise TypeError(\"Input must be a string or a list of strings.\")\n",
    "\n",
    "        embeddings = []\n",
    "        phrases_to_compute = []\n",
    "        indices_to_compute = []\n",
    "\n",
    "        for idx, phrase in enumerate(phrases):\n",
    "            if phrase in self.cache:\n",
    "                embeddings.append(self.cache[phrase])\n",
    "            else:\n",
    "                embeddings.append(None)\n",
    "                phrases_to_compute.append(phrase)\n",
    "                indices_to_compute.append(idx)\n",
    "        \n",
    "        if phrases_to_compute:\n",
    "            new_embeddings = self.model.encode(\n",
    "                phrases_to_compute, \n",
    "                show_progress_bar=False, \n",
    "                convert_to_numpy=True, \n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            for idx, emb in zip(indices_to_compute, new_embeddings):\n",
    "                embeddings[idx] = emb\n",
    "                self.cache[phrases[idx]] = emb\n",
    "        \n",
    "        # Return embeddings\n",
    "        if len(embeddings) == 1:\n",
    "            return embeddings[0]\n",
    "        else:\n",
    "            return np.array(embeddings)"
   ],
   "id": "6c97857e987a912f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:20.888906Z",
     "start_time": "2024-10-20T10:14:20.886036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LLM():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", top_k=1)\n",
    "    \n",
    "    def query(self, query, context_df):\n",
    "        \n",
    "        top_columns = context_df.columns\n",
    "        \n",
    "        context = \"\"\n",
    "        for index, row in context_df.iterrows():\n",
    "            node_label = row.get(\"node label\", \"Unknown\")\n",
    "            row_context = f\"This text is about \\\"{node_label}\\\":\\n\"\n",
    "            row_context += \"\\n\".join([f\"{col}: {row[col]}\" for col in context_df[top_columns].columns if col != \"node label\"])\n",
    "            row_context += \"\\n\\n\"\n",
    "            context += row_context\n",
    "        \n",
    "        output = self.qa_model(question=query, context=context)\n",
    "        \n",
    "        answer_str = str()\n",
    "        if isinstance(output, list) and output:\n",
    "            answer_str = \", \".join([result['answer'] for result in output])\n",
    "            \n",
    "        elif isinstance(output, dict):\n",
    "            answer_str = output['answer']\n",
    "        \n",
    "        if not answer_str:\n",
    "            answer_str = \"No answer found.\"\n",
    "        \n",
    "        return answer_str"
   ],
   "id": "e0ce5b9bfb93651f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:20.897455Z",
     "start_time": "2024-10-20T10:14:20.893361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 \n",
    "    \n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "def rescale_probabilities(similarities):\n",
    "    \"\"\"\n",
    "    Rescales the similarity scores so that they sum to 1, turning them into a probability distribution.\n",
    "    \n",
    "    Args:\n",
    "        similarities (List[float]): List of similarity scores.\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Rescaled probabilities.\n",
    "    \"\"\"\n",
    "    similarity_sum = sum(similarities)\n",
    "    if similarity_sum == 0:\n",
    "        return [0] * len(similarities)  # Avoid division by zero\n",
    "    \n",
    "    return [sim / similarity_sum for sim in similarities]\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, high_threshold=0.4, top_n=10, rescaled_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Returns columns based on cosine similarity with a two-tiered strategy and rescaled probabilities.\n",
    "    - If a column has similarity above 'high_threshold', return that column immediately.\n",
    "    - Otherwise, return all columns with a similarity greater than 'low_threshold'.\n",
    "    - Rescale the top N column similarities into probabilities and return columns with a rescaled probability greater than rescaled_threshold.\n",
    "    \n",
    "    Args:\n",
    "        query_embeddings (List[np.ndarray]): Embeddings for query words.\n",
    "        column_embeddings (Dict[str, np.ndarray]): Precomputed embeddings for columns.\n",
    "        low_threshold (float): Minimum similarity threshold (default: 0.27).\n",
    "        high_threshold (float): Confidence threshold to return immediately (default: 0.35).\n",
    "        top_n (int): Number of top columns to consider for rescaling (default: 10).\n",
    "        rescaled_threshold (float): Minimum rescaled probability threshold (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: The selected column names.\n",
    "    \"\"\"\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_columns = sorted_columns[:top_n]\n",
    "    \n",
    "    column_names, similarities = zip(*top_columns)\n",
    "    \n",
    "    rescaled_probs = rescale_probabilities(similarities)\n",
    "    \n",
    "    selected_columns = []\n",
    "    \n",
    "    for col, sim in zip(column_names, similarities):\n",
    "        if sim >= high_threshold:\n",
    "            print(f\"High confidence match found: {col} with similarity {sim: .4f}\")\n",
    "            return [col]\n",
    "    \n",
    "    for col, rescaled_prob in zip(column_names, rescaled_probs):\n",
    "        print(f\"Column {col} has similarity {rescaled_prob: .4f}\")\n",
    "        if rescaled_prob >= rescaled_threshold:\n",
    "            selected_columns.append(col)\n",
    "    \n",
    "    return selected_columns"
   ],
   "id": "93858e6040c9c835",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:23.175242Z",
     "start_time": "2024-10-20T10:14:20.903388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DataBase()\n",
    "\n",
    "#qe = QueryEmbedder()\n",
    "\n",
    "qe = QueryEmbedderContextualized()\n",
    "\n",
    "llm = LLM()"
   ],
   "id": "71ebcb4ff84a1fe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:23.183295Z",
     "start_time": "2024-10-20T10:14:23.180866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_query(query, node_label):\n",
    "                \n",
    "    if not len(query):\n",
    "        return []\n",
    "    \n",
    "    relevant = []\n",
    "    for word in query.replace(\". \", \" \").lower().split(\" \"):\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in node_label.lower().replace(\" \", \"\") or cleaned_word == \"\":\n",
    "            continue\n",
    "        \n",
    "        relevant.append(cleaned_word)\n",
    "        \n",
    "    return \" \".join(relevant)"
   ],
   "id": "349af24c9d659479",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:23.190416Z",
     "start_time": "2024-10-20T10:14:23.187974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fuzzy_match(query_str, comparison_list, threshold=30):\n",
    "    matches = process.extract(query_str, comparison_list, scorer=fuzz.partial_ratio, limit=100)\n",
    "    \n",
    "    id_name_score = []\n",
    "    for match in matches:\n",
    "        name = match[0]\n",
    "        score = match[1]\n",
    "        matched_id = next(key for key, value in db.entities.items() if value[0] == name)\n",
    "            \n",
    "        length_ratio = len(name) / len(query_str)\n",
    "        adjusted_score = score * length_ratio\n",
    "                \n",
    "        id_name_score.append((matched_id, name, adjusted_score))\n",
    "        \n",
    "    # print(tabulate(id_name_score[:3], headers=[\"id\", \"Name\", \"Score\"], tablefmt=\"grid\"))\n",
    "    \n",
    "    return [id for id, _, score in id_name_score if score >= threshold]"
   ],
   "id": "b7975593c212a460",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:14:23.197020Z",
     "start_time": "2024-10-20T10:14:23.194881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_matches(df, normalized_query, top_n=2):\n",
    "    concatenated_rows = df.apply(lambda row: ' '.join(row.astype(str)), axis=1).tolist()\n",
    "    top_matches = process.extract(normalized_query, concatenated_rows, scorer=fuzz.partial_ratio, limit=top_n)\n",
    "    \n",
    "    top_indices = [match[2] for match in top_matches]\n",
    "    \n",
    "    return df.iloc[top_indices]"
   ],
   "id": "68ede21d279d32fa",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:04.632632Z",
     "start_time": "2024-10-20T10:15:04.628551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "# Decorator to measure execution time\n",
    "def measure_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        result = func(*args, **kwargs)  # Call the function\n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(f\"Execution time for {func.__name__}: {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ],
   "id": "8d39854dad147821",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:05.893615Z",
     "start_time": "2024-10-20T10:15:05.885572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@measure_time\n",
    "def answer_query(query, correct_answer=\"\"):\n",
    "    normalized_query = db.normalize_string(query)\n",
    "    \n",
    "    index_matches = fuzzy_match(normalized_query, db.entity_list, threshold=30)\n",
    "        \n",
    "    context = db.fetch(index_matches, \"subject_id\")\n",
    "        \n",
    "    # EXPERIMENTAL\n",
    "    context = get_top_matches(context, normalized_query, top_n=1)\n",
    "    \n",
    "    try:\n",
    "        node_label = context[\"node label\"].values[0]\n",
    "    except Exception:\n",
    "        node_label = \"\"\n",
    "    \n",
    "    if context.empty:\n",
    "        print(\"No context data found for given IDs or string\")\n",
    "        context = pd.DataFrame()\n",
    "        \n",
    "    # EXPERIMENTAL - remove unused columns\n",
    "    elements_to_remove = [\"image\"]\n",
    "    context = context.drop(columns=elements_to_remove, errors='ignore')\n",
    "    \n",
    "    context.head(10).to_excel(\"debug.xlsx\")\n",
    "    \n",
    "    # EXPERIMENTAL - rename columns\n",
    "    columns_to_rename = {\n",
    "        \"cast member\":\"movie cast\",\n",
    "        \"notable work\": \"acted in\"\n",
    "    }\n",
    "    columns_to_rename = {k: v for k, v in columns_to_rename.items() if k in context.columns}\n",
    "    context = context.rename(columns=columns_to_rename)\n",
    "    \n",
    "    # EXPERIMENTAL - duplicate columns\n",
    "    columns_to_duplicate = {\"acted in\": \"played in\",\n",
    "                            \"acted in\": \"appeared in\"}\n",
    "    \n",
    "    for column, duplicate in columns_to_duplicate.items():\n",
    "        try:\n",
    "            context[duplicate] = context[column]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    query_filtered = filter_query(query, node_label)\n",
    "        \n",
    "    column_embeddings = {col: qe.embed_phrase(col) for col in context.columns}\n",
    "    query_embeddings = [qe.embed_phrase(word) for word in query_filtered.split()]  \n",
    "    top_columns_embeddings = find_closest_columns(query_embeddings, column_embeddings)\n",
    "    \n",
    "    # EXPERIMENTAL\n",
    "    top_columns_dict = process.extract(normalized_query, context.columns, scorer=fuzz.partial_ratio, limit=3)\n",
    "    top_columns_fuzzy = [c[0] for c in top_columns_dict]\n",
    "    \n",
    "    # MANUAL OVERWRITE:\n",
    "    top_columns_fuzzy = []\n",
    "        \n",
    "    # EXPERIMENTAL - always keep columns\n",
    "    col_always_keep = []\n",
    "    \n",
    "    combined_columns = set(top_columns_fuzzy + top_columns_embeddings + col_always_keep)\n",
    "    top_columns = [col for col in combined_columns if col in context.columns]\n",
    "    filtered_context_df = context[top_columns]\n",
    "\n",
    "    answer = llm.query(query, filtered_context_df)\n",
    "    \n",
    "    print(\"Answer\")\n",
    "    print(answer)\n",
    "    \n",
    "    ### EXPERIMENTAL\n",
    "    #filtered_context_df[\"hint\"] = answer\n",
    "    #answer = llm.query(query, filtered_context_df)\n",
    "        \n",
    "    #normalized_answer = db.normalize_string(answer)\n",
    "    #normalized_correct_answer = db.normalize_string(correct_answer)\n",
    "    \n",
    "    print(f\"{'CORRECT' if answer and answer in correct_answer else 'WRONG'} - {query} - {answer}\")\n"
   ],
   "id": "f64a89b6c62d95e4",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:08.429349Z",
     "start_time": "2024-10-20T10:15:06.998838Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Good Will Hunting?\", \"Gus Van Sant\")",
   "id": "b92daea468f8ae0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.7044\n",
      "Answer\n",
      "Gus Van Sant\n",
      "CORRECT - Who is the director of Good Will Hunting? - Gus Van Sant\n",
      "Execution time for answer_query: 1.4279 seconds\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:12.872981Z",
     "start_time": "2024-10-20T10:15:12.237787Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Bridge on the River Kwai?\", \"David Lean\")",
   "id": "fc09a07aff4c27e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.4908\n",
      "Answer\n",
      "David Lean\n",
      "CORRECT - Who directed The Bridge on the River Kwai? - David Lean\n",
      "Execution time for answer_query: 0.6328 seconds\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:14.771784Z",
     "start_time": "2024-10-20T10:15:13.955405Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed the movie The Godfather?\", \"Francis Ford Coppola\") # or Mario Puzo or Francis Ford Coppola",
   "id": "a6056ee8bb4f64ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.4927\n",
      "Answer\n",
      "Francis Ford Coppola\n",
      "CORRECT - Who directed the movie The Godfather? - Francis Ford Coppola\n",
      "Execution time for answer_query: 0.8137 seconds\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:16.565592Z",
     "start_time": "2024-10-20T10:15:15.636983Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of The Dark Knight?\", \"Christopher Nolan\")",
   "id": "8d9752b180ab30d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.7044\n",
      "Answer\n",
      "Christopher Nolan\n",
      "CORRECT - Who is the director of The Dark Knight? - Christopher Nolan\n",
      "Execution time for answer_query: 0.9264 seconds\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:18.206911Z",
     "start_time": "2024-10-20T10:15:17.426840Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Dark Knight?\", \"Christopher Nolan\")",
   "id": "73e2d76165df3d84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.4908\n",
      "Answer\n",
      "Christopher Nolan\n",
      "CORRECT - Who directed The Dark Knight? - Christopher Nolan\n",
      "Execution time for answer_query: 0.7781 seconds\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:21.816201Z",
     "start_time": "2024-10-20T10:15:21.181975Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Where was Angelina Jolie born?\", \"Los Angeles\")",
   "id": "14626d0f4be528dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: place of birth with similarity  0.5401\n",
      "Answer\n",
      "Los Angeles\n",
      "CORRECT - Where was Angelina Jolie born? - Los Angeles\n",
      "Execution time for answer_query: 0.6317 seconds\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:33.222426Z",
     "start_time": "2024-10-20T10:15:32.670561Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Which role had Lenardo di Caprio in Inception?\", \"actor\")",
   "id": "f1d40bcb791470e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column director has similarity  0.1229\n",
      "Column occupation has similarity  0.1138\n",
      "Column executive producer has similarity  0.1018\n",
      "Column winner has similarity  0.0991\n",
      "Column screenwriter has similarity  0.0969\n",
      "Column nominated for has similarity  0.0960\n",
      "Column instance of has similarity  0.0948\n",
      "Column performer has similarity  0.0937\n",
      "Column movie cast has similarity  0.0926\n",
      "Column IMDb ID has similarity  0.0883\n",
      "Answer\n",
      "executive producer\n",
      "WRONG - Which role had Lenardo di Caprio in Inception? - executive producer\n",
      "Execution time for answer_query: 0.5481 seconds\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:39.163884Z",
     "start_time": "2024-10-20T10:15:38.593161Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed Inception?\", \"christopher nolan\")",
   "id": "744b63aa69f8e8ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.4404\n",
      "Answer\n",
      "Sidney J. Furie\n",
      "WRONG - Who directed Inception? - Sidney J. Furie\n",
      "Execution time for answer_query: 0.5596 seconds\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:41.720429Z",
     "start_time": "2024-10-20T10:15:41.118117Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the genre of Good Neighbors?\", \"comedy-drama\") # Could also be comedy-drama, and comedy film. ",
   "id": "3c31ec3966faaa2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: genre with similarity  0.6792\n",
      "Answer\n",
      "art film, comedy-drama\n",
      "WRONG - What is the genre of Good Neighbors? - art film, comedy-drama\n",
      "Execution time for answer_query: 0.5997 seconds\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:44.200042Z",
     "start_time": "2024-10-20T10:15:43.635066Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the MPAA film rating of Weathering with You?\", \"PG-13\")",
   "id": "8ba20793435fd0e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: MPAA film rating with similarity  0.4311\n",
      "Answer\n",
      "NC-17\n",
      "WRONG - What is the MPAA film rating of Weathering with You? - NC-17\n",
      "Execution time for answer_query: 0.5622 seconds\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:46.117994Z",
     "start_time": "2024-10-20T10:15:45.561885Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars: Episode VI - Return of the Jedi?\", \"Richard Marquand\")",
   "id": "361dde5a560d788d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.7044\n",
      "Answer\n",
      "Richard Marquand\n",
      "CORRECT - Who is the director of Star Wars: Episode VI - Return of the Jedi? - Richard Marquand\n",
      "Execution time for answer_query: 0.5535 seconds\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:48.638753Z",
     "start_time": "2024-10-20T10:15:48.027641Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the screenwriter of The Masked Gang: Cyprus?\", \"Murat Aslan\")",
   "id": "51eeb0370bf2a5d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: screenwriter with similarity  0.5085\n",
      "Answer\n",
      "Murat Aslan\n",
      "CORRECT - Who is the screenwriter of The Masked Gang: Cyprus? - Murat Aslan\n",
      "Execution time for answer_query: 0.6057 seconds\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:50.744898Z",
     "start_time": "2024-10-20T10:15:50.264502Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Angelina Jolie play?\", \"Interrupted\")",
   "id": "125faf56210bb156",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: acted in with similarity  0.4268\n",
      "Answer\n",
      "Gia, Girl, Interrupted, Changeling\n",
      "WRONG - In which movie did Angelina Jolie play? - Gia, Girl, Interrupted, Changeling\n",
      "Execution time for answer_query: 0.4769 seconds\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:54.431832Z",
     "start_time": "2024-10-20T10:15:53.866928Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Name a movie with Brad Pitt\")",
   "id": "d36c0a5593973454",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column winner has similarity  0.1070\n",
      "Column narrator has similarity  0.1050\n",
      "Column director has similarity  0.1041\n",
      "Column follows has similarity  0.1017\n",
      "Column followed by has similarity  0.1010\n",
      "Column color has similarity  0.0982\n",
      "Column acted in has similarity  0.0977\n",
      "Column spouse has similarity  0.0966\n",
      "Column student of has similarity  0.0953\n",
      "Column student has similarity  0.0934\n",
      "Answer\n",
      "Giorgia Farina\n",
      "WRONG - Name a movie with Brad Pitt - Giorgia Farina\n",
      "Execution time for answer_query: 0.5613 seconds\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:15:56.373589Z",
     "start_time": "2024-10-20T10:15:55.899487Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Liam Neeson act?\")",
   "id": "58629b65eef22b3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: acted in with similarity  0.5002\n",
      "Answer\n",
      "Star Wars: Episode I – The Phantom Menace\n",
      "WRONG - In which movie did Liam Neeson act? - Star Wars: Episode I – The Phantom Menace\n",
      "Execution time for answer_query: 0.4694 seconds\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T10:16:02.290603Z",
     "start_time": "2024-10-20T10:16:01.871087Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Liam Neeson play?\")",
   "id": "a9a065b36d7f8674",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: sport with similarity  0.4461\n",
      "Answer\n",
      "Unknown\n",
      "WRONG - In which movie did Liam Neeson play? - Unknown\n",
      "Execution time for answer_query: 0.4163 seconds\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8a489e99e4c989bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
