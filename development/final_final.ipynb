{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:04.432321Z",
     "start_time": "2024-11-06T10:32:55.487083Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration\n",
    ")\n",
    "\n",
    "from transformers import logging as transformers_logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "transformers_logging.set_verbosity_error()\n",
    "import json\n",
    "import time\n",
    "from functools import wraps\n",
    "import sentencepiece\n",
    "\n",
    "# Silencing TqdmWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\UntrackedFolder\\movie-bot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:05.702067Z",
     "start_time": "2024-11-06T10:33:04.448085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_to_keep = [\"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"with\", \"how\", \"before\", \"after\",\"same\"]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])"
   ],
   "id": "9ce915e61e55399c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:05.843599Z",
     "start_time": "2024-11-06T10:33:05.839375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def measure_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        result = func(*args, **kwargs)  # Call the function\n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(f\"Execution time for {func.__name__}: {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ],
   "id": "987d727174eaa4ee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:05.858044Z",
     "start_time": "2024-11-06T10:33:05.853085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NERParser:\n",
    "    def __init__(self, model_name=\"dslim/bert-base-NER\", lowercase=False):\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "\n",
    "        self.nlp_pipeline = pipeline(\n",
    "            \"ner\", \n",
    "            model=AutoModelForTokenClassification.from_pretrained(model_name),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_name, do_lower_case=lowercase),\n",
    "            device=self.device, \n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "\n",
    "    def get_device(self):\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def parse_ner_results(self, ner_results):\n",
    "        per_entities = [e['word'] for e in ner_results if e['entity_group'] == 'PER']\n",
    "        misc_entities = [e['word'] for e in ner_results if e['entity_group'] == 'MISC']\n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    def process_query(self, query):\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        return self.parse_ner_results(self.nlp_pipeline(query))\n",
    "\n"
   ],
   "id": "a15b5f4fab282289",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:05.912901Z",
     "start_time": "2024-11-06T10:33:05.903998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataBase:\n",
    "    \"\"\"Handles context data extraction for people and movies from a database with fuzzy matching support.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.db = pd.read_pickle(os.path.join(os.getcwd(), \"exports/extended_graph_triples.pkl\"))\n",
    "        \n",
    "        self.db['subject_id'] = self.db['subject_id'].astype(str).str.strip()\n",
    "        self.db['predicate_label'] = self.db['predicate_label'].astype(str).str.strip()\n",
    "        self.db['object_label'] = self.db['object_label'].astype(str).str.strip()\n",
    "        \n",
    "        self.db_pivot = self.db.pivot_table(\n",
    "                index='subject_id',\n",
    "                columns='predicate_label',\n",
    "                values='object_label',\n",
    "                aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "            )\n",
    "        \n",
    "        with open('exports/movie_db.json') as f:\n",
    "            self.movie_data = json.load(f)\n",
    "            self.movie_ids = set(self.movie_data.keys())\n",
    "        self.movie_db = pd.DataFrame(list(self.movie_data.items()), columns=[\"entity_id\", \"entity_label\"])\n",
    "        \n",
    "        with open('exports/people_db.json') as f:\n",
    "            self.people_data = json.load(f)\n",
    "            self.people_ids = set(self.people_data.keys())\n",
    "        self.people_db = pd.DataFrame(list(self.people_data.items()), columns=[\"entity_id\", \"entity_label\"])\n",
    "        \n",
    "        self.entities = {**self.movie_data, **self.people_data}\n",
    "        \n",
    "        self.movie_names = self.movie_db[\"entity_label\"].tolist()\n",
    "        self.people_names = self.people_db[\"entity_label\"].tolist()\n",
    "        \n",
    "        self.entity_list = self.movie_names + self.people_names\n",
    "       \n",
    "        self.people_movie_mapping = {}\n",
    "        self.movie_people_mapping = {}\n",
    "        \n",
    "        self.map_people_movies()\n",
    "        \n",
    "        self.movie_recommender_db = self.filter_relevant_movies()\n",
    "        \n",
    "    def map_people_movies(self):\n",
    "        id_triples = pd.read_pickle(os.path.join(\"exports/df_new_triples_only_ids.pkl\"))\n",
    "        \n",
    "        id_triples['subject_id'] = id_triples['subject_id'].astype(str).str.strip()\n",
    "        id_triples['object_id'] = id_triples['object_id'].astype(str).str.strip()\n",
    "        \n",
    "        for _, row in id_triples.iterrows():\n",
    "            subject_id = row['subject_id']\n",
    "            object_id = row['object_id']\n",
    "            \n",
    "            if subject_id in self.people_ids and object_id in self.movie_ids:\n",
    "                if subject_id not in self.people_movie_mapping:\n",
    "                    self.people_movie_mapping[subject_id] = []\n",
    "                self.people_movie_mapping[subject_id].append(object_id)\n",
    "                \n",
    "                if object_id not in self.movie_people_mapping:\n",
    "                    self.movie_people_mapping[object_id] = []\n",
    "                self.movie_people_mapping[object_id].append(subject_id)\n",
    "        \n",
    "        for person, movies in self.people_movie_mapping.items():\n",
    "            self.people_movie_mapping[person] = list(set(movies))\n",
    "        \n",
    "        for movie, people in self.movie_people_mapping.items():\n",
    "            self.movie_people_mapping[movie] = list(set(people))\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def normalize_string(s):\n",
    "        \"\"\"Normalizes strings by removing non-ASCII characters, punctuation, and redundant spaces.\"\"\"\n",
    "        return ' '.join(re.sub(r'[^\\w\\s]', '', unicodedata.normalize('NFKD', s.lower())\n",
    "                               .encode('ascii', 'ignore').decode('utf-8')).split())\n",
    "\n",
    "    def fetch(self, entity_list, search_column):\n",
    "        \"\"\"Fetches relevant rows from the database where `search_column` matches values in `entity_list`.\"\"\"\n",
    "        relevant = self.db[self.db[search_column].isin(entity_list)].dropna(axis=1)\n",
    "        \n",
    "        if relevant.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        return relevant.pivot_table(\n",
    "            index='subject_id',\n",
    "            columns='predicate_label',\n",
    "            values='object_label',\n",
    "            aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "        ).reset_index()\n",
    "    \n",
    "    def filter_relevant_movies(self):\n",
    "\n",
    "        clean_db = self.db[self.db[\"subject_id\"].isin(self.movie_data.keys())]\n",
    "        relevant_cols = [\n",
    "            # \"author\", # only 99 movies hav an author\n",
    "            # \"cast member\",\n",
    "            \"director\", \n",
    "            \"performer\",\n",
    "            \"genre\",\n",
    "            # \"narrative motif\", # only 43 movies have a narrative motif\n",
    "            \"screenwriter\",\n",
    "            \"subject_id\",\n",
    "            \"node label\" # Required for processing\n",
    "        ]\n",
    "        \n",
    "        pv_db = clean_db.pivot_table(\n",
    "                index='subject_id',\n",
    "                columns='predicate_label',\n",
    "                values='object_label',\n",
    "                aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "            )\n",
    "        \n",
    "        pv_db = pv_db[[col for col in relevant_cols if col in pv_db.columns]]\n",
    "\n",
    "        return pv_db.reset_index()"
   ],
   "id": "c9bf6d33ae34d781",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:05.927649Z",
     "start_time": "2024-11-06T10:33:05.920705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QueryEmbedderContextualized:\n",
    "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v2'):\n",
    "        \"\"\"Initializes the QueryEmbedder with a SentenceTransformer model and device setup.\"\"\"\n",
    "        self.device = self.get_device()\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "        self.cache = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        \"\"\"Determines the available hardware device (MPS, CUDA, or CPU).\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def embed_phrase(self, phrases):\n",
    "        \"\"\"\n",
    "        Generates embeddings for given phrases using SentenceTransformer, with caching.\n",
    "\n",
    "        Args:\n",
    "            phrases (str or List[str]): Input phrase(s) to embed.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Embedding vector(s) for the input phrase(s).\n",
    "        \"\"\"\n",
    "        if isinstance(phrases, str):\n",
    "            phrases = [phrases]\n",
    "        elif not isinstance(phrases, list):\n",
    "            raise TypeError(\"Input must be a string or a list of strings.\")\n",
    "        \n",
    "        phrases_to_compute = [p for p in phrases if p not in self.cache]\n",
    "        cached_embeddings = [self.cache[p] for p in phrases if p in self.cache]\n",
    "\n",
    "        if phrases_to_compute:\n",
    "            new_embeddings = self.model.encode(\n",
    "                phrases_to_compute, \n",
    "                show_progress_bar=False, \n",
    "                convert_to_numpy=True, \n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            \n",
    "            for phrase, emb in zip(phrases_to_compute, new_embeddings):\n",
    "                self.cache[phrase] = emb\n",
    "            cached_embeddings.extend(new_embeddings)\n",
    "        \n",
    "        return cached_embeddings[0] if len(cached_embeddings) == 1 else np.array(cached_embeddings)\n"
   ],
   "id": "b6108d2c6628d7db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:05.940888Z",
     "start_time": "2024-11-06T10:33:05.934473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QuestionAnsweringAgent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.qa_model = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\", top_k=1)\n",
    "    \n",
    "    def query(self, query, context_df):\n",
    "        \n",
    "        top_columns = context_df.columns\n",
    "        \n",
    "        context = \"\"\n",
    "        for index, row in context_df.iterrows():\n",
    "            node_label = row.get(\"node label\", \"\")\n",
    "            \n",
    "            row_context = f\"This text is about \\\"{node_label}\\\":\\n\"\n",
    "            \n",
    "            for col in context_df[top_columns].columns:\n",
    "                if col == \"node label\":\n",
    "                    continue\n",
    "                \n",
    "                values = row[col]\n",
    "                values_lst = str(values).split(\",\")\n",
    "                \n",
    "                if len(values_lst) > 5:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst[:5])}\"\n",
    "                else:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst)}\"\n",
    "\n",
    "            context += row_context + \"\\n\\n\"\n",
    "        \n",
    "        output = self.qa_model(question=query, context=context)\n",
    "        \n",
    "        answer_str = str()\n",
    "        if isinstance(output, list) and output:\n",
    "            answer_str = \", \".join([result['answer'] for result in output])\n",
    "            \n",
    "        elif isinstance(output, dict):\n",
    "            answer_str = output['answer']\n",
    "        \n",
    "        if not answer_str:\n",
    "            answer_str = \"No answer found.\"\n",
    "        \n",
    "        return answer_str"
   ],
   "id": "9e2df2f00abd15da",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:05.954947Z",
     "start_time": "2024-11-06T10:33:05.947262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConversationAgent:\n",
    "    def __init__(self, model_name=\"google/flan-t5-large\", max_length=150):\n",
    "        self.device = self.get_device()\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        \"\"\"\n",
    "        Generates a response based on the given prompt.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=self.max_length,\n",
    "            num_beams=5,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response.strip()\n"
   ],
   "id": "adbe62e7f66579e2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:06.105007Z",
     "start_time": "2024-11-06T10:33:05.961011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import rdflib\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class GraphEmbeddings:\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        \n",
    "        self.RDFS = rdflib.namespace.RDFS\n",
    "        self.WD = rdflib.Namespace('http://www.wikidata.org/entity/')\n",
    "     \n",
    "        self.entity_emb = np.load('exports/entity_embeds.npy')\n",
    "        self.relation_emb = np.load('exports/relation_embeds.npy')\n",
    "        \n",
    "        with open('exports/entity_ids.del', 'r') as ifile:\n",
    "            self.ent2id = {rdflib.term.URIRef(ent): int(idx) for idx, ent in csv.reader(ifile, delimiter='\\t')}\n",
    "            self.id2ent = {v: k for k, v in self.ent2id.items()}\n",
    "            \n",
    "        with open('exports/relation_ids.del', 'r') as ifile:\n",
    "            self.rel2id = {rdflib.term.URIRef(rel): int(idx) for idx, rel in csv.reader(ifile, delimiter='\\t')}\n",
    "        \n",
    "        with open(\"exports/predicate_db.json\", encoding=\"utf-8\") as f:\n",
    "            self.predicates_db = json.load(f)\n",
    "        \n",
    "        self.ent2lbl = {rdflib.term.URIRef(row.subject_id): row.subject_label for index, row in graph.iterrows()}\n",
    "\n",
    "    def answer_query_embedding(self, context, top_columns):\n",
    "        STD_ERROR = \"The embeddings did not provide a valid answer.\"\n",
    "        try:\n",
    "            context_id = context.subject_id.values[0]\n",
    "            if not context_id:\n",
    "                print(\"No context ID found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            e_id = self.ent2id.get(rdflib.term.URIRef(context_id))\n",
    "            if e_id is None:\n",
    "                return \"2\"\n",
    "\n",
    "            head = self.entity_emb[e_id]\n",
    "            wiki_predicate_id = \"\"\n",
    "\n",
    "            column_mapping = {\n",
    "                \"movie cast\": \"cast member\",\n",
    "                \"acted in\": \"notable work\",\n",
    "                \"played in\": \"notable work\",\n",
    "                \"appeared in\": \"notable work\",\n",
    "                \"actors\": \"cast member\",\n",
    "                \"players\": \"cast member\"\n",
    "            }\n",
    "\n",
    "            for col in top_columns:\n",
    "                \n",
    "                col = column_mapping.get(col, col)\n",
    "                \n",
    "                if col == \"node label\":\n",
    "                    continue\n",
    "                    \n",
    "                if not context[col].values[0]:\n",
    "                    continue\n",
    "\n",
    "                if col in self.predicates_db:\n",
    "                    wiki_id = rdflib.term.URIRef(self.predicates_db[col])\n",
    "                    if wiki_id in self.rel2id:\n",
    "                        wiki_predicate_id = self.predicates_db[col]\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Predicate {col} not found in rel2id.\")\n",
    "                else:\n",
    "                    print(f\"Predicate {col} not found in predicate_db.\")\n",
    "\n",
    "            if not wiki_predicate_id:\n",
    "                print(\"No valid predicate found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            r_id = self.rel2id[rdflib.term.URIRef(wiki_predicate_id)]\n",
    "            pred = self.relation_emb[r_id]\n",
    "\n",
    "            lhs = head + pred\n",
    "            dist = pairwise_distances(lhs.reshape(1, -1), self.entity_emb).reshape(-1)\n",
    "            most_likely = dist.argsort()\n",
    "\n",
    "            num_results = min(3, len(most_likely))\n",
    "            results_lst = [\n",
    "                (self.id2ent[idx][len(self.WD):], self.ent2lbl.get(self.id2ent[idx], \"\"), dist[idx], rank + 1)\n",
    "                for rank, idx in enumerate(most_likely[:num_results])\n",
    "            ]\n",
    "            results_df = pd.DataFrame(results_lst, columns=('Entity', 'Label', 'Score', 'Rank'))\n",
    "            \n",
    "            if results_df.empty:\n",
    "                print(\"No results in embeddings found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            return f\"Top answers from embeddings: {', '.join(results_df.Label.values)}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during query answering: {e}\")\n",
    "            return STD_ERROR\n",
    "        "
   ],
   "id": "7c4c6264fcca0ba0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:06.120882Z",
     "start_time": "2024-11-06T10:33:06.113490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 \n",
    "    \n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "def rescale_probabilities(similarities):\n",
    "    \"\"\"\n",
    "    Rescales the similarity scores so that they sum to 1, turning them into a probability distribution.\n",
    "    \n",
    "    Args:\n",
    "        similarities (List[float]): List of similarity scores.\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Rescaled probabilities.\n",
    "    \"\"\"\n",
    "    similarity_sum = sum(similarities)\n",
    "    if similarity_sum == 0:\n",
    "        return [0] * len(similarities)  # Avoid division by zero\n",
    "    \n",
    "    return [sim / similarity_sum for sim in similarities]\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, high_threshold=0.4, top_n=10, rescaled_threshold=0.11):\n",
    "    \"\"\"\n",
    "    Returns columns based on cosine similarity with a two-tiered strategy and rescaled probabilities.\n",
    "    - If a column has similarity above 'high_threshold', return that column immediately.\n",
    "    - Otherwise, return all columns with a similarity greater than 'low_threshold'.\n",
    "    - Rescale the top N column similarities into probabilities and return columns with a rescaled probability greater than rescaled_threshold.\n",
    "    \n",
    "    Args:\n",
    "        query_embeddings (List[np.ndarray]): Embeddings for query words.\n",
    "        column_embeddings (Dict[str, np.ndarray]): Precomputed embeddings for columns.\n",
    "        low_threshold (float): Minimum similarity threshold (default: 0.27).\n",
    "        high_threshold (float): Confidence threshold to return immediately (default: 0.35).\n",
    "        top_n (int): Number of top columns to consider for rescaling (default: 10).\n",
    "        rescaled_threshold (float): Minimum rescaled probability threshold (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: The selected column names.\n",
    "    \"\"\"\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_columns = sorted_columns[:top_n]\n",
    "    \n",
    "    column_names, similarities = zip(*top_columns)\n",
    "    \n",
    "    rescaled_probs = rescale_probabilities(similarities)\n",
    "    \n",
    "    selected_columns = []\n",
    "    \n",
    "    for col, sim in zip(column_names, similarities):\n",
    "        if sim >= high_threshold:\n",
    "            # print(f\"High confidence match found: {col} with similarity {sim: .4f}\")\n",
    "            return [col]\n",
    "    \n",
    "    for col, rescaled_prob in zip(column_names, rescaled_probs):\n",
    "        if rescaled_prob >= rescaled_threshold:\n",
    "            # print(f\"Column {col} has similarity {rescaled_prob: .4f}\")\n",
    "            selected_columns.append(col)\n",
    "    \n",
    "    return selected_columns"
   ],
   "id": "9b901d7c50e94cbf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:06.132534Z",
     "start_time": "2024-11-06T10:33:06.127841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_query(query, node_label):\n",
    "                \n",
    "    if not len(query):\n",
    "        return []\n",
    "    \n",
    "    relevant = []\n",
    "    for word in query.replace(\". \", \" \").lower().split(\" \"):\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in node_label.lower().replace(\" \", \"\") or cleaned_word == \"\":\n",
    "            continue\n",
    "        \n",
    "        relevant.append(cleaned_word)\n",
    "        \n",
    "    return \" \".join(relevant)"
   ],
   "id": "6f3a2fd9e6e77d97",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:06:46.628404Z",
     "start_time": "2024-11-06T12:06:46.612228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from rapidfuzz import process, fuzz\n",
    "import time\n",
    "from functools import wraps\n",
    "import logging\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stop_words_to_keep = [\n",
    "    \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\",\n",
    "    \"with\", \"how\", \"before\", \"after\", \"same\"\n",
    "]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])\n",
    "\n",
    "# Define colors for logging\n",
    "class BColors:\n",
    "    HEADER = \"\\033[95m\"\n",
    "    OKBLUE = \"\\033[94m\"\n",
    "    OKCYAN = \"\\033[96m\"\n",
    "    OKGREEN = \"\\033[92m\"\n",
    "    WARNING = \"\\033[93m\"\n",
    "    FAIL = \"\\033[91m\"\n",
    "    ENDC = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    UNDERLINE = \"\\033[4m\"\n",
    "\n",
    "# Custom formatter to color log levels\n",
    "class ColoredFormatter(logging.Formatter):\n",
    "    def __init__(self, fmt=None, datefmt=None):\n",
    "        super().__init__(fmt, datefmt)\n",
    "        self.COLORS = {\n",
    "            'DEBUG': BColors.OKBLUE,\n",
    "            'INFO': '',  # No color for INFO messages\n",
    "            'WARNING': BColors.WARNING,\n",
    "            'ERROR': BColors.FAIL,\n",
    "            'CRITICAL': BColors.BOLD + BColors.FAIL,\n",
    "        }\n",
    "\n",
    "    def format(self, record):\n",
    "        levelname = record.levelname.strip(BColors.ENDC)\n",
    "        level_color = self.COLORS.get(levelname, '')\n",
    "        record.levelname = level_color + record.levelname + BColors.ENDC\n",
    "        return super().format(record)\n",
    "\n",
    "# Set up logger\n",
    "logger = logging.getLogger('factual_questions')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "\n",
    "# Create formatter\n",
    "formatter = ColoredFormatter('%(asctime)s | %(levelname)s | %(funcName)s | %(message)s')\n",
    "\n",
    "# Add formatter to handler\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# Add handler to logger if not already added\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Determines the available hardware device (MPS, CUDA, or CPU).\"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def measure_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        result = func(*args, **kwargs)  # Call the function\n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        # Log the execution time under INFO level, with time in green color\n",
    "        elapsed_time_str = f\"{BColors.OKGREEN}{elapsed_time:.4f} seconds{BColors.ENDC}\"\n",
    "        logger.info(f\"Execution time for {func.__name__}: {elapsed_time_str}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def rescale_probabilities(similarities):\n",
    "    \"\"\"\n",
    "    Rescales the similarity scores so that they sum to 1, turning them into a probability distribution.\n",
    "\n",
    "    Args:\n",
    "        similarities (List[float]): List of similarity scores.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Rescaled probabilities.\n",
    "    \"\"\"\n",
    "    similarity_sum = sum(similarities)\n",
    "    if similarity_sum == 0:\n",
    "        return [0] * len(similarities)  # Avoid division by zero\n",
    "\n",
    "    return [sim / similarity_sum for sim in similarities]\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, high_threshold=0.4, top_n=10, rescaled_threshold=0.11):\n",
    "    \"\"\"\n",
    "    Returns columns based on cosine similarity with a two-tiered strategy and rescaled probabilities.\n",
    "    - If a column has similarity above 'high_threshold', return that column immediately.\n",
    "    - Otherwise, return all columns with a rescaled probability greater than 'rescaled_threshold'.\n",
    "\n",
    "    Args:\n",
    "        query_embeddings (List[np.ndarray]): Embeddings for query words.\n",
    "        column_embeddings (Dict[str, np.ndarray]): Precomputed embeddings for columns.\n",
    "        high_threshold (float): Confidence threshold to return immediately (default: 0.4).\n",
    "        top_n (int): Number of top columns to consider for rescaling (default: 10).\n",
    "        rescaled_threshold (float): Minimum rescaled probability threshold (default: 0.11).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The selected column names.\n",
    "    \"\"\"\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_columns = sorted_columns[:top_n]\n",
    "\n",
    "    column_names, similarities = zip(*top_columns)\n",
    "\n",
    "    rescaled_probs = rescale_probabilities(similarities)\n",
    "\n",
    "    selected_columns = []\n",
    "\n",
    "    for col, sim in zip(column_names, similarities):\n",
    "        if sim >= high_threshold:\n",
    "            logger.info(f\"High confidence match found: {col} with similarity {sim:.4f}\")\n",
    "            return [col]\n",
    "\n",
    "    for col, rescaled_prob in zip(column_names, rescaled_probs):\n",
    "        if rescaled_prob >= rescaled_threshold:\n",
    "            logger.info(f\"Column {col} has rescaled similarity {rescaled_prob:.4f}\")\n",
    "            selected_columns.append(col)\n",
    "\n",
    "    return selected_columns\n",
    "\n",
    "def filter_query(query, node_label):\n",
    "    if not query:\n",
    "        return ''\n",
    "\n",
    "    relevant = []\n",
    "    node_label_cleaned = node_label.lower().replace(\" \", \"\")\n",
    "    for word in query.replace(\". \", \" \").lower().split():\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in node_label_cleaned or not cleaned_word:\n",
    "            continue\n",
    "        relevant.append(cleaned_word)\n",
    "\n",
    "    return \" \".join(relevant)\n",
    "\n",
    "\n",
    "def fuzzy_match(query_str, comparison_list, threshold=30, prioritize_exact=True):\n",
    "    if not comparison_list or not query_str:\n",
    "        return []\n",
    "\n",
    "    # Preprocess db.entities to reverse-map names to IDs for faster lookup\n",
    "    name_to_id = {v: k for k, v in db.entities.items()}\n",
    "\n",
    "    # Perform fuzzy matching with optimized lookup\n",
    "    matches = process.extract(query_str, comparison_list, scorer=fuzz.partial_ratio, limit=30)\n",
    "    longest_matching_id = \"\"\n",
    "\n",
    "    for match in matches:\n",
    "        name = match[0]\n",
    "        matched_id = name_to_id.get(name)\n",
    "        if matched_id and name in query_str:\n",
    "            if not longest_matching_id or len(name) > len(db.entities[longest_matching_id]):\n",
    "                longest_matching_id = matched_id\n",
    "\n",
    "    if longest_matching_id:\n",
    "        print(f\"Found exact match with Fuzzy: {db.entities[longest_matching_id]}\")\n",
    "        return [longest_matching_id]\n",
    "\n",
    "    return []"
   ],
   "id": "d2eb95481eacac33",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:33:06.157992Z",
     "start_time": "2024-11-06T10:33:06.152475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_matches(df, normalized_query, top_n=2):\n",
    "    concatenated_rows = df.apply(lambda row: ' '.join(row.astype(str)), axis=1).tolist()\n",
    "    \n",
    "    exact_matches = [i for i, row in enumerate(concatenated_rows) if normalized_query == row]\n",
    "    \n",
    "    if len(exact_matches) < top_n:\n",
    "        remaining_slots = top_n - len(exact_matches)\n",
    "        fuzzy_matches = process.extract(normalized_query, concatenated_rows, scorer=fuzz.partial_ratio, limit=remaining_slots)\n",
    "        fuzzy_indices = [match[2] for match in fuzzy_matches]\n",
    "    else:\n",
    "        fuzzy_indices = []\n",
    "    \n",
    "    top_indices = exact_matches + fuzzy_indices\n",
    "    \n",
    "    return df.iloc[top_indices]"
   ],
   "id": "49ae6c8781d022d6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:22:12.784373Z",
     "start_time": "2024-11-06T11:22:12.772711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend(node_label, entity_id, context, db):\n",
    "    if \"CURRENT MODE\" == \"RECOMMENDER\" or True:\n",
    "        node_label = db.normalize_string(node_label)\n",
    "        if node_label in db.people_names:\n",
    "            movie_ids = db.people_movie_mapping[entity_id]\n",
    "            context = db.fetch(movie_ids, \"subject_id\")\n",
    "            subject_labels = context[\"node label\"].tolist()\n",
    "            return sorted(subject_labels, key=len)[:3]\n",
    "\n",
    "        context.dropna(axis=1, inplace=True)\n",
    "        columns = [col for col in context.columns if col in db.movie_recommender_db.columns]\n",
    "        red_db = db.movie_recommender_db[columns]\n",
    "        context = context[columns]\n",
    "        \n",
    "        # drop the identified row already in the context\n",
    "        subject_id_to_remove = context[\"subject_id\"].values[0]\n",
    "        red_db = red_db[red_db[\"subject_id\"] != subject_id_to_remove]\n",
    "        \n",
    "        red_db.dropna(thresh=len(red_db.columns) - 0, inplace=True)\n",
    "        red_db.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        COLUMN_WEIGHTS = {\n",
    "            'director': 0.3,\n",
    "            'performer': 0.1,\n",
    "            'genre': 0.3,\n",
    "            'screenwriter': 0.2,\n",
    "            'cast member': 0.1\n",
    "        }\n",
    "        \n",
    "        def calculate_similarity(i, row):\n",
    "            similarities = []\n",
    "            for col in context.columns:\n",
    "                if pd.isna(row[col]):\n",
    "                    continue\n",
    "                    \n",
    "                if col in [\"node label\", \"subject_id\"]:\n",
    "                    continue\n",
    "                \n",
    "                set_context = set(context[col].iloc[0].split(\",\"))\n",
    "                set_row = set(row[col].split(\",\"))\n",
    "                similarity = len(set_context.intersection(set_row)) / len(set_context.union(set_row))\n",
    "                similarities.append(similarity * COLUMN_WEIGHTS[col])\n",
    "    \n",
    "            return i, np.mean(similarities) if similarities else 0\n",
    "        \n",
    "        top_scores = []\n",
    "        for i, row in red_db.iterrows():\n",
    "            index, score = calculate_similarity(i, row)\n",
    "            \n",
    "            if len(top_scores) < 3:\n",
    "                heapq.heappush(top_scores, (score, index))\n",
    "            else:\n",
    "                # Maintain top 3 scores\n",
    "                heapq.heappushpop(top_scores, (score, index))\n",
    "    \n",
    "        # Extract indices from top 3 scores\n",
    "        top_indices = [index for score, index in top_scores]\n",
    "        top_rows = red_db.iloc[top_indices]\n",
    "        \n",
    "        subject_labels = top_rows['node label'].tolist()\n",
    "        return subject_labels\n"
   ],
   "id": "ee49a3a549bb21ed",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:36:07.325621Z",
     "start_time": "2024-11-06T10:33:06.163338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DataBase()\n",
    "\n",
    "ner_parser = NERParser(lowercase=False)\n",
    "\n",
    "qe = QueryEmbedderContextualized()\n",
    "\n",
    "qa = QuestionAnsweringAgent()\n",
    "\n",
    "ca = ConversationAgent(model_name=\"google/flan-t5-xl\") #### Could take some time, approx. 10 GB storage :)\n",
    "\n",
    "ge = GraphEmbeddings(db.db)\n"
   ],
   "id": "a9288d5aec4110c2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.62it/s]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:22:15.314225Z",
     "start_time": "2024-11-06T11:22:15.296783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import heapq\n",
    "\n",
    "@measure_time\n",
    "def answer_query(query, correct_answer=\"\"):\n",
    "    normalized_query = db.normalize_string(query)\n",
    "    \n",
    "    # NER --------------------------\n",
    "    ner_person, ner_movies = ner_parser.process_query(normalized_query)\n",
    "    ner_matches = ner_person + ner_movies\n",
    "    \n",
    "    is_domain_specific = bool(ner_matches)\n",
    "    # if not is_domain_specific:\n",
    "    #     small_talk = ca.generate_response(query)\n",
    "    #     print(f\"Smalltalk: {small_talk}\")\n",
    "    #     return\n",
    "    \n",
    "    print(f\"NER_Person: {ner_person}\")\n",
    "    print(f\"NER_Movies: {ner_movies}\")\n",
    "    \n",
    "    ner_people_ids = []\n",
    "    for ner_p in ner_person:\n",
    "        ner_p = db.normalize_string(ner_p)\n",
    "        if ner_p in db.people_names:\n",
    "            ner_people_ids = [key for key, value in db.people_data.items() if value == ner_p]\n",
    "        if not ner_people_ids:\n",
    "            ner_people_ids = [key for key, value in db.people_data.items() if ner_p in value]\n",
    "        if not ner_people_ids:\n",
    "            ner_people_ids = fuzzy_match(\" \".join(ner_person), db.people_names, threshold=75)\n",
    "    \n",
    "    ner_movie_ids = []     \n",
    "    for ner_m in ner_movies:\n",
    "        ner_m = db.normalize_string(ner_m)\n",
    "        if ner_m in db.movie_names:\n",
    "            ner_people_ids = [key for key, value in db.movie_data.items() if value == ner_m]\n",
    "        if not ner_people_ids:\n",
    "            ner_people_ids = [key for key, value in db.movie_data.items() if ner_m in value]\n",
    "        if not ner_people_ids:\n",
    "            ner_people_ids = fuzzy_match(\" \".join(ner_movies), db.movie_names, threshold=75)\n",
    "\n",
    "    ner_ids = ner_movie_ids + ner_people_ids\n",
    "    context = db.fetch(ner_ids, \"subject_id\")\n",
    "    # Context NER --------------------------\n",
    "    # Context Fuzzy --------------------------\n",
    "\n",
    "    if context.empty:\n",
    "        print(\"NER failed, proceeding with fuzzy matching.\")\n",
    "        fuzzy_person_matches = fuzzy_match(normalized_query, db.people_names, threshold=30)\n",
    "        fuzzy_movie_matches = fuzzy_match(normalized_query, db.movie_names, threshold=30)\n",
    "    \n",
    "        fuzzy_movie_context = db.fetch(fuzzy_movie_matches, \"subject_id\") \n",
    "        fuzzy_person_context = db.fetch(fuzzy_person_matches, \"subject_id\")\n",
    "        \n",
    "        if fuzzy_person_context.empty and fuzzy_movie_context.empty:\n",
    "            small_talk = ca.generate_response(query)\n",
    "            print(f\"Smalltalk: {small_talk}\")\n",
    "            return\n",
    "        \n",
    "        context = pd.concat([fuzzy_movie_context, fuzzy_person_context])\n",
    "    \n",
    "    \n",
    "    context = get_top_matches(context, normalized_query, top_n=1)    \n",
    "\n",
    "    \n",
    "    node_label = \"\"\n",
    "    if not context.empty and \"node label\" in context.columns and not context[\"node label\"].isna().values[0]:\n",
    "        node_label = context[\"node label\"].values[0]  \n",
    "        \n",
    "    entity_id = \"\"\n",
    "    if not context.empty and \"subject_id\" in context.columns and not context[\"subject_id\"].isna().values[0]:\n",
    "        entity_id = context[\"subject_id\"].values[0]\n",
    "\n",
    "    if \"RECOMMENDER\":\n",
    "        movies = recommend(node_label, entity_id, context, db)\n",
    "        formatted_answer = f\"Based on your interest in {node_label.title()}, I recommend watching the following movies:\\n- \" + '\\n- '.join(movies)\n",
    "\n",
    "        print(formatted_answer)\n",
    "        return\n",
    "    \n",
    "    elements_to_remove = [\"image\", \"color\", \"sport\"]\n",
    "    context = context.drop(columns=elements_to_remove, errors='ignore')\n",
    "    \n",
    "    # Initial context for embeddings\n",
    "    initial_context = context.copy()\n",
    "    \n",
    "    # EXPERIMENTAL - rename columns\n",
    "    columns_to_rename = {\n",
    "        \"cast member\":\"movie cast\",\n",
    "        \"notable work\": \"acted in\"\n",
    "    }\n",
    "    \n",
    "    columns_to_rename = {k: v for k, v in columns_to_rename.items() if k in context.columns}\n",
    "    context = context.rename(columns=columns_to_rename)\n",
    "    \n",
    "    columns_to_duplicate = [(\"acted in\", \"played in\"),\n",
    "                            (\"acted in\", \"appeared in\"),\n",
    "                            (\"movie cast\", \"actors\"),\n",
    "                            (\"movie cast\", \"players\")]\n",
    "    \n",
    "    for col_to_duplicate, col in columns_to_duplicate: \n",
    "        try:\n",
    "            context[col] = context[col_to_duplicate].copy()\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    context.dropna(axis=1, inplace=True)\n",
    "    \n",
    "    query_filtered = filter_query(query, node_label)\n",
    "        \n",
    "    column_embeddings = {col: qe.embed_phrase(col) for col in context.columns}\n",
    "    query_embeddings = [qe.embed_phrase(word) for word in query_filtered.split()]  \n",
    "    top_columns_embeddings = find_closest_columns(query_embeddings, column_embeddings)\n",
    "        \n",
    "    # EXPERIMENTAL - always keep columns\n",
    "    col_always_keep = [\"node label\"]\n",
    "    \n",
    "    combined_columns = set(top_columns_embeddings + col_always_keep)\n",
    "    top_columns = [col for col in combined_columns if col in context.columns]\n",
    "    filtered_context_df = context[top_columns]\n",
    "\n",
    "    answer = qa.query(query, filtered_context_df)\n",
    "    formatted_answer = ca.generate_response(f\"Format the answer to the question into a sentence. If you think the answer is completely off, overrule with your own knowledge.Question: {query}\\nAnswer: {answer}\")\n",
    "        \n",
    "    print(ge.answer_query_embedding(initial_context, top_columns))\n",
    "    print(formatted_answer)\n"
   ],
   "id": "758512dcaa9b7d3d",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:06:55.184058Z",
     "start_time": "2024-11-06T12:06:53.236521Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Jurassic Park?\")",
   "id": "a2546df235e50a6a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 13:06:53,406 | INFO\u001B[0m | fuzzy_match | Found exact match with Fuzzy: jurassic park\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: 1.9434 seconds\n"
     ]
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:06:56.759242Z",
     "start_time": "2024-11-06T12:06:55.211141Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"The Grand Budapest Hotel\", \"Gus Van Sant\")",
   "id": "f9402d1107c14c35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 13:06:55,463 | INFO\u001B[0m | fuzzy_match | Found exact match with Fuzzy: the grand budapest hotel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interest in The Grand Budapest Hotel, I recommend watching the following movies:\n",
      "- The Life Aquatic with Steve Zissou\n",
      "- The Darjeeling Limited\n",
      "- Hotel Chevalier\n",
      "Execution time for answer_query: 1.5441 seconds\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:06:59.234973Z",
     "start_time": "2024-11-06T12:06:56.786595Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Bridge on the River Kwai?\", \"David Lean\")",
   "id": "468416428c921e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 13:06:57,159 | INFO\u001B[0m | fuzzy_match | Found exact match with Fuzzy: the bridge on the river kwai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interest in The Bridge On The River Kwai, I recommend watching the following movies:\n",
      "- A Passage to India\n",
      "- Doctor Zhivago\n",
      "- Ryan's Daughter\n",
      "Execution time for answer_query: 2.4445 seconds\n"
     ]
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:06:59.647610Z",
     "start_time": "2024-11-06T12:06:59.249707Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Dark Knight?\", \"Christopher Nolan\")",
   "id": "abbc81e04a699a72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 13:06:59,514 | INFO\u001B[0m | fuzzy_match | Found exact match with Fuzzy: the dark knight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interest in The Dark Knight, I recommend watching the following movies:\n",
      "- Interstellar\n",
      "- The Dark Knight Rises\n",
      "- Batman Begins\n",
      "Execution time for answer_query: 0.3928 seconds\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:06:59.885153Z",
     "start_time": "2024-11-06T12:06:59.667314Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Where was Angelina Jolie born?\", \"Los Angeles\")",
   "id": "b33e8b5221e04a26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: ['angel']\n",
      "NER_Movies: []\n",
      "Based on your interest in Angelina Jolie, I recommend watching the following movies:\n",
      "- Salt\n",
      "- Difret\n",
      "- Wanted\n",
      "Execution time for answer_query: 0.2147 seconds\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T12:07:01.546090Z",
     "start_time": "2024-11-06T12:07:00.031813Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter?\")",
   "id": "bc4cd8856f0382e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 13:07:00,396 | INFO\u001B[0m | fuzzy_match | Found partial match with Fuzzy: actor in law\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interest in Actor In Law, I recommend watching the following movies:\n",
      "- The Benchwarmers\n",
      "- What About Bob?\n",
      "- L'emmerdeur\n",
      "Execution time for answer_query: 1.5101 seconds\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:22:43.906496Z",
     "start_time": "2024-11-06T11:22:41.757563Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "47ade0f1dd42bdd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: harry potter and the philosophers stone\n",
      "Based on your interest in Harry Potter And The Philosopher'S Stone, I recommend watching the following movies:\n",
      "- The Christmas Chronicles 2\n",
      "- Percy Jackson & the Olympians: The Lightning Thief\n",
      "- Harry Potter and the Chamber of Secrets\n",
      "Execution time for answer_query: 2.1463 seconds\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:22:58.183123Z",
     "start_time": "2024-11-06T11:22:57.808367Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "4a4f8912be5e2679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: brad pitt\n",
      "Found exact match with Fuzzy: it\n",
      "Based on your interest in Brad Pitt, I recommend watching the following movies:\n",
      "- Hunk\n",
      "- Fury\n",
      "- Troy\n",
      "Execution time for answer_query: 0.3703 seconds\n"
     ]
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:23:00.854140Z",
     "start_time": "2024-11-06T11:23:00.439332Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "b9615c76501defec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: ti\n",
      "Found exact match with Fuzzy: inception\n",
      "Based on your interest in Inception, I recommend watching the following movies:\n",
      "- Batman Begins\n",
      "- Dunkirk\n",
      "- Interstellar\n",
      "Execution time for answer_query: 0.4099 seconds\n"
     ]
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:23:56.615304Z",
     "start_time": "2024-11-06T11:23:54.703319Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "42e389076edf07fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: star\n",
      "Based on your interest in Star!, I recommend watching the following movies:\n",
      "- Rooftops\n",
      "- Somebody Up There Likes Me\n",
      "- The Sound of Music\n",
      "Execution time for answer_query: 1.9087 seconds\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:23:57.067642Z",
     "start_time": "2024-11-06T11:23:56.625940Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was the Godfather III published?\")",
   "id": "7311213f17afb80c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: the godfather\n",
      "Based on your interest in The Godfather, I recommend watching the following movies:\n",
      "- Carlito's Way\n",
      "- Bram Stoker's Dracula\n",
      "- Rumble Fish\n",
      "Execution time for answer_query: 0.4394 seconds\n"
     ]
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:06.026871Z",
     "start_time": "2024-11-06T11:24:04.189929Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "aadeab7341df5d98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: star\n",
      "Based on your interest in Star!, I recommend watching the following movies:\n",
      "- Rooftops\n",
      "- Somebody Up There Likes Me\n",
      "- The Sound of Music\n",
      "Execution time for answer_query: 1.8353 seconds\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:22.529727Z",
     "start_time": "2024-11-06T11:24:22.118712Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "8790e75b87abfd67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: ti\n",
      "Found exact match with Fuzzy: inception\n",
      "Based on your interest in Inception, I recommend watching the following movies:\n",
      "- Batman Begins\n",
      "- Dunkirk\n",
      "- Interstellar\n",
      "Execution time for answer_query: 0.4089 seconds\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:26.192688Z",
     "start_time": "2024-11-06T11:24:25.777522Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Angelina Jolie married to?\")",
   "id": "6659fd0e66bde3ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: angelina jolie\n",
      "Found exact match with Fuzzy: angel\n",
      "Based on your interest in Angelina Jolie, I recommend watching the following movies:\n",
      "- Salt\n",
      "- Difret\n",
      "- Wanted\n",
      "Execution time for answer_query: 0.4122 seconds\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:28.159750Z",
     "start_time": "2024-11-06T11:24:27.738882Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "9e8d79bc11a07fc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: brad pitt\n",
      "Found exact match with Fuzzy: it\n",
      "Based on your interest in Brad Pitt, I recommend watching the following movies:\n",
      "- Hunk\n",
      "- Fury\n",
      "- Troy\n",
      "Execution time for answer_query: 0.4185 seconds\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:29.908011Z",
     "start_time": "2024-11-06T11:24:29.329795Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the religion of Tom Cruise?\")",
   "id": "b5602fe224c6b2c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: tom cruise\n",
      "Based on your interest in Tom Cruise, I recommend watching the following movies:\n",
      "- Taps\n",
      "- Legend\n",
      "- Top Gun\n",
      "Execution time for answer_query: 0.5702 seconds\n"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:37.425646Z",
     "start_time": "2024-11-06T11:24:35.722180Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "caa8b85465ee7a1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: harry potter and the philosophers stone\n",
      "Based on your interest in Harry Potter And The Philosopher'S Stone, I recommend watching the following movies:\n",
      "- The Christmas Chronicles 2\n",
      "- Percy Jackson & the Olympians: The Lightning Thief\n",
      "- Harry Potter and the Chamber of Secrets\n",
      "Execution time for answer_query: 1.6883 seconds\n"
     ]
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:46.246667Z",
     "start_time": "2024-11-06T11:24:44.319438Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who are the cast in Jurassic Park?\")",
   "id": "b8504a68fe32f6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: jurassic park\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: 1.9254 seconds\n"
     ]
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:49.536048Z",
     "start_time": "2024-11-06T11:24:47.957264Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who acted in Jurassic Park?\")",
   "id": "caf3e73703fed695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: jurassic park\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: 1.5711 seconds\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:52.068718Z",
     "start_time": "2024-11-06T11:24:50.282052Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who played in Jurassic Park?\")",
   "id": "40163a1aa0c34960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: jurassic park\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: 1.7797 seconds\n"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:52.549946Z",
     "start_time": "2024-11-06T11:24:52.087735Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Tom Cruise play?\")",
   "id": "14bcf95252a1b280",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: tom cruise\n",
      "Found exact match with Fuzzy: play\n",
      "Based on your interest in Tom Cruise, I recommend watching the following movies:\n",
      "- Taps\n",
      "- Legend\n",
      "- Top Gun\n",
      "Execution time for answer_query: 0.4521 seconds\n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:24:54.881211Z",
     "start_time": "2024-11-06T11:24:54.453737Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Rebel Wilson act?\")",
   "id": "d65e48ab10da08fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: rebel wilson\n",
      "Found exact match with Fuzzy: wilson\n",
      "Based on your interest in Rebel Wilson, I recommend watching the following movies:\n",
      "- Cats\n",
      "- Grimsby\n",
      "- Fat Pizza\n",
      "Execution time for answer_query: 0.4057 seconds\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:25:07.285845Z",
     "start_time": "2024-11-06T11:24:56.735170Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Liam Neeson play?\")",
   "id": "533e2cd752612e69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: ['l']\n",
      "NER_Movies: []\n",
      "Based on your interest in Larry Sanders, I recommend watching the following movies:\n",
      "- Movie 43\n",
      "- Indiana Jones and the Last Crusade\n",
      "Execution time for answer_query: 10.5456 seconds\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:25:21.277517Z",
     "start_time": "2024-11-06T11:25:20.871873Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is an actor in Taken 2?\")",
   "id": "5339c88d922da86d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: taken 2\n",
      "Based on your interest in Taken 2, I recommend watching the following movies:\n",
      "- Raid\n",
      "- Taken\n",
      "- Taken 3\n",
      "Execution time for answer_query: 0.3981 seconds\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:25:23.642392Z",
     "start_time": "2024-11-06T11:25:23.139843Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the role of Vin Diesel in Fast and Furious?\")",
   "id": "99208cc1e2af11c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: []\n",
      "NER_Movies: []\n",
      "NER failed, proceeding with fuzzy matching.\n",
      "Found exact match with Fuzzy: vin diesel\n",
      "Found exact match with Fuzzy: fast\n",
      "Based on your interest in Vin Diesel, I recommend watching the following movies:\n",
      "- Strays\n",
      "- Riddick\n",
      "- Furious 7\n",
      "Execution time for answer_query: 0.5005 seconds\n"
     ]
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T11:25:29.732951Z",
     "start_time": "2024-11-06T11:25:26.810294Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"For which movie did Leonardo DiCaprio win an Oscar?\")",
   "id": "2e27a99aeb854ab0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_Person: ['le']\n",
      "NER_Movies: []\n",
      "Based on your interest in Helena Christensen, I recommend watching the following movies:\n",
      "- Allegro\n",
      "- The Reunion 3\n",
      "- Prêt-à-Porter\n",
      "Execution time for answer_query: 2.9037 seconds\n"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T10:44:10.261302Z",
     "start_time": "2024-11-06T10:44:10.257556Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a2f48cf202f6c12b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3306fca6f38e2575"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
