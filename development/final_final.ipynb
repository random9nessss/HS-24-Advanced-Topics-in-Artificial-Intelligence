{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:44.333691Z",
     "start_time": "2024-10-27T14:46:44.329824Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration\n",
    ")\n",
    "\n",
    "from transformers import logging as transformers_logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "transformers_logging.set_verbosity_error()\n",
    "import json\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "# Silencing TqdmWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:44.835081Z",
     "start_time": "2024-10-27T14:46:44.831874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_to_keep = [\"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"with\", \"how\", \"before\", \"after\",\"same\"]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])"
   ],
   "id": "9ce915e61e55399c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kevinbrundler/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:45.770936Z",
     "start_time": "2024-10-27T14:46:45.768560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def measure_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        result = func(*args, **kwargs)  # Call the function\n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(f\"Execution time for {func.__name__}: {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ],
   "id": "987d727174eaa4ee",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:46.347990Z",
     "start_time": "2024-10-27T14:46:46.344785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NERParser:\n",
    "    def __init__(self, model_name=\"dslim/bert-base-NER\", lowercase=False):\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "\n",
    "        self.nlp_pipeline = pipeline(\n",
    "            \"ner\", \n",
    "            model=AutoModelForTokenClassification.from_pretrained(model_name),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_name, do_lower_case=lowercase),\n",
    "            device=self.device, \n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "\n",
    "    def get_device(self):\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def parse_ner_results(self, ner_results):\n",
    "        per_entities = [e['word'] for e in ner_results if e['entity_group'] == 'PER']\n",
    "        misc_entities = [e['word'] for e in ner_results if e['entity_group'] == 'MISC']\n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    def process_query(self, query):\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        return self.parse_ner_results(self.nlp_pipeline(query))\n",
    "\n"
   ],
   "id": "a15b5f4fab282289",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:46.788284Z",
     "start_time": "2024-10-27T14:46:46.784715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataBase:\n",
    "    \"\"\"Handles context data extraction for people and movies from a database with fuzzy matching support.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.db = pd.read_pickle(os.path.join(os.getcwd(), \"exports/extended_graph_triples.pkl\"))\n",
    "        \n",
    "        with open(\"exports/entity_db.json\", encoding=\"utf-8\") as f:\n",
    "            self.entities = json.load(f)\n",
    "            self.entity_list = [subject.lower() for subject, _ in self.entities.values()]\n",
    "\n",
    "        self.db['subject_id'] = self.db['subject_id'].astype(str).str.strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_string(s):\n",
    "        \"\"\"Normalizes strings by removing non-ASCII characters, punctuation, and redundant spaces.\"\"\"\n",
    "        return ' '.join(re.sub(r'[^\\w\\s]', '', unicodedata.normalize('NFKD', s.lower())\n",
    "                               .encode('ascii', 'ignore').decode('utf-8')).split())\n",
    "\n",
    "    def fetch(self, entity_list, search_column):\n",
    "        \"\"\"Fetches relevant rows from the database where `search_column` matches values in `entity_list`.\"\"\"\n",
    "        relevant = self.db[self.db[search_column].isin(entity_list)].dropna(axis=1)\n",
    "        \n",
    "        if relevant.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        return relevant.pivot_table(\n",
    "            index='subject_id',\n",
    "            columns='predicate_label',\n",
    "            values='object_label',\n",
    "            aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "        ).reset_index()\n"
   ],
   "id": "c9bf6d33ae34d781",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:47.153728Z",
     "start_time": "2024-10-27T14:46:47.149906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QueryEmbedderContextualized:\n",
    "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v2'):\n",
    "        \"\"\"Initializes the QueryEmbedder with a SentenceTransformer model and device setup.\"\"\"\n",
    "        self.device = self.get_device()\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "        self.cache = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        \"\"\"Determines the available hardware device (MPS, CUDA, or CPU).\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def embed_phrase(self, phrases):\n",
    "        \"\"\"\n",
    "        Generates embeddings for given phrases using SentenceTransformer, with caching.\n",
    "\n",
    "        Args:\n",
    "            phrases (str or List[str]): Input phrase(s) to embed.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Embedding vector(s) for the input phrase(s).\n",
    "        \"\"\"\n",
    "        if isinstance(phrases, str):\n",
    "            phrases = [phrases]\n",
    "        elif not isinstance(phrases, list):\n",
    "            raise TypeError(\"Input must be a string or a list of strings.\")\n",
    "        \n",
    "        phrases_to_compute = [p for p in phrases if p not in self.cache]\n",
    "        cached_embeddings = [self.cache[p] for p in phrases if p in self.cache]\n",
    "\n",
    "        if phrases_to_compute:\n",
    "            new_embeddings = self.model.encode(\n",
    "                phrases_to_compute, \n",
    "                show_progress_bar=False, \n",
    "                convert_to_numpy=True, \n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            \n",
    "            for phrase, emb in zip(phrases_to_compute, new_embeddings):\n",
    "                self.cache[phrase] = emb\n",
    "            cached_embeddings.extend(new_embeddings)\n",
    "        \n",
    "        return cached_embeddings[0] if len(cached_embeddings) == 1 else np.array(cached_embeddings)\n"
   ],
   "id": "b6108d2c6628d7db",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:47.544731Z",
     "start_time": "2024-10-27T14:46:47.541205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QuestionAnsweringAgent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.qa_model = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\", top_k=1)\n",
    "    \n",
    "    def query(self, query, context_df):\n",
    "        \n",
    "        top_columns = context_df.columns\n",
    "        \n",
    "        context = \"\"\n",
    "        for index, row in context_df.iterrows():\n",
    "            node_label = row.get(\"node label\", \"\")\n",
    "            \n",
    "            row_context = f\"This text is about \\\"{node_label}\\\":\\n\"\n",
    "            \n",
    "            for col in context_df[top_columns].columns:\n",
    "                if col == \"node label\":\n",
    "                    continue\n",
    "                \n",
    "                values = row[col]\n",
    "                values_lst = str(values).split(\",\")\n",
    "                \n",
    "                if len(values_lst) > 5:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst[:5])}\"\n",
    "                else:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst)}\"\n",
    "\n",
    "            context += row_context + \"\\n\\n\"\n",
    "        \n",
    "        output = self.qa_model(question=query, context=context)\n",
    "        \n",
    "        answer_str = str()\n",
    "        if isinstance(output, list) and output:\n",
    "            answer_str = \", \".join([result['answer'] for result in output])\n",
    "            \n",
    "        elif isinstance(output, dict):\n",
    "            answer_str = output['answer']\n",
    "        \n",
    "        if not answer_str:\n",
    "            answer_str = \"No answer found.\"\n",
    "        \n",
    "        return answer_str"
   ],
   "id": "9e2df2f00abd15da",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:47.995844Z",
     "start_time": "2024-10-27T14:46:47.992747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConversationAgent:\n",
    "    def __init__(self, model_name=\"google/flan-t5-large\", max_length=150):\n",
    "        self.device = self.get_device()\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        \"\"\"\n",
    "        Generates a response based on the given prompt.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=self.max_length,\n",
    "            num_beams=5,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response.strip()\n"
   ],
   "id": "adbe62e7f66579e2",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:48.598867Z",
     "start_time": "2024-10-27T14:46:48.594233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 \n",
    "    \n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "def rescale_probabilities(similarities):\n",
    "    \"\"\"\n",
    "    Rescales the similarity scores so that they sum to 1, turning them into a probability distribution.\n",
    "    \n",
    "    Args:\n",
    "        similarities (List[float]): List of similarity scores.\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Rescaled probabilities.\n",
    "    \"\"\"\n",
    "    similarity_sum = sum(similarities)\n",
    "    if similarity_sum == 0:\n",
    "        return [0] * len(similarities)  # Avoid division by zero\n",
    "    \n",
    "    return [sim / similarity_sum for sim in similarities]\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, high_threshold=0.4, top_n=10, rescaled_threshold=0.11):\n",
    "    \"\"\"\n",
    "    Returns columns based on cosine similarity with a two-tiered strategy and rescaled probabilities.\n",
    "    - If a column has similarity above 'high_threshold', return that column immediately.\n",
    "    - Otherwise, return all columns with a similarity greater than 'low_threshold'.\n",
    "    - Rescale the top N column similarities into probabilities and return columns with a rescaled probability greater than rescaled_threshold.\n",
    "    \n",
    "    Args:\n",
    "        query_embeddings (List[np.ndarray]): Embeddings for query words.\n",
    "        column_embeddings (Dict[str, np.ndarray]): Precomputed embeddings for columns.\n",
    "        low_threshold (float): Minimum similarity threshold (default: 0.27).\n",
    "        high_threshold (float): Confidence threshold to return immediately (default: 0.35).\n",
    "        top_n (int): Number of top columns to consider for rescaling (default: 10).\n",
    "        rescaled_threshold (float): Minimum rescaled probability threshold (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: The selected column names.\n",
    "    \"\"\"\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_columns = sorted_columns[:top_n]\n",
    "    \n",
    "    column_names, similarities = zip(*top_columns)\n",
    "    \n",
    "    rescaled_probs = rescale_probabilities(similarities)\n",
    "    \n",
    "    selected_columns = []\n",
    "    \n",
    "    for col, sim in zip(column_names, similarities):\n",
    "        if sim >= high_threshold:\n",
    "            print(f\"High confidence match found: {col} with similarity {sim: .4f}\")\n",
    "            return [col]\n",
    "    \n",
    "    for col, rescaled_prob in zip(column_names, rescaled_probs):\n",
    "        if rescaled_prob >= rescaled_threshold:\n",
    "            print(f\"Column {col} has similarity {rescaled_prob: .4f}\")\n",
    "            selected_columns.append(col)\n",
    "    \n",
    "    return selected_columns"
   ],
   "id": "9b901d7c50e94cbf",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:49.376952Z",
     "start_time": "2024-10-27T14:46:49.373977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_query(query, node_label):\n",
    "                \n",
    "    if not len(query):\n",
    "        return []\n",
    "    \n",
    "    relevant = []\n",
    "    for word in query.replace(\". \", \" \").lower().split(\" \"):\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in node_label.lower().replace(\" \", \"\") or cleaned_word == \"\":\n",
    "            continue\n",
    "        \n",
    "        relevant.append(cleaned_word)\n",
    "        \n",
    "    return \" \".join(relevant)"
   ],
   "id": "6f3a2fd9e6e77d97",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:50.270218Z",
     "start_time": "2024-10-27T14:46:50.266083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fuzzy_match(query_str, comparison_list, threshold=30, prioritize_exact=True):\n",
    "    matches = process.extract(query_str, comparison_list, scorer=fuzz.partial_ratio, limit=50)\n",
    "        \n",
    "    id_name_score = []\n",
    "    \n",
    "    if prioritize_exact and query_str in comparison_list:\n",
    "        matched_id = next(key for key, value in db.entities.items() if value[0] == query_str)\n",
    "        id_name_score.append((matched_id, query_str, 100))\n",
    "    \n",
    "    for match in matches:\n",
    "        name = match[0]\n",
    "        score = match[1]\n",
    "        matched_id = next(key for key, value in db.entities.items() if value[0] == name)\n",
    "        \n",
    "        length_diff = abs(len(name) - len(query_str)) / len(query_str)\n",
    "        adjusted_score = score * (1 - length_diff)\n",
    "        \n",
    "        id_name_score.append((matched_id, name, adjusted_score))\n",
    "    \n",
    "    return [id for id, _, score in id_name_score if score >= threshold]"
   ],
   "id": "d2eb95481eacac33",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:50.982351Z",
     "start_time": "2024-10-27T14:46:50.979528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_matches(df, normalized_query, top_n=2):\n",
    "    concatenated_rows = df.apply(lambda row: ' '.join(row.astype(str)), axis=1).tolist()\n",
    "    \n",
    "    exact_matches = [i for i, row in enumerate(concatenated_rows) if normalized_query == row]\n",
    "    \n",
    "    if len(exact_matches) < top_n:\n",
    "        remaining_slots = top_n - len(exact_matches)\n",
    "        fuzzy_matches = process.extract(normalized_query, concatenated_rows, scorer=fuzz.partial_ratio, limit=remaining_slots)\n",
    "        fuzzy_indices = [match[2] for match in fuzzy_matches]\n",
    "    else:\n",
    "        fuzzy_indices = []\n",
    "    \n",
    "    top_indices = exact_matches + fuzzy_indices\n",
    "    \n",
    "    return df.iloc[top_indices]"
   ],
   "id": "49ae6c8781d022d6",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T14:46:22.702449Z",
     "start_time": "2024-10-27T14:46:22.464936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DataBase()\n",
    "\n",
    "ner_parser = NERParser(lowercase=False)\n",
    "\n",
    "qe = QueryEmbedderContextualized()\n",
    "\n",
    "qa = QuestionAnsweringAgent()\n",
    "\n",
    "ca = ConversationAgent(model_name=\"google/flan-t5-xl\") #### Could take some time, approx. 10 GB storage :)\n"
   ],
   "id": "a9288d5aec4110c2",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kevinbrundler/Desktop/ATAI/movie-bot/development/exports/extended_graph_triples.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m db \u001B[38;5;241m=\u001B[39m \u001B[43mDataBase\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m ner_parser \u001B[38;5;241m=\u001B[39m NERParser(lowercase\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m qe \u001B[38;5;241m=\u001B[39m QueryEmbedderContextualized()\n",
      "Cell \u001B[0;32mIn[31], line 5\u001B[0m, in \u001B[0;36mDataBase.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdb \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_pickle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetcwd\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mexports/extended_graph_triples.pkl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexports/entity_db.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      8\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentities \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n",
      "File \u001B[0;32m~/Desktop/ATAI/movie-bot/.venv/lib/python3.10/site-packages/pandas/io/pickle.py:185\u001B[0m, in \u001B[0;36mread_pickle\u001B[0;34m(filepath_or_buffer, compression, storage_options)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001B[39;00m\n\u001B[1;32m    125\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;124;03m4    4    9\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    184\u001B[0m excs_to_catch \u001B[38;5;241m=\u001B[39m (\u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mImportError\u001B[39;00m, \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m)\n\u001B[0;32m--> 185\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;66;03m# 1) try standard library Pickle\u001B[39;00m\n\u001B[1;32m    193\u001B[0m     \u001B[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001B[39;00m\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001B[39;00m\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    197\u001B[0m         \u001B[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001B[39;00m\n\u001B[1;32m    198\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Desktop/ATAI/movie-bot/.venv/lib/python3.10/site-packages/pandas/io/common.py:882\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    874\u001B[0m             handle,\n\u001B[1;32m    875\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    878\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    879\u001B[0m         )\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m--> 882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    883\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[1;32m    885\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/kevinbrundler/Desktop/ATAI/movie-bot/development/exports/extended_graph_triples.pkl'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:35:15.054015Z",
     "start_time": "2024-10-27T13:35:15.046764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@measure_time\n",
    "def answer_query(query, correct_answer=\"\"):\n",
    "    normalized_query = db.normalize_string(query)\n",
    "    \n",
    "    entity_matches = fuzzy_match(normalized_query, db.entity_list, threshold=30)\n",
    "    \n",
    "    # NER Model and NER Matching\n",
    "    ner_person, ner_movies = ner_parser.process_query(query)\n",
    "    \n",
    "    if len(ner_movies):\n",
    "        ner_movie_entities = fuzzy_match(\" \".join(ner_movies), db.entity_list, threshold=75)\n",
    "        subjects_ner_movies = db.fetch(ner_movie_entities, \"subject_id\")\n",
    "        context_ner_movies = get_top_matches(subjects_ner_movies, normalized_query, top_n=1) \n",
    "            \n",
    "    else:\n",
    "        context_ner_movies = pd.DataFrame()\n",
    "    \n",
    "    if len(ner_person):\n",
    "        ner_person_entities = fuzzy_match(\" \".join(ner_person), db.entity_list, threshold=75)\n",
    "        subjects_ner_person = db.fetch(ner_person_entities, \"subject_id\")\n",
    "        context_ner_person = get_top_matches(subjects_ner_person, normalized_query, top_n=1)   \n",
    "                \n",
    "    else:\n",
    "        context_ner_person = pd.DataFrame()\n",
    "    \n",
    "    is_domain_specific = bool(ner_person or ner_movies)\n",
    "\n",
    "    if not is_domain_specific:\n",
    "        small_talk = ca.generate_response(query)\n",
    "        print(small_talk)\n",
    "        return\n",
    "    \n",
    "    # Fuzzy Matching\n",
    "    subjects = db.fetch(entity_matches, \"subject_id\")   \n",
    "    context = get_top_matches(subjects, normalized_query, top_n=1)    \n",
    "    \n",
    "    ner_context = pd.concat([context_ner_movies, context_ner_person])\n",
    "        \n",
    "    if not ner_context.empty:\n",
    "        context = ner_context\n",
    "    \n",
    "    try:\n",
    "        node_label = context[\"node label\"].values[0]\n",
    "    except Exception:\n",
    "        node_label = \"\"\n",
    "    \n",
    "    if context.empty:\n",
    "        print(\"No context data found for given IDs or string\")\n",
    "        context = pd.DataFrame()\n",
    "                \n",
    "        #Fallback Strategy\n",
    "        small_talk = ca.generate_small_talk(query)\n",
    "        print(small_talk)\n",
    "        return\n",
    "       \n",
    "    # EXPERIMENTAL - remove unused columns\n",
    "    elements_to_remove = [\"image\", \"color\", \"sport\"]\n",
    "    context = context.drop(columns=elements_to_remove, errors='ignore')\n",
    "    \n",
    "    \n",
    "    # EXPERIMENTAL - rename columns\n",
    "    columns_to_rename = {\n",
    "        \"cast member\":\"movie cast\",\n",
    "        \"notable work\": \"acted in\"\n",
    "    }\n",
    "    \n",
    "    columns_to_rename = {k: v for k, v in columns_to_rename.items() if k in context.columns}\n",
    "    context = context.rename(columns=columns_to_rename)\n",
    "    \n",
    "    columns_to_duplicate = [(\"acted in\", \"played in\"),\n",
    "                            (\"acted in\", \"appeared in\"),\n",
    "                            (\"movie cast\", \"actors\"),\n",
    "                            (\"movie cast\", \"players\")]\n",
    "    \n",
    "    for col_to_duplicate, col in columns_to_duplicate: \n",
    "        try:\n",
    "            context[col] = context[col_to_duplicate].copy()\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    context.dropna(axis=1, inplace=True)\n",
    "    \n",
    "    query_filtered = filter_query(query, node_label)\n",
    "        \n",
    "    column_embeddings = {col: qe.embed_phrase(col) for col in context.columns}\n",
    "    query_embeddings = [qe.embed_phrase(word) for word in query_filtered.split()]  \n",
    "    top_columns_embeddings = find_closest_columns(query_embeddings, column_embeddings)\n",
    "    \n",
    "    # EXPERIMENTAL\n",
    "    top_columns_dict = process.extract(normalized_query, context.columns, scorer=fuzz.partial_ratio, limit=3)\n",
    "    top_columns_fuzzy = [c[0] for c in top_columns_dict]\n",
    "    \n",
    "    # MANUAL OVERWRITE:\n",
    "    top_columns_fuzzy = []\n",
    "        \n",
    "    # EXPERIMENTAL - always keep columns\n",
    "    col_always_keep = [\"node label\"]\n",
    "    \n",
    "    combined_columns = set(top_columns_fuzzy + top_columns_embeddings + col_always_keep)\n",
    "    top_columns = [col for col in combined_columns if col in context.columns]\n",
    "    filtered_context_df = context[top_columns]\n",
    "\n",
    "    answer = qa.query(query, filtered_context_df)\n",
    "    formatted_answer = ca.generate_response(f\"\"\"\"Format the answer to the question into a sentence.\n",
    "                                            If you think the answer is completely off, overrule with your own knowledge.\n",
    "                                            Question: {query}\\nAnswer: {answer}\"\"\")\n",
    "\n",
    "    print(formatted_answer)\n"
   ],
   "id": "758512dcaa9b7d3d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:35:21.260620Z",
     "start_time": "2024-10-27T13:35:15.882153Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Tell me a joke\")",
   "id": "a2546df235e50a6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i saw a man in a tuxedo and he was wearing a tuxedo\n",
      "Execution time for answer_query: 5.3766 seconds\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:35:25.342236Z",
     "start_time": "2024-10-27T13:35:22.976119Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Tell me a good joke\")",
   "id": "3ca2ea020035a86b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you want to be a doctor, you have to be a dentist.\n",
      "Execution time for answer_query: 2.3642 seconds\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:35:28.304283Z",
     "start_time": "2024-10-27T13:35:26.441912Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hello, how is life?\")",
   "id": "468bb67207d901c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm fine, thanks.\n",
      "Execution time for answer_query: 1.8606 seconds\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:35:30.696365Z",
     "start_time": "2024-10-27T13:35:29.338604Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hello, how are you?\")",
   "id": "946f8598f3fde92d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm fine, thanks.\n",
      "Execution time for answer_query: 1.3556 seconds\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:35:46.124444Z",
     "start_time": "2024-10-27T13:35:44.770225Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hell, how are you doing?\")",
   "id": "6ed8407fe866d4ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm fine, thanks.\n",
      "Execution time for answer_query: 1.3519 seconds\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:35:53.814909Z",
     "start_time": "2024-10-27T13:35:52.773165Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hello, what is the capital of switzerland?\")",
   "id": "31e8c5e0aef44c0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bern\n",
      "Execution time for answer_query: 1.0394 seconds\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:36:40.678867Z",
     "start_time": "2024-10-27T13:36:39.611818Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hello, what is the capital of the Paris?\")",
   "id": "45f5b39f42371358",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital of france\n",
      "Execution time for answer_query: 1.0653 seconds\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:36:50.374306Z",
     "start_time": "2024-10-27T13:36:46.487122Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Good Will Hunting?\", \"Gus Van Sant\")",
   "id": "f9402d1107c14c35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.6866\n",
      "Gus Van Sant is the director of Good Will Hunting.\n",
      "Execution time for answer_query: 3.8853 seconds\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:36:54.559524Z",
     "start_time": "2024-10-27T13:36:51.899665Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Bridge on the River Kwai?\", \"David Lean\")",
   "id": "468416428c921e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.5111\n",
      "David Lean directed The Bridge on the River Kwai.\n",
      "Execution time for answer_query: 2.6572 seconds\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:24.453272Z",
     "start_time": "2024-10-26T16:51:21.858789Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Dark Knight?\", \"Christopher Nolan\")",
   "id": "abbc81e04a699a72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.5111\n",
      "The Dark Knight was directed by Christopher Nolan.\n",
      "Execution time for answer_query: 2.5928 seconds\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:27.152755Z",
     "start_time": "2024-10-26T16:51:24.458477Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Where was Angelina Jolie born?\", \"Los Angeles\")",
   "id": "b33e8b5221e04a26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: place of birth with similarity  0.4204\n",
      "Angelina Jolie was born in Los Angeles.\n",
      "Execution time for answer_query: 2.6926 seconds\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:28.474917Z",
     "start_time": "2024-10-26T16:51:27.158004Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "47ade0f1dd42bdd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rupert Grint\n",
      "Execution time for answer_query: 1.3153 seconds\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:31.198575Z",
     "start_time": "2024-10-26T16:51:28.542555Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "4a4f8912be5e2679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: spouse with similarity  0.4737\n",
      "Jennifer Aniston and Angelina Jolie were married to Brad Pitt.\n",
      "Execution time for answer_query: 2.6542 seconds\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:33.437739Z",
     "start_time": "2024-10-26T16:51:31.203778Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "b9615c76501defec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: publication date with similarity  0.4198\n",
      "2010-07-08 was Inception released.\n",
      "Execution time for answer_query: 2.2322 seconds\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:35.843100Z",
     "start_time": "2024-10-26T16:51:33.445406Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "42e389076edf07fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.4614\n",
      "James Glickenhaus is the director of Star Wars.\n",
      "Execution time for answer_query: 2.3958 seconds\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:37.799560Z",
     "start_time": "2024-10-26T16:51:35.848448Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was the Godfather III published?\")",
   "id": "7311213f17afb80c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: publication date with similarity  0.4091\n",
      "1972-03-15 was the Godfather III published.\n",
      "Execution time for answer_query: 1.9495 seconds\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:39.606715Z",
     "start_time": "2024-10-26T16:51:37.815228Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "aadeab7341df5d98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.4614\n",
      "James Glickenhaus is the director of Star Wars.\n",
      "Execution time for answer_query: 1.7895 seconds\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:41.358946Z",
     "start_time": "2024-10-26T16:51:39.612888Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "8790e75b87abfd67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: publication date with similarity  0.4198\n",
      "2010-07-08 was Inception released.\n",
      "Execution time for answer_query: 1.7443 seconds\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:43.576958Z",
     "start_time": "2024-10-26T16:51:41.364194Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Angelina Jolie married to?\")",
   "id": "6659fd0e66bde3ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: spouse with similarity  0.4737\n",
      "Angelina Jolie was married to Billy Bob Thornton.\n",
      "Execution time for answer_query: 2.2110 seconds\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:45.712317Z",
     "start_time": "2024-10-26T16:51:43.582483Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "9e8d79bc11a07fc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: spouse with similarity  0.4737\n",
      "Jennifer Aniston and Angelina Jolie were married to Brad Pitt.\n",
      "Execution time for answer_query: 2.1282 seconds\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:47.410047Z",
     "start_time": "2024-10-26T16:51:45.717185Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the religion of Tom Cruise?\")",
   "id": "b5602fe224c6b2c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: religion with similarity  0.6583\n",
      "Scientology is the religion of Tom Cruise.\n",
      "Execution time for answer_query: 1.6911 seconds\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:48.352219Z",
     "start_time": "2024-10-26T16:51:47.415215Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "caa8b85465ee7a1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rupert Grint\n",
      "Execution time for answer_query: 0.9352 seconds\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:54.870984Z",
     "start_time": "2024-10-26T16:51:48.418532Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who are the cast in Jurassic Park?\")",
   "id": "b8504a68fe32f6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: movie cast with similarity  0.5334\n",
      "Bd wong, laura dern, sam neill, samuel l jackson are the cast in Jurassic Park.\n",
      "Execution time for answer_query: 6.4506 seconds\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:56.595107Z",
     "start_time": "2024-10-26T16:51:54.876185Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who acted in Jurassic Park?\")",
   "id": "caf3e73703fed695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: actors with similarity  0.4118\n",
      "Wayne Knight acted in Jurassic Park.\n",
      "Execution time for answer_query: 1.7174 seconds\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:57.991299Z",
     "start_time": "2024-10-26T16:51:56.600148Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who played in Jurassic Park?\")",
   "id": "40163a1aa0c34960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: players with similarity  0.4161\n",
      "Wayne Knight played in Jurassic Park.\n",
      "Execution time for answer_query: 1.3895 seconds\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:51:59.989283Z",
     "start_time": "2024-10-26T16:51:57.996495Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Tom Cruise play?\")",
   "id": "14bcf95252a1b280",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column actors has similarity  0.1180\n",
      "Column players has similarity  0.1113\n",
      "Days of Thunder is a movie that Tom Cruise played in.\n",
      "Execution time for answer_query: 1.9912 seconds\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:52:02.127190Z",
     "start_time": "2024-10-26T16:51:59.994426Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Rebel Wilson act?\")",
   "id": "d65e48ab10da08fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column actors has similarity  0.1657\n",
      "Column movie cast has similarity  0.1462\n",
      "Column imdb id has similarity  0.1247\n",
      "Column occupation has similarity  0.1230\n",
      "Rebel Wilson acted in Ghost Rider.\n",
      "Execution time for answer_query: 2.1311 seconds\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:52:04.042100Z",
     "start_time": "2024-10-26T16:52:02.136231Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Liam Neeson play?\")",
   "id": "533e2cd752612e69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column played in has similarity  0.1265\n",
      "Column acted in has similarity  0.1202\n",
      "Liam Neeson played in Star Wars.\n",
      "Execution time for answer_query: 1.9041 seconds\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:52:05.601798Z",
     "start_time": "2024-10-26T16:52:04.052414Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is an actor in Taken 2?\")",
   "id": "5339c88d922da86d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: actors with similarity  0.5670\n",
      "Maggie Grace is an actor in Taken 2.\n",
      "Execution time for answer_query: 1.5475 seconds\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:52:07.689940Z",
     "start_time": "2024-10-26T16:52:05.610740Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the role of Vin Diesel in Fast and Furious?\")",
   "id": "99208cc1e2af11c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column director has similarity  0.1230\n",
      "Column actors has similarity  0.1118\n",
      "Vin Diesel is the director of Fast and Furious.\n",
      "Execution time for answer_query: 2.0773 seconds\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T16:52:10.438905Z",
     "start_time": "2024-10-26T16:52:07.705492Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"For which movie did Leonardo Di Caprio win an Oscar?\")",
   "id": "2e27a99aeb854ab0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column actors has similarity  0.1623\n",
      "Column imdb id has similarity  0.1592\n",
      "Column movie cast has similarity  0.1467\n",
      "Column nominated for has similarity  0.1392\n",
      "Column players has similarity  0.1264\n",
      "For which movie did Leonardo Di Caprio win an Oscar?\n",
      "Execution time for answer_query: 2.7314 seconds\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a2f48cf202f6c12b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
