{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:35.939203Z",
     "start_time": "2024-11-10T16:58:32.546462Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration\n",
    ")\n",
    "\n",
    "from transformers import logging as transformers_logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "transformers_logging.set_verbosity_error()\n",
    "import json\n",
    "import time\n",
    "from functools import wraps\n",
    "import sentencepiece\n",
    "\n",
    "# Silencing TqdmWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\UntrackedFolder\\movie-bot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.513282Z",
     "start_time": "2024-11-10T16:58:35.952096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_to_keep = [\"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"with\", \"how\", \"before\", \"after\",\"same\"]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])"
   ],
   "id": "9ce915e61e55399c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.684230Z",
     "start_time": "2024-11-10T16:58:36.677456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def measure_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        result = func(*args, **kwargs)  # Call the function\n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(f\"Execution time for {func.__name__}: {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ],
   "id": "987d727174eaa4ee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.699883Z",
     "start_time": "2024-11-10T16:58:36.690331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NERParser:\n",
    "    def __init__(self, model_name=\"dslim/bert-base-NER\", lowercase=False):\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "\n",
    "        self.nlp_pipeline = pipeline(\n",
    "            \"ner\", \n",
    "            model=AutoModelForTokenClassification.from_pretrained(model_name),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_name, do_lower_case=lowercase),\n",
    "            device=self.device, \n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "\n",
    "    def get_device(self):\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def parse_ner_results(self, ner_results):\n",
    "        per_entities = [e['word'] for e in ner_results if e['entity_group'] == 'PER']\n",
    "        misc_entities = [e['word'] for e in ner_results if e['entity_group'] == 'MISC']\n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    def process_query(self, query):\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        return self.parse_ner_results(self.nlp_pipeline(query))\n",
    "\n"
   ],
   "id": "a15b5f4fab282289",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:34:34.544031Z",
     "start_time": "2024-11-10T17:32:40.789665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataBase:\n",
    "    \"\"\"Handles context data extraction for people and movies from a database with fuzzy matching support.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        with open('exports/images.json') as f:\n",
    "            self.images_data = json.load(f)\n",
    "        self.image_lookup = {}\n",
    "        for element in self.images_data:\n",
    "            img = element[\"img\"]\n",
    "            for m in element[\"movie\"] + element[\"cast\"]:\n",
    "                if m not in self.image_lookup:\n",
    "                    self.image_lookup[m] = []\n",
    "                self.image_lookup[m].append(img)\n",
    "        \n",
    "        # print first few preview items for self.image_lookup\n",
    "        print({k: self.image_lookup[k] for k in list(self.image_lookup)[:1]})\n",
    "        \n",
    "        self.db = pd.read_pickle(os.path.join(os.getcwd(), \"exports/extended_graph_triples.pkl\"))\n",
    "        \n",
    "        self.db['subject_id'] = self.db['subject_id'].astype(str).str.strip()\n",
    "        self.db['predicate_label'] = self.db['predicate_label'].astype(str).str.strip()\n",
    "        self.db['object_label'] = self.db['object_label'].astype(str).str.strip()\n",
    "        \n",
    "        self.db_pivot = self.db.pivot_table(\n",
    "                index='subject_id',\n",
    "                columns='predicate_label',\n",
    "                values='object_label',\n",
    "                aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "            )\n",
    "        \n",
    "        with open('exports/movie_db.json') as f:\n",
    "            self.movie_data = json.load(f)\n",
    "            self.movie_ids = set(self.movie_data.keys())\n",
    "        self.movie_db = pd.DataFrame(list(self.movie_data.items()), columns=[\"entity_id\", \"entity_label\"])   \n",
    "        \n",
    "        with open('exports/people_db.json') as f:\n",
    "            self.people_data = json.load(f)\n",
    "            self.people_ids = set(self.people_data.keys())\n",
    "        self.people_db = pd.DataFrame(list(self.people_data.items()), columns=[\"entity_id\", \"entity_label\"])\n",
    "        \n",
    "        self.entities = {**self.movie_data, **self.people_data}\n",
    "        \n",
    "        self.movie_names = self.movie_db[\"entity_label\"].tolist()\n",
    "        self.people_names = self.people_db[\"entity_label\"].tolist()\n",
    "        \n",
    "        self.entity_list = self.movie_names + self.people_names\n",
    "       \n",
    "        self.people_movie_mapping = {}\n",
    "        self.movie_people_mapping = {}\n",
    "        \n",
    "        self.map_people_movies()\n",
    "        \n",
    "        self.movie_recommender_db = self.filter_relevant_movies()\n",
    "        \n",
    "    def map_people_movies(self):\n",
    "        id_triples = pd.read_pickle(os.path.join(\"exports/df_new_triples_only_ids.pkl\"))\n",
    "        \n",
    "        id_triples['subject_id'] = id_triples['subject_id'].astype(str).str.strip()\n",
    "        id_triples['object_id'] = id_triples['object_id'].astype(str).str.strip()\n",
    "        \n",
    "        for _, row in id_triples.iterrows():\n",
    "            subject_id = row['subject_id']\n",
    "            object_id = row['object_id']\n",
    "            \n",
    "            if subject_id in self.people_ids and object_id in self.movie_ids:\n",
    "                if subject_id not in self.people_movie_mapping:\n",
    "                    self.people_movie_mapping[subject_id] = []\n",
    "                self.people_movie_mapping[subject_id].append(object_id)\n",
    "                \n",
    "                if object_id not in self.movie_people_mapping:\n",
    "                    self.movie_people_mapping[object_id] = []\n",
    "                self.movie_people_mapping[object_id].append(subject_id)\n",
    "        \n",
    "        for person, movies in self.people_movie_mapping.items():\n",
    "            self.people_movie_mapping[person] = list(set(movies))\n",
    "        \n",
    "        for movie, people in self.movie_people_mapping.items():\n",
    "            self.movie_people_mapping[movie] = list(set(people))\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def normalize_string(s):\n",
    "        \"\"\"Normalizes strings by removing non-ASCII characters, punctuation, and redundant spaces.\"\"\"\n",
    "        return ' '.join(re.sub(r'[^\\w\\s]', '', unicodedata.normalize('NFKD', s.lower())\n",
    "                               .encode('ascii', 'ignore').decode('utf-8')).split())\n",
    "\n",
    "    def fetch(self, entity_list, search_column):\n",
    "        \"\"\"Fetches relevant rows from the database where `search_column` matches values in `entity_list`.\"\"\"\n",
    "        relevant = self.db[self.db[search_column].isin(entity_list)].dropna(axis=1)\n",
    "        \n",
    "        if relevant.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        return relevant.pivot_table(\n",
    "            index='subject_id',\n",
    "            columns='predicate_label',\n",
    "            values='object_label',\n",
    "            aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "        ).reset_index()\n",
    "    \n",
    "    def filter_relevant_movies(self):\n",
    "\n",
    "        clean_db = self.db[self.db[\"subject_id\"].isin(self.movie_data.keys())]\n",
    "        relevant_cols = [\n",
    "            # \"author\", # only 99 movies hav an author\n",
    "            # \"cast member\",\n",
    "            \"director\", \n",
    "            \"performer\",\n",
    "            \"genre\",\n",
    "            # \"narrative motif\", # only 43 movies have a narrative motif\n",
    "            \"screenwriter\",\n",
    "            \"subject_id\",\n",
    "            \"node label\" # Required for processing\n",
    "        ]\n",
    "        \n",
    "        pv_db = clean_db.pivot_table(\n",
    "                index='subject_id',\n",
    "                columns='predicate_label',\n",
    "                values='object_label',\n",
    "                aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "            )\n",
    "        \n",
    "        pv_db = pv_db[[col for col in relevant_cols if col in pv_db.columns]]\n",
    "\n",
    "        return pv_db.reset_index()\n",
    "    \n",
    "DataBase()"
   ],
   "id": "c9bf6d33ae34d781",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tt4882376': ['0315/rm601699072.jpg', '3458/rm3357090048.jpg', '0904/rm2350522624.jpg', '2230/rm4217315328.jpg', '0786/rm2333745408.jpg', '1335/rm1519133184.jpg', '2636/rm3037079040.jpg', '0471/rm4158403328.jpg', '2143/rm2044143104.jpg', '3265/rm3591971072.jpg', '1301/rm3373867264.jpg', '1626/rm2456173824.jpg', '0282/rm3417122304.jpg', '3328/rm67577344.jpg', '0990/rm3390644480.jpg', '0805/rm2348819968.jpg', '2232/rm3623953920.jpg', '2767/rm2969970176.jpg', '2849/rm936715776.jpg', '1168/rm822224384.jpg', '0765/rm3470537472.jpg', '3835/rm3137742336.jpg', '3063/rm1742022144.jpg', '2154/rm2607948288.jpg', '1797/rm1398156544.jpg', '2160/rm1004352256.jpg', '1441/rm3570804224.jpg', '3362/rm3575193856.jpg', '0340/rm151135744.jpg', '3734/rm3738576384.jpg', '3200/rm248980992.jpg', '0403/rm115159808.jpg', '0965/rm668411392.jpg', '1969/rm2641502720.jpg', '1762/rm785786368.jpg', '3725/rm1322722816.jpg', '0433/rm2316968192.jpg', '0305/rm2413110784.jpg', '2595/rm162342400.jpg', '3326/rm3608748288.jpg', '2138/rm50472448.jpg', '2095/rm788669952.jpg', '1728/rm2108433920.jpg', '3088/rm1156784384.jpg']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DataBase at 0x22179e8c890>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.736813Z",
     "start_time": "2024-11-10T16:58:36.727520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QueryEmbedderContextualized:\n",
    "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v2'):\n",
    "        \"\"\"Initializes the QueryEmbedder with a SentenceTransformer model and device setup.\"\"\"\n",
    "        self.device = self.get_device()\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "        self.cache = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        \"\"\"Determines the available hardware device (MPS, CUDA, or CPU).\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def embed_phrase(self, phrases):\n",
    "        \"\"\"\n",
    "        Generates embeddings for given phrases using SentenceTransformer, with caching.\n",
    "\n",
    "        Args:\n",
    "            phrases (str or List[str]): Input phrase(s) to embed.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Embedding vector(s) for the input phrase(s).\n",
    "        \"\"\"\n",
    "        if isinstance(phrases, str):\n",
    "            phrases = [phrases]\n",
    "        elif not isinstance(phrases, list):\n",
    "            raise TypeError(\"Input must be a string or a list of strings.\")\n",
    "        \n",
    "        phrases_to_compute = [p for p in phrases if p not in self.cache]\n",
    "        cached_embeddings = [self.cache[p] for p in phrases if p in self.cache]\n",
    "\n",
    "        if phrases_to_compute:\n",
    "            new_embeddings = self.model.encode(\n",
    "                phrases_to_compute, \n",
    "                show_progress_bar=False, \n",
    "                convert_to_numpy=True, \n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            \n",
    "            for phrase, emb in zip(phrases_to_compute, new_embeddings):\n",
    "                self.cache[phrase] = emb\n",
    "            cached_embeddings.extend(new_embeddings)\n",
    "        \n",
    "        return cached_embeddings[0] if len(cached_embeddings) == 1 else np.array(cached_embeddings)\n"
   ],
   "id": "b6108d2c6628d7db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.754038Z",
     "start_time": "2024-11-10T16:58:36.747241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QuestionAnsweringAgent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.qa_model = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\", top_k=1)\n",
    "    \n",
    "    def query(self, query, context_df):\n",
    "        \n",
    "        top_columns = context_df.columns\n",
    "        \n",
    "        context = \"\"\n",
    "        for index, row in context_df.iterrows():\n",
    "            node_label = row.get(\"node label\", \"\")\n",
    "            \n",
    "            row_context = f\"This text is about \\\"{node_label}\\\":\\n\"\n",
    "            \n",
    "            for col in context_df[top_columns].columns:\n",
    "                if col == \"node label\":\n",
    "                    continue\n",
    "                \n",
    "                values = row[col]\n",
    "                values_lst = str(values).split(\",\")\n",
    "                \n",
    "                if len(values_lst) > 5:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst[:5])}\"\n",
    "                else:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst)}\"\n",
    "\n",
    "            context += row_context + \"\\n\\n\"\n",
    "        \n",
    "        output = self.qa_model(question=query, context=context)\n",
    "        \n",
    "        answer_str = str()\n",
    "        if isinstance(output, list) and output:\n",
    "            answer_str = \", \".join([result['answer'] for result in output])\n",
    "            \n",
    "        elif isinstance(output, dict):\n",
    "            answer_str = output['answer']\n",
    "        \n",
    "        if not answer_str:\n",
    "            answer_str = \"No answer found.\"\n",
    "        \n",
    "        return answer_str"
   ],
   "id": "9e2df2f00abd15da",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.767379Z",
     "start_time": "2024-11-10T16:58:36.760945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConversationAgent:\n",
    "    def __init__(self, model_name=\"google/flan-t5-large\", max_length=150):\n",
    "        self.device = self.get_device()\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        \"\"\"\n",
    "        Generates a response based on the given prompt.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=self.max_length,\n",
    "            num_beams=5,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response.strip()\n"
   ],
   "id": "adbe62e7f66579e2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.823639Z",
     "start_time": "2024-11-10T16:58:36.776196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import rdflib\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class GraphEmbeddings:\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        \n",
    "        self.RDFS = rdflib.namespace.RDFS\n",
    "        self.WD = rdflib.Namespace('http://www.wikidata.org/entity/')\n",
    "     \n",
    "        self.entity_emb = np.load('exports/entity_embeds.npy')\n",
    "        self.relation_emb = np.load('exports/relation_embeds.npy')\n",
    "        \n",
    "        with open('exports/entity_ids.del', 'r') as ifile:\n",
    "            self.ent2id = {rdflib.term.URIRef(ent): int(idx) for idx, ent in csv.reader(ifile, delimiter='\\t')}\n",
    "            self.id2ent = {v: k for k, v in self.ent2id.items()}\n",
    "            \n",
    "        with open('exports/relation_ids.del', 'r') as ifile:\n",
    "            self.rel2id = {rdflib.term.URIRef(rel): int(idx) for idx, rel in csv.reader(ifile, delimiter='\\t')}\n",
    "        \n",
    "        with open(\"exports/predicate_db.json\", encoding=\"utf-8\") as f:\n",
    "            self.predicates_db = json.load(f)\n",
    "        \n",
    "        self.ent2lbl = {rdflib.term.URIRef(row.subject_id): row.subject_label for index, row in graph.iterrows()}\n",
    "\n",
    "    def answer_query_embedding(self, context, top_columns):\n",
    "        STD_ERROR = \"The embeddings did not provide a valid answer.\"\n",
    "        try:\n",
    "            context_id = context.subject_id.values[0]\n",
    "            if not context_id:\n",
    "                print(\"No context ID found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            e_id = self.ent2id.get(rdflib.term.URIRef(context_id))\n",
    "            if e_id is None:\n",
    "                return \"2\"\n",
    "\n",
    "            head = self.entity_emb[e_id]\n",
    "            wiki_predicate_id = \"\"\n",
    "\n",
    "            column_mapping = {\n",
    "                \"movie cast\": \"cast member\",\n",
    "                \"acted in\": \"notable work\",\n",
    "                \"played in\": \"notable work\",\n",
    "                \"appeared in\": \"notable work\",\n",
    "                \"actors\": \"cast member\",\n",
    "                \"players\": \"cast member\"\n",
    "            }\n",
    "\n",
    "            for col in top_columns:\n",
    "                \n",
    "                col = column_mapping.get(col, col)\n",
    "                \n",
    "                if col == \"node label\":\n",
    "                    continue\n",
    "                    \n",
    "                if not context[col].values[0]:\n",
    "                    continue\n",
    "\n",
    "                if col in self.predicates_db:\n",
    "                    wiki_id = rdflib.term.URIRef(self.predicates_db[col])\n",
    "                    if wiki_id in self.rel2id:\n",
    "                        wiki_predicate_id = self.predicates_db[col]\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Predicate {col} not found in rel2id.\")\n",
    "                else:\n",
    "                    print(f\"Predicate {col} not found in predicate_db.\")\n",
    "\n",
    "            if not wiki_predicate_id:\n",
    "                print(\"No valid predicate found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            r_id = self.rel2id[rdflib.term.URIRef(wiki_predicate_id)]\n",
    "            pred = self.relation_emb[r_id]\n",
    "\n",
    "            lhs = head + pred\n",
    "            dist = pairwise_distances(lhs.reshape(1, -1), self.entity_emb).reshape(-1)\n",
    "            most_likely = dist.argsort()\n",
    "\n",
    "            num_results = min(3, len(most_likely))\n",
    "            results_lst = [\n",
    "                (self.id2ent[idx][len(self.WD):], self.ent2lbl.get(self.id2ent[idx], \"\"), dist[idx], rank + 1)\n",
    "                for rank, idx in enumerate(most_likely[:num_results])\n",
    "            ]\n",
    "            results_df = pd.DataFrame(results_lst, columns=('Entity', 'Label', 'Score', 'Rank'))\n",
    "            \n",
    "            if results_df.empty:\n",
    "                print(\"No results in embeddings found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            return f\"Top answers from embeddings: {', '.join(results_df.Label.values)}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during query answering: {e}\")\n",
    "            return STD_ERROR\n",
    "        "
   ],
   "id": "7c4c6264fcca0ba0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.839104Z",
     "start_time": "2024-11-10T16:58:36.830351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 \n",
    "    \n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "def rescale_probabilities(similarities):\n",
    "    \"\"\"\n",
    "    Rescales the similarity scores so that they sum to 1, turning them into a probability distribution.\n",
    "    \n",
    "    Args:\n",
    "        similarities (List[float]): List of similarity scores.\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Rescaled probabilities.\n",
    "    \"\"\"\n",
    "    similarity_sum = sum(similarities)\n",
    "    if similarity_sum == 0:\n",
    "        return [0] * len(similarities)  # Avoid division by zero\n",
    "    \n",
    "    return [sim / similarity_sum for sim in similarities]\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, high_threshold=0.4, top_n=10, rescaled_threshold=0.11):\n",
    "    \"\"\"\n",
    "    Returns columns based on cosine similarity with a two-tiered strategy and rescaled probabilities.\n",
    "    - If a column has similarity above 'high_threshold', return that column immediately.\n",
    "    - Otherwise, return all columns with a similarity greater than 'low_threshold'.\n",
    "    - Rescale the top N column similarities into probabilities and return columns with a rescaled probability greater than rescaled_threshold.\n",
    "    \n",
    "    Args:\n",
    "        query_embeddings (List[np.ndarray]): Embeddings for query words.\n",
    "        column_embeddings (Dict[str, np.ndarray]): Precomputed embeddings for columns.\n",
    "        low_threshold (float): Minimum similarity threshold (default: 0.27).\n",
    "        high_threshold (float): Confidence threshold to return immediately (default: 0.35).\n",
    "        top_n (int): Number of top columns to consider for rescaling (default: 10).\n",
    "        rescaled_threshold (float): Minimum rescaled probability threshold (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: The selected column names.\n",
    "    \"\"\"\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_columns = sorted_columns[:top_n]\n",
    "    \n",
    "    column_names, similarities = zip(*top_columns)\n",
    "    \n",
    "    rescaled_probs = rescale_probabilities(similarities)\n",
    "    \n",
    "    selected_columns = []\n",
    "    \n",
    "    for col, sim in zip(column_names, similarities):\n",
    "        if sim >= high_threshold:\n",
    "            # print(f\"High confidence match found: {col} with similarity {sim: .4f}\")\n",
    "            return [col]\n",
    "    \n",
    "    for col, rescaled_prob in zip(column_names, rescaled_probs):\n",
    "        if rescaled_prob >= rescaled_threshold:\n",
    "            # print(f\"Column {col} has similarity {rescaled_prob: .4f}\")\n",
    "            selected_columns.append(col)\n",
    "    \n",
    "    return selected_columns"
   ],
   "id": "9b901d7c50e94cbf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.852643Z",
     "start_time": "2024-11-10T16:58:36.845848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_query(query, node_label):\n",
    "                \n",
    "    if not len(query):\n",
    "        return []\n",
    "    \n",
    "    relevant = []\n",
    "    for word in query.replace(\". \", \" \").lower().split(\" \"):\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in node_label.lower().replace(\" \", \"\") or cleaned_word == \"\":\n",
    "            continue\n",
    "        \n",
    "        relevant.append(cleaned_word)\n",
    "        \n",
    "    return \" \".join(relevant)"
   ],
   "id": "6f3a2fd9e6e77d97",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.875455Z",
     "start_time": "2024-11-10T16:58:36.860968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from rapidfuzz import process, fuzz\n",
    "import time\n",
    "from functools import wraps\n",
    "import logging\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stop_words_to_keep = [\n",
    "    \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\",\n",
    "    \"with\", \"how\", \"before\", \"after\", \"same\"\n",
    "]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])\n",
    "\n",
    "# Define colors for logging\n",
    "class BColors:\n",
    "    HEADER = \"\\033[95m\"\n",
    "    OKBLUE = \"\\033[94m\"\n",
    "    OKCYAN = \"\\033[96m\"\n",
    "    OKGREEN = \"\\033[92m\"\n",
    "    WARNING = \"\\033[93m\"\n",
    "    FAIL = \"\\033[91m\"\n",
    "    ENDC = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    UNDERLINE = \"\\033[4m\"\n",
    "\n",
    "# Custom formatter to color log levels\n",
    "class ColoredFormatter(logging.Formatter):\n",
    "    def __init__(self, fmt=None, datefmt=None):\n",
    "        super().__init__(fmt, datefmt)\n",
    "        self.COLORS = {\n",
    "            'DEBUG': BColors.OKBLUE,\n",
    "            'INFO': '',  # No color for INFO messages\n",
    "            'WARNING': BColors.WARNING,\n",
    "            'ERROR': BColors.FAIL,\n",
    "            'CRITICAL': BColors.BOLD + BColors.FAIL,\n",
    "        }\n",
    "\n",
    "    def format(self, record):\n",
    "        levelname = record.levelname.strip(BColors.ENDC)\n",
    "        level_color = self.COLORS.get(levelname, '')\n",
    "        record.levelname = level_color + record.levelname + BColors.ENDC\n",
    "        return super().format(record)\n",
    "\n",
    "# Set up logger\n",
    "logger = logging.getLogger('factual_questions')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "\n",
    "# Create formatter\n",
    "formatter = ColoredFormatter('%(asctime)s | %(levelname)s | %(funcName)s | %(message)s')\n",
    "\n",
    "# Add formatter to handler\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# Add handler to logger if not already added\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Determines the available hardware device (MPS, CUDA, or CPU).\"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def measure_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        result = func(*args, **kwargs)  # Call the function\n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        # Log the execution time under INFO level, with time in green color\n",
    "        elapsed_time_str = f\"{BColors.OKGREEN}{elapsed_time:.4f} seconds{BColors.ENDC}\"\n",
    "        print(f\"Execution time for {func.__name__}: {elapsed_time_str}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def rescale_probabilities(similarities):\n",
    "    \"\"\"\n",
    "    Rescales the similarity scores so that they sum to 1, turning them into a probability distribution.\n",
    "\n",
    "    Args:\n",
    "        similarities (List[float]): List of similarity scores.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Rescaled probabilities.\n",
    "    \"\"\"\n",
    "    similarity_sum = sum(similarities)\n",
    "    if similarity_sum == 0:\n",
    "        return [0] * len(similarities)  # Avoid division by zero\n",
    "\n",
    "    return [sim / similarity_sum for sim in similarities]\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, high_threshold=0.4, top_n=10, rescaled_threshold=0.11):\n",
    "    \"\"\"\n",
    "    Returns columns based on cosine similarity with a two-tiered strategy and rescaled probabilities.\n",
    "    - If a column has similarity above 'high_threshold', return that column immediately.\n",
    "    - Otherwise, return all columns with a rescaled probability greater than 'rescaled_threshold'.\n",
    "\n",
    "    Args:\n",
    "        query_embeddings (List[np.ndarray]): Embeddings for query words.\n",
    "        column_embeddings (Dict[str, np.ndarray]): Precomputed embeddings for columns.\n",
    "        high_threshold (float): Confidence threshold to return immediately (default: 0.4).\n",
    "        top_n (int): Number of top columns to consider for rescaling (default: 10).\n",
    "        rescaled_threshold (float): Minimum rescaled probability threshold (default: 0.11).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The selected column names.\n",
    "    \"\"\"\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_columns = sorted_columns[:top_n]\n",
    "\n",
    "    column_names, similarities = zip(*top_columns)\n",
    "\n",
    "    rescaled_probs = rescale_probabilities(similarities)\n",
    "\n",
    "    selected_columns = []\n",
    "\n",
    "    for col, sim in zip(column_names, similarities):\n",
    "        if sim >= high_threshold:\n",
    "            print(f\"High confidence match found: {col} with similarity {sim:.4f}\")\n",
    "            return [col]\n",
    "\n",
    "    for col, rescaled_prob in zip(column_names, rescaled_probs):\n",
    "        if rescaled_prob >= rescaled_threshold:\n",
    "            print(f\"Column {col} has rescaled similarity {rescaled_prob:.4f}\")\n",
    "            selected_columns.append(col)\n",
    "\n",
    "    return selected_columns\n",
    "\n",
    "def filter_query(query, node_label):\n",
    "    if not query:\n",
    "        return ''\n",
    "\n",
    "    relevant = []\n",
    "    node_label_cleaned = node_label.lower().replace(\" \", \"\")\n",
    "    for word in query.replace(\". \", \" \").lower().split():\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in node_label_cleaned or not cleaned_word:\n",
    "            continue\n",
    "        relevant.append(cleaned_word)\n",
    "\n",
    "    return \" \".join(relevant)\n",
    "\n",
    "def fuzzy_match(query_str, comparison_list, db):\n",
    "    if not comparison_list or not query_str:\n",
    "        return []\n",
    "\n",
    "    name_to_id = {v: k for k, v in db.entities.items()}\n",
    "\n",
    "    longest_full_match = \"\"\n",
    "    longest_full_length = 0\n",
    "    longest_prefix_match = \"\"\n",
    "    longest_prefix_length = 0\n",
    "    \n",
    "    query_str = db.normalize_string(query_str)\n",
    "\n",
    "    # Loop through the comparison list to find both longest full match and longest prefix match\n",
    "    for subject in comparison_list:\n",
    "        if \"porn\" in subject:\n",
    "            continue\n",
    "        \n",
    "        if subject in query_str:\n",
    "            if len(subject) > longest_full_length:\n",
    "                longest_full_match = subject\n",
    "                longest_full_length = len(subject)\n",
    "\n",
    "        # Check for longest prefix match\n",
    "        for i in range(len(subject), 0, -1):\n",
    "            if subject[:i] == query_str[:i] and len(subject) > len(query_str):\n",
    "                if i > longest_prefix_length:\n",
    "                    longest_prefix_match = subject\n",
    "                    longest_prefix_length = i\n",
    "                break\n",
    "\n",
    "    if longest_full_length >= 4:\n",
    "        print(f\"Found FULL match: {longest_full_match}\")\n",
    "        return name_to_id[longest_full_match], True, longest_full_length\n",
    "    elif longest_prefix_length >= 9:\n",
    "        print(f\"Found PREFIX match: {longest_prefix_match}\")\n",
    "        return name_to_id[longest_prefix_match], False, longest_prefix_length\n",
    "    return [], False, 0\n",
    "\n"
   ],
   "id": "d2eb95481eacac33",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.888155Z",
     "start_time": "2024-11-10T16:58:36.881779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_matches(df, normalized_query, top_n=2):\n",
    "    concatenated_rows = df.apply(lambda row: ' '.join(row.astype(str)), axis=1).tolist()\n",
    "    \n",
    "    exact_matches = [i for i, row in enumerate(concatenated_rows) if normalized_query == row]\n",
    "    \n",
    "    if len(exact_matches) < top_n:\n",
    "        remaining_slots = top_n - len(exact_matches)\n",
    "        fuzzy_matches = process.extract(normalized_query, concatenated_rows, scorer=fuzz.partial_ratio, limit=remaining_slots)\n",
    "        fuzzy_indices = [match[2] for match in fuzzy_matches]\n",
    "    else:\n",
    "        fuzzy_indices = []\n",
    "    \n",
    "    top_indices = exact_matches + fuzzy_indices\n",
    "    \n",
    "    return df.iloc[top_indices]"
   ],
   "id": "49ae6c8781d022d6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T16:58:36.903442Z",
     "start_time": "2024-11-10T16:58:36.895709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend(node_label, entity_id, context, db):\n",
    "    if \"CURRENT MODE\" == \"RECOMMENDER\" or True:\n",
    "        node_label = db.normalize_string(node_label)\n",
    "        if node_label in db.people_names:\n",
    "            movie_ids = db.people_movie_mapping[entity_id]\n",
    "            context = db.fetch(movie_ids, \"subject_id\")\n",
    "            subject_labels = context[\"node label\"].tolist()\n",
    "            return sorted(subject_labels, key=len)[:3]\n",
    "\n",
    "        context.dropna(axis=1, inplace=True)\n",
    "        columns = [col for col in context.columns if col in db.movie_recommender_db.columns]\n",
    "        red_db = db.movie_recommender_db[columns]\n",
    "        context = context[columns]\n",
    "        \n",
    "        # drop the identified row already in the context\n",
    "        subject_id_to_remove = context[\"subject_id\"].values[0]\n",
    "        red_db = red_db[red_db[\"subject_id\"] != subject_id_to_remove]\n",
    "        \n",
    "        red_db.dropna(thresh=len(red_db.columns) - 0, inplace=True)\n",
    "        red_db.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        COLUMN_WEIGHTS = {\n",
    "            'director': 0.3,\n",
    "            'performer': 0.1,\n",
    "            'genre': 0.3,\n",
    "            'screenwriter': 0.2,\n",
    "            'cast member': 0.1\n",
    "        }\n",
    "        \n",
    "        def calculate_similarity(i, row):\n",
    "            similarities = []\n",
    "            for col in context.columns:\n",
    "                if pd.isna(row[col]):\n",
    "                    continue\n",
    "                    \n",
    "                if col in [\"node label\", \"subject_id\"]:\n",
    "                    continue\n",
    "                \n",
    "                set_context = set(context[col].iloc[0].split(\",\"))\n",
    "                set_row = set(row[col].split(\",\"))\n",
    "                similarity = len(set_context.intersection(set_row)) / len(set_context.union(set_row))\n",
    "                similarities.append(similarity * COLUMN_WEIGHTS[col])\n",
    "    \n",
    "            return i, np.mean(similarities) if similarities else 0\n",
    "        \n",
    "        top_scores = []\n",
    "        for i, row in red_db.iterrows():\n",
    "            index, score = calculate_similarity(i, row)\n",
    "            \n",
    "            if len(top_scores) < 3:\n",
    "                heapq.heappush(top_scores, (score, index))\n",
    "            else:\n",
    "                # Maintain top 3 scores\n",
    "                heapq.heappushpop(top_scores, (score, index))\n",
    "    \n",
    "        # Extract indices from top 3 scores\n",
    "        top_indices = [index for score, index in top_scores]\n",
    "        top_rows = red_db.iloc[top_indices]\n",
    "        \n",
    "        subject_labels = top_rows['node label'].tolist()\n",
    "        return subject_labels\n"
   ],
   "id": "ee49a3a549bb21ed",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:53.770393Z",
     "start_time": "2024-11-10T16:58:36.910658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DataBase()\n",
    "\n",
    "ner_parser = NERParser(lowercase=False)\n",
    "\n",
    "qe = QueryEmbedderContextualized()\n",
    "\n",
    "qa = QuestionAnsweringAgent()\n",
    "\n",
    "ca = ConversationAgent(model_name=\"google/flan-t5-xl\") #### Could take some time, approx. 10 GB storage :)\n",
    "\n",
    "ge = GraphEmbeddings(db.db)\n"
   ],
   "id": "a9288d5aec4110c2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:53.790133Z",
     "start_time": "2024-11-10T17:00:53.778221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import heapq\n",
    "\n",
    "@measure_time\n",
    "def answer_query(query, correct_answer=\"\"):\n",
    "    normalized_query = db.normalize_string(query)\n",
    "\n",
    "    # ************ REACTIVATE NER IF REQUIRED ************\n",
    "    # ************ REACTIVATE NER IF REQUIRED ************\n",
    "    # ************ REACTIVATE NER IF REQUIRED ************\n",
    "    if True:\n",
    "        # print(\"NER failed, proceeding with fuzzy matching.\")\n",
    "        fuzzy_person_match, person_full_match, person_match_length = fuzzy_match(normalized_query, db.people_names, db)\n",
    "        fuzzy_movie_match, movie_full_match, movie_match_length = fuzzy_match(normalized_query, db.movie_names, db)\n",
    "        \n",
    "        fuzzy_movie_matches = []\n",
    "        fuzzy_person_matches = []\n",
    "        if movie_full_match and person_full_match:\n",
    "            if movie_match_length > person_match_length:\n",
    "                fuzzy_person_matches = []\n",
    "                fuzzy_movie_matches = [fuzzy_movie_match]\n",
    "            else:\n",
    "                fuzzy_movie_matches = []\n",
    "                fuzzy_person_matches = [fuzzy_person_match]\n",
    "            \n",
    "        elif person_full_match:\n",
    "            fuzzy_movie_matches = []\n",
    "            fuzzy_person_matches = [fuzzy_person_match]\n",
    "        elif movie_full_match:\n",
    "            fuzzy_person_matches = []\n",
    "            fuzzy_movie_matches = [fuzzy_movie_match]\n",
    "            \n",
    "        elif len(fuzzy_movie_match) and len(fuzzy_person_match):\n",
    "            if person_match_length > movie_match_length:\n",
    "                fuzzy_movie_matches = []\n",
    "            else:\n",
    "                fuzzy_person_matches = []\n",
    "\n",
    "        \n",
    "        fuzzy_movie_context = db.fetch(fuzzy_movie_matches, \"subject_id\") \n",
    "        fuzzy_person_context = db.fetch(fuzzy_person_matches, \"subject_id\")\n",
    "        \n",
    "        if fuzzy_person_context.empty and fuzzy_movie_context.empty:\n",
    "            small_talk = ca.generate_response(query)\n",
    "            print(f\"Smalltalk: {small_talk}\")\n",
    "            return\n",
    "        \n",
    "        context = pd.concat([fuzzy_movie_context, fuzzy_person_context])\n",
    "    \n",
    "    \n",
    "    context = get_top_matches(context, normalized_query, top_n=1)    \n",
    "\n",
    "    \n",
    "    node_label = \"\"\n",
    "    if not context.empty and \"node label\" in context.columns and not context[\"node label\"].isna().values[0]:\n",
    "        node_label = context[\"node label\"].values[0]  \n",
    "        \n",
    "    entity_id = \"\"\n",
    "    if not context.empty and \"subject_id\" in context.columns and not context[\"subject_id\"].isna().values[0]:\n",
    "        entity_id = context[\"subject_id\"].values[0]\n",
    "\n",
    "    if \"RECOMMENDER\":\n",
    "        movies = recommend(node_label, entity_id, context, db)\n",
    "        formatted_answer = f\"Based on your interest in {node_label.title()}, I recommend watching the following movies:\\n- \" + '\\n- '.join(movies)\n",
    "\n",
    "        print(formatted_answer)\n",
    "        return\n",
    "    \n",
    "    elements_to_remove = [\"image\", \"color\", \"sport\"]\n",
    "    context = context.drop(columns=elements_to_remove, errors='ignore')\n",
    "    \n",
    "    # Initial context for embeddings\n",
    "    initial_context = context.copy()\n",
    "    \n",
    "    # EXPERIMENTAL - rename columns\n",
    "    columns_to_rename = {\n",
    "        \"cast member\":\"movie cast\",\n",
    "        \"notable work\": \"acted in\"\n",
    "    }\n",
    "    \n",
    "    columns_to_rename = {k: v for k, v in columns_to_rename.items() if k in context.columns}\n",
    "    context = context.rename(columns=columns_to_rename)\n",
    "    \n",
    "    columns_to_duplicate = [(\"acted in\", \"played in\"),\n",
    "                            (\"acted in\", \"appeared in\"),\n",
    "                            (\"movie cast\", \"actors\"),\n",
    "                            (\"movie cast\", \"players\")]\n",
    "    \n",
    "    for col_to_duplicate, col in columns_to_duplicate: \n",
    "        try:\n",
    "            context[col] = context[col_to_duplicate].copy()\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    context.dropna(axis=1, inplace=True)\n",
    "    \n",
    "    query_filtered = filter_query(query, node_label)\n",
    "        \n",
    "    column_embeddings = {col: qe.embed_phrase(col) for col in context.columns}\n",
    "    query_embeddings = [qe.embed_phrase(word) for word in query_filtered.split()]  \n",
    "    top_columns_embeddings = find_closest_columns(query_embeddings, column_embeddings)\n",
    "        \n",
    "    # EXPERIMENTAL - always keep columns\n",
    "    col_always_keep = [\"node label\"]\n",
    "    \n",
    "    combined_columns = set(top_columns_embeddings + col_always_keep)\n",
    "    top_columns = [col for col in combined_columns if col in context.columns]\n",
    "    filtered_context_df = context[top_columns]\n",
    "\n",
    "    answer = qa.query(query, filtered_context_df)\n",
    "    formatted_answer = ca.generate_response(f\"Format the answer to the question into a sentence. If you think the answer is completely off, overrule with your own knowledge.Question: {query}\\nAnswer: {answer}\")\n",
    "        \n",
    "    print(ge.answer_query_embedding(initial_context, top_columns))\n",
    "    print(formatted_answer)\n"
   ],
   "id": "758512dcaa9b7d3d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:53.802100Z",
     "start_time": "2024-11-10T17:00:53.798962Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3f57aaedb081b5df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:55.005967Z",
     "start_time": "2024-11-10T17:00:53.814805Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of the movie the return of the Jedi?\")\n",
   "id": "50529ca584ae5294",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: the return\n",
      "Based on your interest in The Return, I recommend watching the following movies:\n",
      "- The Orphanage\n",
      "- Far North\n",
      "- The Warrior\n",
      "Execution time for answer_query: \u001B[92m1.1821 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:56.123870Z",
     "start_time": "2024-11-10T17:00:55.015336Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Jurassic Park?\")",
   "id": "a2546df235e50a6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: jurassic park\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: \u001B[92m1.0985 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:57.267276Z",
     "start_time": "2024-11-10T17:00:56.130607Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"The Grand Budapest Hotel\", \"Gus Van Sant\")",
   "id": "f9402d1107c14c35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: the grand budapest hotel\n",
      "Based on your interest in The Grand Budapest Hotel, I recommend watching the following movies:\n",
      "- The Life Aquatic with Steve Zissou\n",
      "- The Darjeeling Limited\n",
      "- Hotel Chevalier\n",
      "Execution time for answer_query: \u001B[92m1.1313 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:58.398797Z",
     "start_time": "2024-11-10T17:00:57.274008Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Bridge on the River Kwai?\", \"David Lean\")",
   "id": "468416428c921e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: the bridge on the river kwai\n",
      "Based on your interest in The Bridge On The River Kwai, I recommend watching the following movies:\n",
      "- A Passage to India\n",
      "- Doctor Zhivago\n",
      "- Ryan's Daughter\n",
      "Execution time for answer_query: \u001B[92m1.1203 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:58.654205Z",
     "start_time": "2024-11-10T17:00:58.407264Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Dark Knight?\", \"Christopher Nolan\")",
   "id": "abbc81e04a699a72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: the dark knight\n",
      "Based on your interest in The Dark Knight, I recommend watching the following movies:\n",
      "- Interstellar\n",
      "- The Dark Knight Rises\n",
      "- Batman Begins\n",
      "Execution time for answer_query: \u001B[92m0.2436 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:00:58.901133Z",
     "start_time": "2024-11-10T17:00:58.663956Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Where was Angelina Jolie born?\", \"Los Angeles\")",
   "id": "b33e8b5221e04a26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: angelina jolie\n",
      "Found FULL match: angel\n",
      "Based on your interest in Angelina Jolie, I recommend watching the following movies:\n",
      "- Salt\n",
      "- Difret\n",
      "- Wanted\n",
      "Execution time for answer_query: \u001B[92m0.2348 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:09.184369Z",
     "start_time": "2024-11-10T17:00:58.910678Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter?\")",
   "id": "bc4cd8856f0382e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smalltalk: Rupert Grint\n",
      "Execution time for answer_query: \u001B[92m10.2657 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:10.451168Z",
     "start_time": "2024-11-10T17:01:09.215540Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "47ade0f1dd42bdd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: harry potter and the philosophers stone\n",
      "Based on your interest in Harry Potter And The Philosopher'S Stone, I recommend watching the following movies:\n",
      "- The Christmas Chronicles 2\n",
      "- Percy Jackson & the Olympians: The Lightning Thief\n",
      "- Harry Potter and the Chamber of Secrets\n",
      "Execution time for answer_query: \u001B[92m1.2284 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:10.699256Z",
     "start_time": "2024-11-10T17:01:10.454593Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "4a4f8912be5e2679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: brad pitt\n",
      "Based on your interest in Brad Pitt, I recommend watching the following movies:\n",
      "- Hunk\n",
      "- Fury\n",
      "- Troy\n",
      "Execution time for answer_query: \u001B[92m0.2313 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:10.981120Z",
     "start_time": "2024-11-10T17:01:10.713839Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "b9615c76501defec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: inception\n",
      "Based on your interest in Inception, I recommend watching the following movies:\n",
      "- Batman Begins\n",
      "- Dunkirk\n",
      "- Interstellar\n",
      "Execution time for answer_query: \u001B[92m0.2572 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:12.132374Z",
     "start_time": "2024-11-10T17:01:10.981120Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "42e389076edf07fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: star\n",
      "Based on your interest in Star!, I recommend watching the following movies:\n",
      "- Rooftops\n",
      "- Somebody Up There Likes Me\n",
      "- The Sound of Music\n",
      "Execution time for answer_query: \u001B[92m1.1463 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:12.412644Z",
     "start_time": "2024-11-10T17:01:12.140593Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was the Godfather III published?\")",
   "id": "7311213f17afb80c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: the godfather\n",
      "Based on your interest in The Godfather, I recommend watching the following movies:\n",
      "- Carlito's Way\n",
      "- Bram Stoker's Dracula\n",
      "- Rumble Fish\n",
      "Execution time for answer_query: \u001B[92m0.2667 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:13.585273Z",
     "start_time": "2024-11-10T17:01:12.424163Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "aadeab7341df5d98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: star\n",
      "Based on your interest in Star!, I recommend watching the following movies:\n",
      "- Rooftops\n",
      "- Somebody Up There Likes Me\n",
      "- The Sound of Music\n",
      "Execution time for answer_query: \u001B[92m1.1528 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:13.858769Z",
     "start_time": "2024-11-10T17:01:13.594110Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "8790e75b87abfd67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: inception\n",
      "Based on your interest in Inception, I recommend watching the following movies:\n",
      "- Batman Begins\n",
      "- Dunkirk\n",
      "- Interstellar\n",
      "Execution time for answer_query: \u001B[92m0.2555 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:14.110924Z",
     "start_time": "2024-11-10T17:01:13.871004Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Angelina Jolie married to?\")",
   "id": "6659fd0e66bde3ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: angelina jolie\n",
      "Found FULL match: angel\n",
      "Based on your interest in Angelina Jolie, I recommend watching the following movies:\n",
      "- Salt\n",
      "- Difret\n",
      "- Wanted\n",
      "Execution time for answer_query: \u001B[92m0.2292 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:14.350058Z",
     "start_time": "2024-11-10T17:01:14.119424Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "9e8d79bc11a07fc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: brad pitt\n",
      "Based on your interest in Brad Pitt, I recommend watching the following movies:\n",
      "- Hunk\n",
      "- Fury\n",
      "- Troy\n",
      "Execution time for answer_query: \u001B[92m0.2245 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:14.615885Z",
     "start_time": "2024-11-10T17:01:14.357551Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the religion of Tom Cruise?\")",
   "id": "b5602fe224c6b2c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: tom cruise\n",
      "Based on your interest in Tom Cruise, I recommend watching the following movies:\n",
      "- Taps\n",
      "- Legend\n",
      "- Top Gun\n",
      "Execution time for answer_query: \u001B[92m0.2435 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:15.847089Z",
     "start_time": "2024-11-10T17:01:14.625899Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "caa8b85465ee7a1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: harry potter and the philosophers stone\n",
      "Based on your interest in Harry Potter And The Philosopher'S Stone, I recommend watching the following movies:\n",
      "- The Christmas Chronicles 2\n",
      "- Percy Jackson & the Olympians: The Lightning Thief\n",
      "- Harry Potter and the Chamber of Secrets\n",
      "Execution time for answer_query: \u001B[92m1.2170 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:17.008298Z",
     "start_time": "2024-11-10T17:01:15.854428Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who are the cast in Jurassic Park?\")",
   "id": "b8504a68fe32f6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: jurassic park\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: \u001B[92m1.1490 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:18.219319Z",
     "start_time": "2024-11-10T17:01:17.017402Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who acted in Jurassic Park?\")",
   "id": "caf3e73703fed695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: jurassic park\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: \u001B[92m1.1936 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:19.490314Z",
     "start_time": "2024-11-10T17:01:18.234492Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who played in Jurassic Park?\")",
   "id": "40163a1aa0c34960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: jurassic park\n",
      "Based on your interest in Jurassic Park, I recommend watching the following movies:\n",
      "- Indiana Jones and the Kingdom of the Crystal Skull\n",
      "- The Lost World: Jurassic Park\n",
      "- War of the Worlds\n",
      "Execution time for answer_query: \u001B[92m1.2419 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:19.744082Z",
     "start_time": "2024-11-10T17:01:19.497904Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Tom Cruise play?\")",
   "id": "14bcf95252a1b280",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: tom cruise\n",
      "Found FULL match: play\n",
      "Based on your interest in Tom Cruise, I recommend watching the following movies:\n",
      "- Taps\n",
      "- Legend\n",
      "- Top Gun\n",
      "Execution time for answer_query: \u001B[92m0.2367 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:19.981502Z",
     "start_time": "2024-11-10T17:01:19.751993Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Rebel Wilson act?\")",
   "id": "d65e48ab10da08fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: rebel wilson\n",
      "Found FULL match: wilson\n",
      "Based on your interest in Rebel Wilson, I recommend watching the following movies:\n",
      "- Cats\n",
      "- Grimsby\n",
      "- Fat Pizza\n",
      "Execution time for answer_query: \u001B[92m0.2254 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:20.255773Z",
     "start_time": "2024-11-10T17:01:19.990381Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Liam Neeson play?\")",
   "id": "533e2cd752612e69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: liam neeson\n",
      "Found FULL match: liam\n",
      "Based on your interest in Liam Neeson, I recommend watching the following movies:\n",
      "- Nell\n",
      "- Chloe\n",
      "- Ted 2\n",
      "Execution time for answer_query: \u001B[92m0.2600 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:20.536965Z",
     "start_time": "2024-11-10T17:01:20.263110Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is an actor in Taken 2?\")",
   "id": "5339c88d922da86d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: taken 2\n",
      "Based on your interest in Taken 2, I recommend watching the following movies:\n",
      "- Raid\n",
      "- Taken\n",
      "- Taken 3\n",
      "Execution time for answer_query: \u001B[92m0.2609 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:20.754152Z",
     "start_time": "2024-11-10T17:01:20.544361Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the role of Vin Diesel in Fast and Furious?\")",
   "id": "99208cc1e2af11c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: vin diesel\n",
      "Found FULL match: fast\n",
      "Based on your interest in Vin Diesel, I recommend watching the following movies:\n",
      "- Strays\n",
      "- Riddick\n",
      "- Furious 7\n",
      "Execution time for answer_query: \u001B[92m0.2050 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:20.990057Z",
     "start_time": "2024-11-10T17:01:20.761905Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"For which movie did Leonardo DiCaprio win an Oscar?\")",
   "id": "2e27a99aeb854ab0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found FULL match: leonardo dicaprio\n",
      "Found FULL match: oscar\n",
      "Based on your interest in Leonardo Dicaprio, I recommend watching the following movies:\n",
      "- Hubble\n",
      "- Virunga\n",
      "- Titanic\n",
      "Execution time for answer_query: \u001B[92m0.2173 seconds\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:21.002359Z",
     "start_time": "2024-11-10T17:01:20.998009Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a2f48cf202f6c12b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:01:21.013510Z",
     "start_time": "2024-11-10T17:01:21.010632Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3306fca6f38e2575",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
