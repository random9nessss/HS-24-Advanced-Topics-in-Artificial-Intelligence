{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T15:57:48.547741Z",
     "start_time": "2024-10-27T15:57:48.540521Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    pipeline,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration\n",
    ")\n",
    "\n",
    "from transformers import logging as transformers_logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "transformers_logging.set_verbosity_error()\n",
    "import json\n",
    "import time\n",
    "from functools import wraps\n",
    "import sentencepiece\n",
    "\n",
    "# Silencing TqdmWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.375871Z",
     "start_time": "2024-10-27T15:44:49.110984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_to_keep = [\"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"with\", \"how\", \"before\", \"after\",\"same\"]\n",
    "stop_words = set([s for s in stopwords.words('english') if s not in stop_words_to_keep])"
   ],
   "id": "9ce915e61e55399c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.533124Z",
     "start_time": "2024-10-27T15:44:50.527559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def measure_time(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()  # Record the start time\n",
    "        result = func(*args, **kwargs)  # Call the function\n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "        print(f\"Execution time for {func.__name__}: {elapsed_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ],
   "id": "987d727174eaa4ee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.548676Z",
     "start_time": "2024-10-27T15:44:50.542743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NERParser:\n",
    "    def __init__(self, model_name=\"dslim/bert-base-NER\", lowercase=False):\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "\n",
    "        self.nlp_pipeline = pipeline(\n",
    "            \"ner\", \n",
    "            model=AutoModelForTokenClassification.from_pretrained(model_name),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model_name, do_lower_case=lowercase),\n",
    "            device=self.device, \n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "\n",
    "    def get_device(self):\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def parse_ner_results(self, ner_results):\n",
    "        per_entities = [e['word'] for e in ner_results if e['entity_group'] == 'PER']\n",
    "        misc_entities = [e['word'] for e in ner_results if e['entity_group'] == 'MISC']\n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    def process_query(self, query):\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        return self.parse_ner_results(self.nlp_pipeline(query))\n",
    "\n"
   ],
   "id": "a15b5f4fab282289",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.602258Z",
     "start_time": "2024-10-27T15:44:50.596802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataBase:\n",
    "    \"\"\"Handles context data extraction for people and movies from a database with fuzzy matching support.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.db = pd.read_pickle(os.path.join(os.getcwd(), \"exports/extended_graph_triples.pkl\"))\n",
    "        \n",
    "        with open(\"exports/entity_db.json\", encoding=\"utf-8\") as f:\n",
    "            self.entities = json.load(f)\n",
    "            self.entity_list = [subject.lower() for subject, _ in self.entities.values()]\n",
    "\n",
    "        self.db['subject_id'] = self.db['subject_id'].astype(str).str.strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_string(s):\n",
    "        \"\"\"Normalizes strings by removing non-ASCII characters, punctuation, and redundant spaces.\"\"\"\n",
    "        return ' '.join(re.sub(r'[^\\w\\s]', '', unicodedata.normalize('NFKD', s.lower())\n",
    "                               .encode('ascii', 'ignore').decode('utf-8')).split())\n",
    "\n",
    "    def fetch(self, entity_list, search_column):\n",
    "        \"\"\"Fetches relevant rows from the database where `search_column` matches values in `entity_list`.\"\"\"\n",
    "        relevant = self.db[self.db[search_column].isin(entity_list)].dropna(axis=1)\n",
    "        \n",
    "        if relevant.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        return relevant.pivot_table(\n",
    "            index='subject_id',\n",
    "            columns='predicate_label',\n",
    "            values='object_label',\n",
    "            aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "        ).reset_index()\n"
   ],
   "id": "c9bf6d33ae34d781",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.620550Z",
     "start_time": "2024-10-27T15:44:50.614671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QueryEmbedderContextualized:\n",
    "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v2'):\n",
    "        \"\"\"Initializes the QueryEmbedder with a SentenceTransformer model and device setup.\"\"\"\n",
    "        self.device = self.get_device()\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "        self.cache = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        \"\"\"Determines the available hardware device (MPS, CUDA, or CPU).\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    def embed_phrase(self, phrases):\n",
    "        \"\"\"\n",
    "        Generates embeddings for given phrases using SentenceTransformer, with caching.\n",
    "\n",
    "        Args:\n",
    "            phrases (str or List[str]): Input phrase(s) to embed.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Embedding vector(s) for the input phrase(s).\n",
    "        \"\"\"\n",
    "        if isinstance(phrases, str):\n",
    "            phrases = [phrases]\n",
    "        elif not isinstance(phrases, list):\n",
    "            raise TypeError(\"Input must be a string or a list of strings.\")\n",
    "        \n",
    "        phrases_to_compute = [p for p in phrases if p not in self.cache]\n",
    "        cached_embeddings = [self.cache[p] for p in phrases if p in self.cache]\n",
    "\n",
    "        if phrases_to_compute:\n",
    "            new_embeddings = self.model.encode(\n",
    "                phrases_to_compute, \n",
    "                show_progress_bar=False, \n",
    "                convert_to_numpy=True, \n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "            \n",
    "            for phrase, emb in zip(phrases_to_compute, new_embeddings):\n",
    "                self.cache[phrase] = emb\n",
    "            cached_embeddings.extend(new_embeddings)\n",
    "        \n",
    "        return cached_embeddings[0] if len(cached_embeddings) == 1 else np.array(cached_embeddings)\n"
   ],
   "id": "b6108d2c6628d7db",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.634723Z",
     "start_time": "2024-10-27T15:44:50.629218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QuestionAnsweringAgent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.qa_model = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\", top_k=1)\n",
    "    \n",
    "    def query(self, query, context_df):\n",
    "        \n",
    "        top_columns = context_df.columns\n",
    "        \n",
    "        context = \"\"\n",
    "        for index, row in context_df.iterrows():\n",
    "            node_label = row.get(\"node label\", \"\")\n",
    "            \n",
    "            row_context = f\"This text is about \\\"{node_label}\\\":\\n\"\n",
    "            \n",
    "            for col in context_df[top_columns].columns:\n",
    "                if col == \"node label\":\n",
    "                    continue\n",
    "                \n",
    "                values = row[col]\n",
    "                values_lst = str(values).split(\",\")\n",
    "                \n",
    "                if len(values_lst) > 5:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst[:5])}\"\n",
    "                else:\n",
    "                    row_context += f\"{col}: {', '.join(values_lst)}\"\n",
    "\n",
    "            context += row_context + \"\\n\\n\"\n",
    "        \n",
    "        output = self.qa_model(question=query, context=context)\n",
    "        \n",
    "        answer_str = str()\n",
    "        if isinstance(output, list) and output:\n",
    "            answer_str = \", \".join([result['answer'] for result in output])\n",
    "            \n",
    "        elif isinstance(output, dict):\n",
    "            answer_str = output['answer']\n",
    "        \n",
    "        if not answer_str:\n",
    "            answer_str = \"No answer found.\"\n",
    "        \n",
    "        return answer_str"
   ],
   "id": "9e2df2f00abd15da",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.651781Z",
     "start_time": "2024-10-27T15:44:50.643972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConversationAgent:\n",
    "    def __init__(self, model_name=\"google/flan-t5-large\", max_length=150):\n",
    "        self.device = self.get_device()\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    def generate_response(self, prompt):\n",
    "        \"\"\"\n",
    "        Generates a response based on the given prompt.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=self.max_length,\n",
    "            num_beams=5,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response.strip()\n"
   ],
   "id": "adbe62e7f66579e2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:00:17.702539Z",
     "start_time": "2024-10-27T16:00:17.692982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import rdflib\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class GraphEmbeddings:\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        \n",
    "        self.RDFS = rdflib.namespace.RDFS\n",
    "        self.WD = rdflib.Namespace('http://www.wikidata.org/entity/')\n",
    "     \n",
    "        self.entity_emb = np.load('exports/entity_embeds.npy')\n",
    "        self.relation_emb = np.load('exports/relation_embeds.npy')\n",
    "        \n",
    "        with open('exports/entity_ids.del', 'r') as ifile:\n",
    "            self.ent2id = {rdflib.term.URIRef(ent): int(idx) for idx, ent in csv.reader(ifile, delimiter='\\t')}\n",
    "            self.id2ent = {v: k for k, v in self.ent2id.items()}\n",
    "            \n",
    "        with open('exports/relation_ids.del', 'r') as ifile:\n",
    "            self.rel2id = {rdflib.term.URIRef(rel): int(idx) for idx, rel in csv.reader(ifile, delimiter='\\t')}\n",
    "        \n",
    "        with open(\"exports/predicate_db.json\", encoding=\"utf-8\") as f:\n",
    "            self.predicates_db = json.load(f)\n",
    "        \n",
    "        self.ent2lbl = {rdflib.term.URIRef(row.subject_id): row.subject_label for index, row in graph.iterrows()}\n",
    "\n",
    "    def answer_query_embedding(self, context, top_columns):\n",
    "        STD_ERROR = \"The embeddings did not provide a valid answer.\"\n",
    "        try:\n",
    "            context_id = context.subject_id.values[0]\n",
    "            if not context_id:\n",
    "                print(\"No context ID found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            e_id = self.ent2id.get(rdflib.term.URIRef(context_id))\n",
    "            if e_id is None:\n",
    "                return \"2\"\n",
    "\n",
    "            head = self.entity_emb[e_id]\n",
    "            wiki_predicate_id = \"\"\n",
    "\n",
    "            column_mapping = {\n",
    "                \"movie cast\": \"cast member\",\n",
    "                \"acted in\": \"notable work\",\n",
    "                \"played in\": \"notable work\",\n",
    "                \"appeared in\": \"notable work\",\n",
    "                \"actors\": \"cast member\",\n",
    "                \"players\": \"cast member\"\n",
    "            }\n",
    "\n",
    "            for col in top_columns:\n",
    "                \n",
    "                col = column_mapping.get(col, col)\n",
    "                \n",
    "                if col == \"node label\":\n",
    "                    continue\n",
    "                    \n",
    "                if not context[col].values[0]:\n",
    "                    continue\n",
    "\n",
    "                if col in self.predicates_db:\n",
    "                    wiki_id = rdflib.term.URIRef(self.predicates_db[col])\n",
    "                    if wiki_id in self.rel2id:\n",
    "                        wiki_predicate_id = self.predicates_db[col]\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Predicate {col} not found in rel2id.\")\n",
    "                else:\n",
    "                    print(f\"Predicate {col} not found in predicate_db.\")\n",
    "\n",
    "            if not wiki_predicate_id:\n",
    "                print(\"No valid predicate found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            r_id = self.rel2id[rdflib.term.URIRef(wiki_predicate_id)]\n",
    "            pred = self.relation_emb[r_id]\n",
    "\n",
    "            lhs = head + pred\n",
    "            dist = pairwise_distances(lhs.reshape(1, -1), self.entity_emb).reshape(-1)\n",
    "            most_likely = dist.argsort()\n",
    "\n",
    "            num_results = min(3, len(most_likely))\n",
    "            results_lst = [\n",
    "                (self.id2ent[idx][len(self.WD):], self.ent2lbl.get(self.id2ent[idx], \"\"), dist[idx], rank + 1)\n",
    "                for rank, idx in enumerate(most_likely[:num_results])\n",
    "            ]\n",
    "            results_df = pd.DataFrame(results_lst, columns=('Entity', 'Label', 'Score', 'Rank'))\n",
    "            \n",
    "            if results_df.empty:\n",
    "                print(\"No results in embeddings found.\")\n",
    "                return STD_ERROR\n",
    "\n",
    "            return f\"Top answers from embeddings: {', '.join(results_df.Label.values)}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during query answering: {e}\")\n",
    "            return STD_ERROR\n",
    "        "
   ],
   "id": "7c4c6264fcca0ba0",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.769451Z",
     "start_time": "2024-10-27T15:44:50.761118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 \n",
    "    \n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "def rescale_probabilities(similarities):\n",
    "    \"\"\"\n",
    "    Rescales the similarity scores so that they sum to 1, turning them into a probability distribution.\n",
    "    \n",
    "    Args:\n",
    "        similarities (List[float]): List of similarity scores.\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Rescaled probabilities.\n",
    "    \"\"\"\n",
    "    similarity_sum = sum(similarities)\n",
    "    if similarity_sum == 0:\n",
    "        return [0] * len(similarities)  # Avoid division by zero\n",
    "    \n",
    "    return [sim / similarity_sum for sim in similarities]\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, high_threshold=0.4, top_n=10, rescaled_threshold=0.11):\n",
    "    \"\"\"\n",
    "    Returns columns based on cosine similarity with a two-tiered strategy and rescaled probabilities.\n",
    "    - If a column has similarity above 'high_threshold', return that column immediately.\n",
    "    - Otherwise, return all columns with a similarity greater than 'low_threshold'.\n",
    "    - Rescale the top N column similarities into probabilities and return columns with a rescaled probability greater than rescaled_threshold.\n",
    "    \n",
    "    Args:\n",
    "        query_embeddings (List[np.ndarray]): Embeddings for query words.\n",
    "        column_embeddings (Dict[str, np.ndarray]): Precomputed embeddings for columns.\n",
    "        low_threshold (float): Minimum similarity threshold (default: 0.27).\n",
    "        high_threshold (float): Confidence threshold to return immediately (default: 0.35).\n",
    "        top_n (int): Number of top columns to consider for rescaling (default: 10).\n",
    "        rescaled_threshold (float): Minimum rescaled probability threshold (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: The selected column names.\n",
    "    \"\"\"\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_columns = sorted_columns[:top_n]\n",
    "    \n",
    "    column_names, similarities = zip(*top_columns)\n",
    "    \n",
    "    rescaled_probs = rescale_probabilities(similarities)\n",
    "    \n",
    "    selected_columns = []\n",
    "    \n",
    "    for col, sim in zip(column_names, similarities):\n",
    "        if sim >= high_threshold:\n",
    "            print(f\"High confidence match found: {col} with similarity {sim: .4f}\")\n",
    "            return [col]\n",
    "    \n",
    "    for col, rescaled_prob in zip(column_names, rescaled_probs):\n",
    "        if rescaled_prob >= rescaled_threshold:\n",
    "            print(f\"Column {col} has similarity {rescaled_prob: .4f}\")\n",
    "            selected_columns.append(col)\n",
    "    \n",
    "    return selected_columns"
   ],
   "id": "9b901d7c50e94cbf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.782866Z",
     "start_time": "2024-10-27T15:44:50.777714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_query(query, node_label):\n",
    "                \n",
    "    if not len(query):\n",
    "        return []\n",
    "    \n",
    "    relevant = []\n",
    "    for word in query.replace(\". \", \" \").lower().split(\" \"):\n",
    "        cleaned_word = re.sub(r'[^A-Za-z]', '', word)\n",
    "        if cleaned_word in stop_words or cleaned_word in node_label.lower().replace(\" \", \"\") or cleaned_word == \"\":\n",
    "            continue\n",
    "        \n",
    "        relevant.append(cleaned_word)\n",
    "        \n",
    "    return \" \".join(relevant)"
   ],
   "id": "6f3a2fd9e6e77d97",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.798672Z",
     "start_time": "2024-10-27T15:44:50.792534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fuzzy_match(query_str, comparison_list, threshold=30, prioritize_exact=True):\n",
    "    matches = process.extract(query_str, comparison_list, scorer=fuzz.partial_ratio, limit=50)\n",
    "        \n",
    "    id_name_score = []\n",
    "    \n",
    "    if prioritize_exact and query_str in comparison_list:\n",
    "        matched_id = next(key for key, value in db.entities.items() if value[0] == query_str)\n",
    "        id_name_score.append((matched_id, query_str, 100))\n",
    "    \n",
    "    for match in matches:\n",
    "        name = match[0]\n",
    "        score = match[1]\n",
    "        matched_id = next(key for key, value in db.entities.items() if value[0] == name)\n",
    "        \n",
    "        length_diff = abs(len(name) - len(query_str)) / len(query_str)\n",
    "        adjusted_score = score * (1 - length_diff)\n",
    "        \n",
    "        id_name_score.append((matched_id, name, adjusted_score))\n",
    "    \n",
    "    return [id for id, _, score in id_name_score if score >= threshold]"
   ],
   "id": "d2eb95481eacac33",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:50.811182Z",
     "start_time": "2024-10-27T15:44:50.804876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_matches(df, normalized_query, top_n=2):\n",
    "    concatenated_rows = df.apply(lambda row: ' '.join(row.astype(str)), axis=1).tolist()\n",
    "    \n",
    "    exact_matches = [i for i, row in enumerate(concatenated_rows) if normalized_query == row]\n",
    "    \n",
    "    if len(exact_matches) < top_n:\n",
    "        remaining_slots = top_n - len(exact_matches)\n",
    "        fuzzy_matches = process.extract(normalized_query, concatenated_rows, scorer=fuzz.partial_ratio, limit=remaining_slots)\n",
    "        fuzzy_indices = [match[2] for match in fuzzy_matches]\n",
    "    else:\n",
    "        fuzzy_indices = []\n",
    "    \n",
    "    top_indices = exact_matches + fuzzy_indices\n",
    "    \n",
    "    return df.iloc[top_indices]"
   ],
   "id": "49ae6c8781d022d6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:20:38.989863Z",
     "start_time": "2024-10-27T16:19:55.773668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = DataBase()\n",
    "\n",
    "ner_parser = NERParser(lowercase=False)\n",
    "\n",
    "qe = QueryEmbedderContextualized()\n",
    "\n",
    "qa = QuestionAnsweringAgent()\n",
    "\n",
    "ca = ConversationAgent(model_name=\"google/flan-t5-xl\") #### Could take some time, approx. 10 GB storage :)\n",
    "\n",
    "ge = GraphEmbeddings(db.db)\n"
   ],
   "id": "a9288d5aec4110c2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:55:52.858813Z",
     "start_time": "2024-10-27T15:55:52.846682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@measure_time\n",
    "def answer_query(query, correct_answer=\"\"):\n",
    "    normalized_query = db.normalize_string(query)\n",
    "    \n",
    "    entity_matches = fuzzy_match(normalized_query, db.entity_list, threshold=30)\n",
    "    \n",
    "    # NER Model and NER Matching\n",
    "    ner_person, ner_movies = ner_parser.process_query(query)\n",
    "    \n",
    "    if len(ner_movies):\n",
    "        ner_movie_entities = fuzzy_match(\" \".join(ner_movies), db.entity_list, threshold=75)\n",
    "        subjects_ner_movies = db.fetch(ner_movie_entities, \"subject_id\")\n",
    "        context_ner_movies = get_top_matches(subjects_ner_movies, normalized_query, top_n=1) \n",
    "            \n",
    "    else:\n",
    "        context_ner_movies = pd.DataFrame()\n",
    "    \n",
    "    if len(ner_person):\n",
    "        ner_person_entities = fuzzy_match(\" \".join(ner_person), db.entity_list, threshold=75)\n",
    "        subjects_ner_person = db.fetch(ner_person_entities, \"subject_id\")\n",
    "        context_ner_person = get_top_matches(subjects_ner_person, normalized_query, top_n=1)   \n",
    "                \n",
    "    else:\n",
    "        context_ner_person = pd.DataFrame()\n",
    "    \n",
    "    is_domain_specific = bool(ner_person or ner_movies)\n",
    "\n",
    "    if not is_domain_specific:\n",
    "        small_talk = ca.generate_response(query)\n",
    "        print(small_talk)\n",
    "        return\n",
    "    \n",
    "    # Fuzzy Matching\n",
    "    subjects = db.fetch(entity_matches, \"subject_id\")   \n",
    "    context = get_top_matches(subjects, normalized_query, top_n=1)    \n",
    "    \n",
    "    ner_context = pd.concat([context_ner_movies, context_ner_person])\n",
    "        \n",
    "    if not ner_context.empty:\n",
    "        context = ner_context\n",
    "    \n",
    "    try:\n",
    "        node_label = context[\"node label\"].values[0]\n",
    "    except Exception:\n",
    "        node_label = \"\"\n",
    "    \n",
    "    if context.empty:\n",
    "        print(\"No context data found for given IDs or string\")\n",
    "        context = pd.DataFrame()\n",
    "                \n",
    "        #Fallback Strategy\n",
    "        small_talk = ca.generate_small_talk(query)\n",
    "        print(small_talk)\n",
    "        return\n",
    "       \n",
    "    # EXPERIMENTAL - remove unused columns\n",
    "    elements_to_remove = [\"image\", \"color\", \"sport\"]\n",
    "    context = context.drop(columns=elements_to_remove, errors='ignore')\n",
    "    \n",
    "    # Initial context for embeddings\n",
    "    initial_context = context.copy()\n",
    "    \n",
    "    # EXPERIMENTAL - rename columns\n",
    "    columns_to_rename = {\n",
    "        \"cast member\":\"movie cast\",\n",
    "        \"notable work\": \"acted in\"\n",
    "    }\n",
    "    \n",
    "    columns_to_rename = {k: v for k, v in columns_to_rename.items() if k in context.columns}\n",
    "    context = context.rename(columns=columns_to_rename)\n",
    "    \n",
    "    columns_to_duplicate = [(\"acted in\", \"played in\"),\n",
    "                            (\"acted in\", \"appeared in\"),\n",
    "                            (\"movie cast\", \"actors\"),\n",
    "                            (\"movie cast\", \"players\")]\n",
    "    \n",
    "    for col_to_duplicate, col in columns_to_duplicate: \n",
    "        try:\n",
    "            context[col] = context[col_to_duplicate].copy()\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    context.dropna(axis=1, inplace=True)\n",
    "    \n",
    "    query_filtered = filter_query(query, node_label)\n",
    "        \n",
    "    column_embeddings = {col: qe.embed_phrase(col) for col in context.columns}\n",
    "    query_embeddings = [qe.embed_phrase(word) for word in query_filtered.split()]  \n",
    "    top_columns_embeddings = find_closest_columns(query_embeddings, column_embeddings)\n",
    "    \n",
    "    # EXPERIMENTAL\n",
    "    top_columns_dict = process.extract(normalized_query, context.columns, scorer=fuzz.partial_ratio, limit=3)\n",
    "    top_columns_fuzzy = [c[0] for c in top_columns_dict]\n",
    "    \n",
    "    # MANUAL OVERWRITE:\n",
    "    top_columns_fuzzy = []\n",
    "        \n",
    "    # EXPERIMENTAL - always keep columns\n",
    "    col_always_keep = [\"node label\"]\n",
    "    \n",
    "    combined_columns = set(top_columns_fuzzy + top_columns_embeddings + col_always_keep)\n",
    "    top_columns = [col for col in combined_columns if col in context.columns]\n",
    "    filtered_context_df = context[top_columns]\n",
    "\n",
    "    answer = qa.query(query, filtered_context_df)\n",
    "    formatted_answer = ca.generate_response(f\"Format the answer to the question into a sentence. If you think the answer is completely off, overrule with your own knowledge.Question: {query}\\nAnswer: {answer}\")\n",
    "        \n",
    "    print(ge.answer_query_embedding(initial_context, top_columns))\n",
    "    print(formatted_answer)\n"
   ],
   "id": "758512dcaa9b7d3d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:56:06.286457Z",
     "start_time": "2024-10-27T15:55:53.442358Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Tell me a joke\")",
   "id": "a2546df235e50a6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i saw a man in a tuxedo and he was wearing a tuxedo\n",
      "Execution time for answer_query: 12.8401 seconds\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:56:11.199474Z",
     "start_time": "2024-10-27T15:56:06.369441Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Tell me a good joke\")",
   "id": "3ca2ea020035a86b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you want to be a doctor, you have to be a dentist.\n",
      "Execution time for answer_query: 4.8263 seconds\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:56:14.988522Z",
     "start_time": "2024-10-27T15:56:11.287521Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hello, how is life?\")",
   "id": "468bb67207d901c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm fine, thanks.\n",
      "Execution time for answer_query: 3.6970 seconds\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:56:17.622893Z",
     "start_time": "2024-10-27T15:56:15.087129Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hello, how are you?\")",
   "id": "946f8598f3fde92d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm fine, thanks.\n",
      "Execution time for answer_query: 2.5319 seconds\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:56:19.053325Z",
     "start_time": "2024-10-27T15:56:17.724931Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Hello, what is the capital of switzerland?\")",
   "id": "31e8c5e0aef44c0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bern\n",
      "Execution time for answer_query: 1.3240 seconds\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:59:00.591537Z",
     "start_time": "2024-10-27T15:58:51.575620Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Good Will Hunting?\", \"Gus Van Sant\")",
   "id": "f9402d1107c14c35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.6866\n",
      "No valid predicate found.\n",
      "The embeddings did not provide a valid answer.\n",
      "Gus Van Sant is the director of Good Will Hunting.\n",
      "Execution time for answer_query: 9.0119 seconds\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:01:17.024471Z",
     "start_time": "2024-10-27T16:01:11.857107Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Bridge on the River Kwai?\", \"David Lean\")",
   "id": "468416428c921e05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.5111\n",
      "Predicate director not found in predicate_db.\n",
      "No valid predicate found.\n",
      "The embeddings did not provide a valid answer.\n",
      "David Lean directed The Bridge on the River Kwai.\n",
      "Execution time for answer_query: 5.1643 seconds\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:04:31.153753Z",
     "start_time": "2024-10-27T16:04:26.544778Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who directed The Dark Knight?\", \"Christopher Nolan\")",
   "id": "abbc81e04a699a72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.5111\n",
      "Predicate director not found in predicate_db.\n",
      "No valid predicate found.\n",
      "The embeddings did not provide a valid answer.\n",
      "The Dark Knight was directed by Christopher Nolan.\n",
      "Execution time for answer_query: 4.6056 seconds\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:21:30.430460Z",
     "start_time": "2024-10-27T16:21:25.294778Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Where was Angelina Jolie born?\", \"Los Angeles\")",
   "id": "b33e8b5221e04a26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: place of birth with similarity  0.4204\n",
      "Top answers from embeddings: new york city, los angeles, united states of america\n",
      "Angelina Jolie was born in Los Angeles.\n",
      "Execution time for answer_query: 5.1330 seconds\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:21:32.724342Z",
     "start_time": "2024-10-27T16:21:30.446850Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "47ade0f1dd42bdd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rupert Grint\n",
      "Execution time for answer_query: 2.2724 seconds\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T16:21:40.835428Z",
     "start_time": "2024-10-27T16:21:35.877474Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "4a4f8912be5e2679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: spouse with similarity  0.4737\n",
      "Top answers from embeddings: brad pitt, angelina jolie, jennifer aniston\n",
      "Brad Pitt was married to Angelina Jolie.\n",
      "Execution time for answer_query: 4.9537 seconds\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.211758400Z",
     "start_time": "2024-10-26T16:51:31.203778Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "b9615c76501defec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: publication date with similarity  0.4198\n",
      "2010-07-08 was Inception released.\n",
      "Execution time for answer_query: 2.2322 seconds\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.211758400Z",
     "start_time": "2024-10-26T16:51:33.445406Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "42e389076edf07fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: director with similarity  0.4614\n",
      "James Glickenhaus is the director of Star Wars.\n",
      "Execution time for answer_query: 2.3958 seconds\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.211758400Z",
     "start_time": "2024-10-26T16:51:35.848448Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was the Godfather III published?\")",
   "id": "7311213f17afb80c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: publication date with similarity  0.4091\n",
      "1972-03-15 was the Godfather III published.\n",
      "Execution time for answer_query: 1.9495 seconds\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-27T15:41:05.038910Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the director of Star Wars?\")",
   "id": "aadeab7341df5d98",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[57], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43manswer_query\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWho is the director of Star Wars?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'answer_query' is not defined"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-27T15:41:05.311406Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"When was Inception released?\")",
   "id": "8790e75b87abfd67",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43manswer_query\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen was Inception released?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'answer_query' is not defined"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-27T15:41:05.603612Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Angelina Jolie married to?\")",
   "id": "6659fd0e66bde3ee",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43manswer_query\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWho was Angelina Jolie married to?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'answer_query' is not defined"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:43.582483Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who was Brad Pitt married to?\")",
   "id": "9e8d79bc11a07fc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: spouse with similarity  0.4737\n",
      "Jennifer Aniston and Angelina Jolie were married to Brad Pitt.\n",
      "Execution time for answer_query: 2.1282 seconds\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:45.717185Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the religion of Tom Cruise?\")",
   "id": "b5602fe224c6b2c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: religion with similarity  0.6583\n",
      "Scientology is the religion of Tom Cruise.\n",
      "Execution time for answer_query: 1.6911 seconds\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:47.415215Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is the main actor in harry potter and the philosopher's stone?\")",
   "id": "caa8b85465ee7a1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rupert Grint\n",
      "Execution time for answer_query: 0.9352 seconds\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:48.418532Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who are the cast in Jurassic Park?\")",
   "id": "b8504a68fe32f6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: movie cast with similarity  0.5334\n",
      "Bd wong, laura dern, sam neill, samuel l jackson are the cast in Jurassic Park.\n",
      "Execution time for answer_query: 6.4506 seconds\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:54.876185Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who acted in Jurassic Park?\")",
   "id": "caf3e73703fed695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: actors with similarity  0.4118\n",
      "Wayne Knight acted in Jurassic Park.\n",
      "Execution time for answer_query: 1.7174 seconds\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:56.600148Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who played in Jurassic Park?\")",
   "id": "40163a1aa0c34960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: players with similarity  0.4161\n",
      "Wayne Knight played in Jurassic Park.\n",
      "Execution time for answer_query: 1.3895 seconds\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:57.996495Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Tom Cruise play?\")",
   "id": "14bcf95252a1b280",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column actors has similarity  0.1180\n",
      "Column players has similarity  0.1113\n",
      "Days of Thunder is a movie that Tom Cruise played in.\n",
      "Execution time for answer_query: 1.9912 seconds\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.212757700Z",
     "start_time": "2024-10-26T16:51:59.994426Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Rebel Wilson act?\")",
   "id": "d65e48ab10da08fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column actors has similarity  0.1657\n",
      "Column movie cast has similarity  0.1462\n",
      "Column imdb id has similarity  0.1247\n",
      "Column occupation has similarity  0.1230\n",
      "Rebel Wilson acted in Ghost Rider.\n",
      "Execution time for answer_query: 2.1311 seconds\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.213757400Z",
     "start_time": "2024-10-26T16:52:02.136231Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"In which movie did Liam Neeson play?\")",
   "id": "533e2cd752612e69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column played in has similarity  0.1265\n",
      "Column acted in has similarity  0.1202\n",
      "Liam Neeson played in Star Wars.\n",
      "Execution time for answer_query: 1.9041 seconds\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.213757400Z",
     "start_time": "2024-10-26T16:52:04.052414Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"Who is an actor in Taken 2?\")",
   "id": "5339c88d922da86d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence match found: actors with similarity  0.5670\n",
      "Maggie Grace is an actor in Taken 2.\n",
      "Execution time for answer_query: 1.5475 seconds\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.213757400Z",
     "start_time": "2024-10-26T16:52:05.610740Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"What is the role of Vin Diesel in Fast and Furious?\")",
   "id": "99208cc1e2af11c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column director has similarity  0.1230\n",
      "Column actors has similarity  0.1118\n",
      "Vin Diesel is the director of Fast and Furious.\n",
      "Execution time for answer_query: 2.0773 seconds\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:44:57.213757400Z",
     "start_time": "2024-10-26T16:52:07.705492Z"
    }
   },
   "cell_type": "code",
   "source": "answer_query(\"For which movie did Leonardo Di Caprio win an Oscar?\")",
   "id": "2e27a99aeb854ab0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column actors has similarity  0.1623\n",
      "Column imdb id has similarity  0.1592\n",
      "Column movie cast has similarity  0.1467\n",
      "Column nominated for has similarity  0.1392\n",
      "Column players has similarity  0.1264\n",
      "For which movie did Leonardo Di Caprio win an Oscar?\n",
      "Execution time for answer_query: 2.7314 seconds\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a2f48cf202f6c12b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
