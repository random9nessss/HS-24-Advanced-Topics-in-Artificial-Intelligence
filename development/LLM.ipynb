{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b90198b2b30f28f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T17:24:46.599112Z",
     "start_time": "2024-10-13T16:17:50.019817Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3597e711-ba07-44de-896c-aa0dc506cf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/gpt-j-6B were not used when initializing GPTJForCausalLM: ['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.20.attn.bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.24.attn.bias', 'transformer.h.24.attn.masked_bias', 'transformer.h.25.attn.bias', 'transformer.h.25.attn.masked_bias', 'transformer.h.26.attn.bias', 'transformer.h.26.attn.masked_bias', 'transformer.h.27.attn.bias', 'transformer.h.27.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias']\n",
      "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3a24292-11aa-44aa-a144-2fb994342bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time() \n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_duration = end_time - start_time\n",
    "        print(f\"Execution time for {func.__name__}: {execution_duration:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c0a0262b185117a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T18:35:24.320074Z",
     "start_time": "2024-10-13T18:35:24.315077Z"
    }
   },
   "outputs": [],
   "source": [
    "@execution_time\n",
    "def generate_answer(query, information):\n",
    "    try:\n",
    "        system_prompt = (\n",
    "            \"You are a knowledgeable assistant specializing in movies and well-known individuals. Your task is to answer \"\n",
    "            \"the following question as accurately and concise as possible, based on the provided context.\"\n",
    "        )\n",
    "                \n",
    "        context_parts = [system_prompt, f\"Question: {query}\\n\\n\", \"Retrieved Information:\\n\\n\"]\n",
    "        \n",
    "        for entity_id, data in information.items():\n",
    "            entity_name = data.get('entity_name', 'Unknown')\n",
    "            context_parts.append(f\"Entity: {entity_name} ({entity_id})\\n\")\n",
    "            for prop, values in data.items():\n",
    "                values = values if isinstance(values, list) else [values]\n",
    "                val_str = ', '.join(values)\n",
    "                context_parts.append(f\" - {prop}: {val_str}\\n\")\n",
    "            context_parts.append(\"\\n\")\n",
    "        \n",
    "        context_parts.append(\"Answer:\")\n",
    "        context_str = ''.join(context_parts)\n",
    "        \n",
    "        inputs = tokenizer(context_str, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens = 70,\n",
    "                num_return_sequences=1,       # Single answer\n",
    "                early_stopping=True,          # Stop early if the model has generated a reasonable output\n",
    "                temperature=1.0,              # Lower temperature for more focused answers\n",
    "                top_p=0.9                     # Nucleus sampling for a more diverse yet concise response\n",
    "            )\n",
    "        \n",
    "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        answer = answer.split(\"Answer:\")[-1].strip()\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return \"I'm sorry, I encountered an error while processing your request.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0276f8104b06a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T18:35:24.965217Z",
     "start_time": "2024-10-13T18:35:24.962864Z"
    }
   },
   "outputs": [],
   "source": [
    "context = {\n",
    "  \"Q76364\": {\n",
    "    \"entity_name\": \"Hans Zimmer\",\n",
    "    \"native language\": [\n",
    "      \"German\"\n",
    "    ],\n",
    "    \"occupation\": [\n",
    "      \"musician\"\n",
    "    ],\n",
    "    \"described by source\": [\n",
    "      \"Obalky knih.cz\"\n",
    "    ],\n",
    "    \"religion\": [\n",
    "      \"Christianity\"\n",
    "    ],\n",
    "    \"nominated for\": [\n",
    "      \"Academy Award for Best Original Musical or Comedy Score\",\n",
    "      \"Academy Award for Best Original Dramatic Score\",\n",
    "      \"Academy Award for Best Original Score\"\n",
    "    ],\n",
    "    \"languages spoken, written or signed\": [\n",
    "      \"German\"\n",
    "    ],\n",
    "    \"award received\": [\n",
    "      \"Stephen Hawking Medal For Science Communication\",\n",
    "      \"Academy Award for Best Original Score\"\n",
    "    ],\n",
    "    \"place of birth\": [\n",
    "      \"Frankfurt am Main\"\n",
    "    ],\n",
    "    \"country of citizenship\": [\n",
    "      \"Germany\"\n",
    "    ],\n",
    "    \"instance of\": [\n",
    "      \"human\"\n",
    "    ],\n",
    "    \"work location\": [\n",
    "      \"Los Angeles\"\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6602b619317177b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T18:37:12.109027Z",
     "start_time": "2024-10-13T18:35:25.318608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for generate_answer: 22.7667 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hans Zimmer was born in Frankfurt am Main, Germany.\\n\\nRetrieved Information:\\n\\nEntity: Hans Zimmer (Q76364)\\n - native language: German\\n - occupation: musician\\n - described by source: Obalky knih.cz\\n - religion: Christianity\\n - nominated for: Academy Award for Best Original Musical'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(\"Where was Hans Zimmer born?\", context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
