{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:07:40.003429Z",
     "start_time": "2024-11-13T17:07:39.458099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "db = pd.read_pickle(\"exports/extended_graph_triples.pkl\")"
   ],
   "id": "f990755a79f610dc",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:07:43.323811Z",
     "start_time": "2024-11-13T17:07:43.197829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "relevant_predicates = [\"director\", \n",
    "                       \"performer\",\n",
    "                       \"genre\",\n",
    "                       \"screenwriter\",\n",
    "                       \"cast member\",\n",
    "                       \"publication date\",\n",
    "                       \"mpaa film rating\"]\n",
    "\n",
    "db_filtered = db[db.predicate_label.isin(relevant_predicates)]\n",
    "db_filtered['object_label'] = db_filtered['object_label'].astype(str)\n",
    "db_filtered = db_filtered.copy()\n",
    "\n",
    "db_filtered.loc[db_filtered['predicate_label'] == \"publication date\", 'publication_year'] = (\n",
    "    db_filtered.loc[db_filtered['predicate_label'] == \"publication date\", 'object_label']\n",
    "    .apply(lambda x: x.split(\"-\")[0])\n",
    ")"
   ],
   "id": "321229bc7d7732dc",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:07:47.518881Z",
     "start_time": "2024-11-13T17:07:47.502527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r'exports/movie_db.json') as f:\n",
    "    movie_data = json.load(f)\n",
    "    movie_values = set(movie_data.values())"
   ],
   "id": "bda8b7bde1fd66b3",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:08:07.913843Z",
     "start_time": "2024-11-13T17:07:50.815375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import igraph as ig\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "G = ig.Graph(directed=False)\n",
    "\n",
    "node_to_index = {}\n",
    "index_to_node = []\n",
    "\n",
    "def get_or_add_node(node_label):\n",
    "    if node_label not in node_to_index:\n",
    "        index = len(index_to_node)\n",
    "        node_to_index[node_label] = index\n",
    "        index_to_node.append(node_label)\n",
    "        G.add_vertex(name=node_label)\n",
    "    return node_to_index[node_label]\n",
    "\n",
    "df = db_filtered.copy()\n",
    "df['object_label'] = df['object_label'].str.split(',')\n",
    "df = df.explode('object_label')\n",
    "df['object_label'] = df['object_label'].str.strip()\n",
    "\n",
    "edge_dict = {}\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), desc=\"Processing rows\", total=len(df)):\n",
    "    label = row['predicate_label']\n",
    "    individual_value = row['object_label']\n",
    "    movie = row['subject_label']\n",
    "    \n",
    "    value_index = get_or_add_node(individual_value)\n",
    "    movie_index = get_or_add_node(movie)\n",
    "    \n",
    "    edge = (movie_index, value_index)\n",
    "    \n",
    "    if edge in edge_dict:\n",
    "        edge_dict[edge] += 1\n",
    "    else:\n",
    "        edge_dict[edge] = 1\n",
    "\n",
    "edges_to_add = list(edge_dict.keys())\n",
    "weights = list(edge_dict.values())\n",
    "\n",
    "G.add_edges(edges_to_add)\n",
    "G.es[\"weight\"] = weights\n",
    "\n",
    "print(\"Graph construction complete.\")\n"
   ],
   "id": "592b5bfed8c8422",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing rows:   0%|          | 0/884749 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df4b6f3e53e54ff28bd24d9f3ac2c5e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph construction complete.\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:08:13.859970Z",
     "start_time": "2024-11-13T17:08:11.143949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################\n",
    "# Migration Igraph -> NetworkX\n",
    "################################\n",
    "import networkx as nx\n",
    "\n",
    "G_nx = nx.Graph()\n",
    "\n",
    "for vertex in G.vs:\n",
    "    G_nx.add_node(vertex[\"name\"])\n",
    "\n",
    "for edge in G.es:\n",
    "    source = edge.source\n",
    "    target = edge.target\n",
    "    weight = edge[\"weight\"]\n",
    "    source_label = G.vs[source][\"name\"]\n",
    "    target_label = G.vs[target][\"name\"]\n",
    "    G_nx.add_edge(source_label, target_label, weight=weight)\n",
    "\n",
    "print(\"Converted igraph to NetworkX.\")"
   ],
   "id": "213003ba5c757e56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted igraph to NetworkX.\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:08:32.926905Z",
     "start_time": "2024-11-13T17:08:32.890744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def rp_beta_recommendations_weighted(movie, G, movie_list, num_walks=50, walk_length_range=(2,4), beta_range=(0, 0.1), top_n=10):\n",
    "    \"\"\"\n",
    "    Generate recommendations using weighted RP-beta 3 with relevance-based sorting.\n",
    "    \n",
    "    Parameters:\n",
    "        - movie: The starting node (e.g., \"Hans Zimmer\", \"The Lion King\") for the random walk.\n",
    "        - G: The graph with movies and object labels.\n",
    "        - movie_list: A list of valid movies for recommendations.\n",
    "        - num_walks: Number of random walks to perform.\n",
    "        - walk_length_range: Range for walk lengths (min, max).\n",
    "        - beta_range: Range for restart probability (min, max).\n",
    "        - top_n: Number of recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "        - A list of recommended movies and their relevance scores based on weighted RP-beta 3.\n",
    "    \"\"\"\n",
    "    all_walks = []\n",
    "    relevance_scores = defaultdict(float)\n",
    "    \n",
    "    for _ in range(num_walks):\n",
    "        walk = [movie]\n",
    "        current_node = movie\n",
    "        walk_length = random.randint(*walk_length_range)\n",
    "        beta = random.uniform(*beta_range)\n",
    "        \n",
    "        for _ in range(walk_length - 1):\n",
    "            if random.random() < beta:\n",
    "                current_node = movie\n",
    "            else:\n",
    "                neighbors = list(G.neighbors(current_node))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                \n",
    "                weights = [G[current_node][neighbor].get(\"weight\", 1) for neighbor in neighbors]\n",
    "                total_weight = sum(weights)\n",
    "                probabilities = [weight / total_weight for weight in weights]\n",
    "                \n",
    "                next_node = random.choices(neighbors, probabilities, k=1)[0]\n",
    "                \n",
    "                if next_node != movie:\n",
    "                    relevance_scores[next_node] += G[current_node][next_node].get(\"weight\", 1)\n",
    "                \n",
    "                walk.append(next_node)\n",
    "                current_node = next_node\n",
    "        \n",
    "        all_walks.extend(walk)\n",
    "    \n",
    "    sorted_recommendations = sorted(\n",
    "        ((movie, score) for movie, score in relevance_scores.items() if movie in movie_list),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    recommendations = sorted_recommendations[:top_n]\n",
    "    return recommendations\n",
    "\n",
    "recommendations = rp_beta_recommendations_weighted(\"the lion king\", G_nx, movie_values)\n",
    "\n",
    "print(\"Top recommendations by relevance:\")\n",
    "for movie, score in recommendations:\n",
    "    print(f\"{movie}: {score:.2f}\")\n"
   ],
   "id": "f6b18b5c627e4fd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations by relevance:\n",
      "family film: 3.00\n",
      "open season: 2.00\n",
      "whisper 3: 1.00\n",
      "a hatful of rain: 1.00\n",
      "school of rock: 1.00\n",
      "neighbors 2: 1.00\n",
      "hodet over vannet: 1.00\n",
      "alvin and the chipmunks chipwrecked: 1.00\n",
      "samson: 1.00\n",
      "some kind of monster: 1.00\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:08:44.824523Z",
     "start_time": "2024-11-13T17:08:44.808728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recommendations_one = rp_beta_recommendations_weighted(\"a nightmare on elm street\", G_nx, movie_values)\n",
    "print(\"Top recommendations by relevance:\")\n",
    "for movie, score in recommendations_one:\n",
    "    print(f\"{movie}: {score:.2f}\")"
   ],
   "id": "2e9671740ff6fc66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations by relevance:\n",
      "paris je taime: 3.00\n",
      "childs play: 3.00\n",
      "fear clinic: 2.00\n",
      "salvage: 2.00\n",
      "r xmas: 1.00\n",
      "final analysis: 1.00\n",
      "urban legends final cut: 1.00\n",
      "the girl with the dragon tattoo: 1.00\n",
      "sheitan: 1.00\n",
      "the appeared: 1.00\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:08:49.955166Z",
     "start_time": "2024-11-13T17:08:49.947989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recommendations_two = rp_beta_recommendations_weighted(\"friday the 13th\", G_nx, movie_values)\n",
    "print(\"Top recommendations by relevance:\")\n",
    "for movie, score in recommendations_two:\n",
    "    print(f\"{movie}: {score:.2f}\")"
   ],
   "id": "4a7855d7dc62c365",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations by relevance:\n",
      "crystal lake memories the complete history of friday the 13th: 3.00\n",
      "silent night deadly night: 2.00\n",
      "going to pieces the rise and fall of the slasher film: 2.00\n",
      "the gingerdead man: 2.00\n",
      "nothing: 1.00\n",
      "american pastime: 1.00\n",
      "house of wax: 1.00\n",
      "final destination 5: 1.00\n",
      "hansel gretel witch hunters: 1.00\n",
      "reeker: 1.00\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T17:08:53.307330Z",
     "start_time": "2024-11-13T17:08:53.298060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recommendations_three = rp_beta_recommendations_weighted(\"halloween\", G_nx, movie_values)\n",
    "print(\"Top recommendations by relevance:\")\n",
    "for movie, score in recommendations_three:\n",
    "    print(f\"{movie}: {score:.2f}\")"
   ],
   "id": "a0611f8a5d147744",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations by relevance:\n",
      "the fog: 4.00\n",
      "black christmas: 3.00\n",
      "george washington: 2.00\n",
      "halloween ii: 2.00\n",
      "invaders from mars: 2.00\n",
      "dawn of the dead: 2.00\n",
      "manglehorn: 2.00\n",
      "hairspray: 2.00\n",
      "machete: 1.00\n",
      "the brady bunch movie: 1.00\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96407c33a1dcc3ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:38:05.354230Z",
     "start_time": "2024-11-13T13:38:05.350416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_string(s):\n",
    "    \"\"\"Normalizes strings by removing non-ASCII characters, punctuation, and selected stopwords.\"\"\"\n",
    "    return ' '.join(re.sub(r'[^\\w\\s]', '', unicodedata.normalize('NFKD', s.lower())\n",
    "                                 .encode('ascii', 'ignore').decode('utf-8')).split())\n",
    "    "
   ],
   "id": "e3b8514e14076b1",
   "outputs": [],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:38:05.852562Z",
     "start_time": "2024-11-13T13:38:05.847413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def fuzzy_match(query_str, comparison_list):\n",
    "    normalized_query = normalize_string(query_str)    \n",
    "    entities = {**movie_data, **people_data}\n",
    "    name_to_id = {v: k for k, v in entities.items()}\n",
    "\n",
    "    longest_full_match = \"\"\n",
    "    longest_full_length = 0\n",
    "    longest_prefix_match = \"\"\n",
    "    longest_prefix_length = 0\n",
    "    longest_suffix_match = \"\"\n",
    "    longest_suffix_length = 0\n",
    "\n",
    "    full_matches = []\n",
    "    prefix_matches = []\n",
    "    suffix_matches = []\n",
    "                \n",
    "    for subject in comparison_list:\n",
    "        if \"porn\" in subject:\n",
    "            continue\n",
    "        \n",
    "        subject_tokens = normalize_string(subject).split()\n",
    "        normalized_subject = normalize_string(subject)\n",
    "        \n",
    "        # Check for full match within the query\n",
    "        if normalized_subject in normalized_query:\n",
    "            full_matches.append((subject, len(subject)))\n",
    "            if len(subject) > longest_full_length:\n",
    "                longest_full_match = subject\n",
    "                longest_full_length = len(subject)\n",
    "\n",
    "        # Check for prefix match\n",
    "        for i in range(len(normalized_subject), 0, -1):\n",
    "            if normalized_subject[:i] == normalized_query[:i] and len(normalized_subject) > len(normalized_query):\n",
    "                prefix_matches.append((subject, i))\n",
    "                if i > longest_prefix_length:\n",
    "                    longest_prefix_match = subject\n",
    "                    longest_prefix_length = i\n",
    "                break\n",
    "        \n",
    "        # Check for suffix match\n",
    "        for i in range(len(subject_tokens), 0, -1):\n",
    "            suffix_sequence = \" \".join(subject_tokens[-i:])\n",
    "            if suffix_sequence in normalized_query:\n",
    "                suffix_matches.append((subject, len(suffix_sequence)))\n",
    "                if len(suffix_sequence) > longest_suffix_length:\n",
    "                    longest_suffix_match = subject\n",
    "                    longest_suffix_length = len(suffix_sequence)\n",
    "                break\n",
    "        \n",
    "    top_full_matches = sorted(full_matches, key=lambda x: x[1], reverse=True)[:5]\n",
    "    top_prefix_matches = sorted(prefix_matches, key=lambda x: x[1], reverse=True)[:5]\n",
    "    top_suffix_matches = sorted(suffix_matches, key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    if top_full_matches:\n",
    "        print(\"Top FULL matches:\")\n",
    "        for match in set(top_full_matches):\n",
    "            print(f\"Match: {match[0]}, Length: {match[1]}\")\n",
    "            \n",
    "    elif top_prefix_matches:\n",
    "        print(\"Top PREFIX matches:\")\n",
    "        for match in set(top_prefix_matches):\n",
    "            print(f\"Match: {match[0]}, Length: {match[1]}\")\n",
    "    \n",
    "    elif top_suffix_matches:\n",
    "        print(\"Top SUFFIX matches:\")\n",
    "        for match in set(top_suffix_matches):\n",
    "            print(f\"Match: {match[0]}, Length: {match[1]}\")    \n",
    "    "
   ],
   "id": "cd840643fc48e12d",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:38:06.458826Z",
     "start_time": "2024-11-13T13:38:06.456670Z"
    }
   },
   "cell_type": "code",
   "source": "example_query = \"Recommend movies like Nightmare on Elm Street, Friday the 13th, and Halloween.\"",
   "id": "7e975ec6d109c36c",
   "outputs": [],
   "execution_count": 285
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:38:07.065603Z",
     "start_time": "2024-11-13T13:38:07.004311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(r'exports/movie_db.json') as f:\n",
    "    movie_data = json.load(f)\n",
    "    movie_ids = set(movie_data.keys())\n",
    "movie_db = pd.DataFrame(list(movie_data.items()), columns=[\"entity_id\", \"entity_label\"])\n",
    "\n",
    "with open(r'exports/people_db.json') as f:\n",
    "    people_data = json.load(f)\n",
    "    people_ids = set(people_data.keys())\n",
    "people_db = pd.DataFrame(list(people_data.items()), columns=[\"entity_id\", \"entity_label\"])"
   ],
   "id": "952ddbfca112e9c9",
   "outputs": [],
   "execution_count": 286
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:38:08.131628Z",
     "start_time": "2024-11-13T13:38:07.665723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fuzzy_match(example_query, movie_db.entity_label.tolist())\n",
    "fuzzy_match(example_query, people_db.entity_label.tolist())"
   ],
   "id": "2d0444e62d3901d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top FULL matches:\n",
      "Match: friday the 13th, Length: 15\n",
      "Match: halloween, Length: 9\n",
      "Top FULL matches:\n",
      "Match: , Length: 0\n"
     ]
    }
   ],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T13:38:09.693373Z",
     "start_time": "2024-11-13T13:38:09.681984Z"
    }
   },
   "cell_type": "code",
   "source": "movie_db[movie_db.entity_label.str.endswith(\"elm street\")]",
   "id": "5d620c5879f4bb82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     entity_id               entity_label\n",
       "19785  http://www.wikidata.org/entity/Q4660616  a wet dream on elm street\n",
       "22206   http://www.wikidata.org/entity/Q300508  a nightmare on elm street\n",
       "23875   http://www.wikidata.org/entity/Q329434  a nightmare on elm street"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19785</th>\n",
       "      <td>http://www.wikidata.org/entity/Q4660616</td>\n",
       "      <td>a wet dream on elm street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22206</th>\n",
       "      <td>http://www.wikidata.org/entity/Q300508</td>\n",
       "      <td>a nightmare on elm street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23875</th>\n",
       "      <td>http://www.wikidata.org/entity/Q329434</td>\n",
       "      <td>a nightmare on elm street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 288
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60f1b6b86ffbcd40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
