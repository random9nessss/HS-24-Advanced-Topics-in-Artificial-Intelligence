{
 "cells": [
  {
   "cell_type": "code",
   "id": "cb1a0741-cfeb-4f56-8575-e421f525b8cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T05:42:13.683337Z",
     "start_time": "2024-10-10T05:41:26.433343Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "class NERParser:\n",
    "    def __init__(self, model_name: str = \"dslim/bert-base-NER\", lowercase: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the NER parser with a model and optionally configure the lowercase preprocessing.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "        \n",
    "        # Load the tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set up the NER pipeline\n",
    "        self.nlp_pipeline = pipeline(\"ner\", \n",
    "                                     model=self.model, \n",
    "                                     tokenizer=self.tokenizer, \n",
    "                                     device=self.device, \n",
    "                                     aggregation_strategy=\"simple\")\n",
    "\n",
    "    def get_device(self):\n",
    "        \"\"\"\n",
    "        Determines whether to use MPS, CUDA, or CPU depending on the available hardware.\n",
    "        \"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"MPS device found, using MPS backend.\\n\")\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            print(f\"CUDA device found, using CUDA backend. Device: {torch.cuda.get_device_name(0)}\\n\")\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            print(\"Neither MPS nor CUDA found, using CPU.\\n\")\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    \n",
    "    def parse_ner_results(self, ner_results: list):\n",
    "        \"\"\"\n",
    "        Parse the NER results and extract entities related to 'PER' (persons) and 'MISC' (potential movie titles).\n",
    "        \"\"\"\n",
    "        per_entities, misc_entities = [], []\n",
    "        \n",
    "        for entity in ner_results:\n",
    "            # Extraction of all Persons\n",
    "            if entity['entity_group'] == 'PER':\n",
    "                per_entities.append(entity['word'])\n",
    "            # Extraction of all Misc that could indicate movies\n",
    "            elif entity['entity_group'] == 'MISC':\n",
    "                misc_entities.append(entity['word'])\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    \n",
    "    def process_query(self, query: str):\n",
    "        \"\"\"\n",
    "        Processes a text query, runs NER, and returns the extracted actors and movie names.\n",
    "        \"\"\"\n",
    "        # Optionally lowercase the input if configured\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        \n",
    "        # Run the NER pipeline\n",
    "        ner_results = self.nlp_pipeline(query)\n",
    "\n",
    "        # Parse the results to extract actors and movies\n",
    "        per_entities, misc_entities = self.parse_ner_results(ner_results)\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "\n",
    "##################\n",
    "### Example usage\n",
    "##################\n",
    "ner_parser = NERParser(lowercase=False)\n",
    "query_one = \"Did Kate Winslet and Leonardo Di Caprio play in Titanic?\"\n",
    "actors, movies = ner_parser.process_query(query_one)\n",
    "print(\"Actors:\", actors)\n",
    "print(\"Movies:\", movies)\n",
    "print(\"\\n\")\n",
    "\n",
    "query_two = \"I like Steven Spielberg, can you recommend me similar directors?\"\n",
    "actors, movies = ner_parser.process_query(query_two)\n",
    "print(\"Actors:\", actors)\n",
    "print(\"Movies:\", movies)\n",
    "print(\"\\n\")\n",
    "\n",
    "query_three = \"Who played in the movie Inception?\"\n",
    "actors, movies = ner_parser.process_query(query_three)\n",
    "print(\"Actors:\", actors)\n",
    "print(\"Movies:\", movies)\n",
    "print(\"\\n\")\n",
    "\n",
    "query_four = \"Produced by Steven Spielberg, Kate Winslet and Angelina Jolie played in Titanic is this correct?\"\n",
    "actors, movies = ner_parser.process_query(query_four)\n",
    "print(\"Actors:\", actors)\n",
    "print(\"Movies:\", movies)\n",
    "print(\"\\n\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\UntrackedFolder\\movie-bot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither MPS nor CUDA found, using CPU.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\UntrackedFolder\\movie-bot\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sandr\\.cache\\huggingface\\hub\\models--dslim--bert-base-NER. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actors: ['Kate Winslet', 'Leonardo Di Caprio']\n",
      "Movies: ['Titanic']\n",
      "\n",
      "\n",
      "Actors: ['Steven Spielberg']\n",
      "Movies: []\n",
      "\n",
      "\n",
      "Actors: []\n",
      "Movies: ['Inception']\n",
      "\n",
      "\n",
      "Actors: ['Steven Spielberg', 'Kate Winslet', 'Angelina Jolie']\n",
      "Movies: ['Titanic']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8abdba8c-aa2c-42b7-9ac7-3c10d4cea586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T05:42:13.719870Z",
     "start_time": "2024-10-10T05:42:13.714735Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
