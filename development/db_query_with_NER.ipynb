{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:18.781178Z",
     "start_time": "2024-10-16T17:20:18.769045Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import pipeline"
   ],
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:19.426365Z",
     "start_time": "2024-10-16T17:20:19.000448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "class NERParser:\n",
    "    def __init__(self, model_name: str = \"dslim/bert-base-NER\", lowercase: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the NER parser with a model and optionally configure the lowercase preprocessing.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.lowercase = lowercase\n",
    "        self.device = self.get_device()\n",
    "        \n",
    "        # Load the tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, do_lower_case=self.lowercase)\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Set up the NER pipeline\n",
    "        self.nlp_pipeline = pipeline(\"ner\", \n",
    "                                     model=self.model, \n",
    "                                     tokenizer=self.tokenizer, \n",
    "                                     device=self.device, \n",
    "                                     aggregation_strategy=\"simple\")\n",
    "\n",
    "    def get_device(self):\n",
    "        \"\"\"\n",
    "        Determines whether to use MPS, CUDA, or CPU depending on the available hardware.\n",
    "        \"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            print(\"MPS device found, using MPS backend.\\n\")\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            print(f\"CUDA device found, using CUDA backend. Device: {torch.cuda.get_device_name(0)}\\n\")\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            print(\"Neither MPS nor CUDA found, using CPU.\\n\")\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    \n",
    "    def parse_ner_results(self, ner_results: list):\n",
    "        \"\"\"\n",
    "        Parse the NER results and extract entities related to 'PER' (persons) and 'MISC' (potential movie titles).\n",
    "        \"\"\"\n",
    "        per_entities, misc_entities = [], []\n",
    "        \n",
    "        for entity in ner_results:\n",
    "            # Extraction of all Persons\n",
    "            if entity['entity_group'] == 'PER':\n",
    "                per_entities.append(entity['word'])\n",
    "            # Extraction of all Misc that could indicate movies\n",
    "            elif entity['entity_group'] == 'MISC':\n",
    "                misc_entities.append(entity['word'])\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "    \n",
    "    def process_query(self, query: str):\n",
    "        \"\"\"\n",
    "        Processes a text query, runs NER, and returns the extracted actors and movie names.\n",
    "        \"\"\"\n",
    "        # Optionally lowercase the input if configured\n",
    "        if self.lowercase:\n",
    "            query = query.lower()\n",
    "        \n",
    "        # Run the NER pipeline\n",
    "        ner_results = self.nlp_pipeline(query)\n",
    "\n",
    "        # Parse the results to extract actors and movies\n",
    "        per_entities, misc_entities = self.parse_ner_results(ner_results)\n",
    "        \n",
    "        return per_entities, misc_entities\n",
    "\n",
    "ner_parser = NERParser(lowercase=False)"
   ],
   "id": "471a5a310f6ee704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither MPS nor CUDA found, using CPU.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:20.341267Z",
     "start_time": "2024-10-16T17:20:19.429402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# db = pd.read_pickle('exports/graph.pkl')\n",
    "db = pd.read_pickle(\"exports/extended_graph_triples.pkl\")\n",
    "reverse_index = pd.read_pickle(\"./exports/reverse_index.pkl\")"
   ],
   "id": "451f143f83042411",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:20.612292Z",
     "start_time": "2024-10-16T17:20:20.526939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# query = \"Where was Angela Jolie born?\"\n",
    "# query = \"In which movies did Angela Jolie have a role?\"\n",
    "query = \"Who is the director of Star Wars: Episode VI - Return of the Jedi?\" # Richard Marquand\n",
    "# query = \"Who is the screenwriter of The Masked Gang: Cyprus?\" # Cengiz Küçükayvaz\n",
    "# query = \"When was 'The Godfather' released?\" # 1972\n",
    "person, movies = ner_parser.process_query(query)"
   ],
   "id": "6a7abea64180c1a4",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:21.413955Z",
     "start_time": "2024-10-16T17:20:20.822756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db['subject_id'] = db['subject_id'].str.strip()\n",
    "db['subject_label'] = db['subject_label'].str.strip()\n",
    "db['predicate_label'] = db['predicate_label'].str.strip()\n",
    "db['object_label'] = db['object_label'].str.strip()"
   ],
   "id": "ec6a516fd0763149",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:21.642432Z",
     "start_time": "2024-10-16T17:20:21.636609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_df_by_label(labels:list):\n",
    "    context_person = list()\n",
    "    for p in labels:\n",
    "    \n",
    "        # Levenshtein matching for closest match\n",
    "        matched_subject_label = process.extractOne(p, reverse_index.subject_label, scorer=fuzz.ratio)\n",
    "        \n",
    "        if not matched_subject_label or not matched_subject_label[1] > 80:\n",
    "            continue\n",
    "    \n",
    "        closest_match_label = matched_subject_label[0]\n",
    "        \n",
    "        lst_of_ids = reverse_index.get(reverse_index.subject_label == closest_match_label, []).subject_id.to_list()\n",
    "        \n",
    "        if len(lst_of_ids) == 0:\n",
    "            continue\n",
    "    \n",
    "        relevant = db[db.subject_id.isin(lst_of_ids)].dropna(axis=1)\n",
    "        for index, row in relevant.iterrows():\n",
    "            context_person.append(row)\n",
    "        \n",
    "    c_df = pd.DataFrame(\n",
    "        data=context_person,\n",
    "        columns=['subject_id', 'subject_label', 'predicate_label', 'object_label']\n",
    "    )\n",
    "    \n",
    "    c_df.set_index('subject_id', inplace=True)\n",
    "    \n",
    "    if 'object_label' not in c_df.columns:\n",
    "        print(c_df.columns)\n",
    "        raise KeyError(\"The 'object_label' column is missing from the DataFrame.\")\n",
    "\n",
    "    # Pivot the DataFrame with a custom aggregation function\n",
    "    pivot_df = c_df.pivot_table(\n",
    "        index='subject_id',\n",
    "        columns='predicate_label',\n",
    "        values='object_label',\n",
    "        aggfunc=lambda x: ' | '.join(x.astype(str))\n",
    "    )\n",
    "    \n",
    "    return pivot_df\n"
   ],
   "id": "6e870a8029e45bec",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:21.968694Z",
     "start_time": "2024-10-16T17:20:21.839650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_df_person = get_df_by_label(person)\n",
    "context_df_movie = get_df_by_label(movies)"
   ],
   "id": "e42ace3fd0c21cd9",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:22.191768Z",
     "start_time": "2024-10-16T17:20:22.188674Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c967e47d27e5054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:22.398072Z",
     "start_time": "2024-10-16T17:20:22.391320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_df_movie = context_df_movie.rename(columns={'node label': 'name'})\n",
    "context_df_person = context_df_person.rename(columns={'node label': 'name'})\n",
    "\n",
    "context_df_movie = context_df_movie.rename(columns={'publication date': 'release date publication'})\n",
    "context_df_person = context_df_person.rename(columns={'cast member': 'movies cast role play'})"
   ],
   "id": "8894b50a2c235caa",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:22.635713Z",
     "start_time": "2024-10-16T17:20:22.628049Z"
    }
   },
   "cell_type": "code",
   "source": "context_df_person.head()",
   "id": "748cb768b4c9a46b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicate_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:22.900986Z",
     "start_time": "2024-10-16T17:20:22.889002Z"
    }
   },
   "cell_type": "code",
   "source": "context_df_movie.head()",
   "id": "6d79561b617b2744",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicate_label                            IMDb ID              assessment  \\\n",
       "subject_id                                                                   \n",
       "http://www.wikidata.org/entity/Q3795587  tt0145929  reverse Mako Mori test   \n",
       "\n",
       "predicate_label                             award received  \\\n",
       "subject_id                                                   \n",
       "http://www.wikidata.org/entity/Q3795587  Czech Lion Awards   \n",
       "\n",
       "predicate_label                                                                cast member  \\\n",
       "subject_id                                                                                   \n",
       "http://www.wikidata.org/entity/Q3795587  Petr Vydra, Zdena Hadrbolcová, Jiří Macháček, ...   \n",
       "\n",
       "predicate_label                          color  costume designer  \\\n",
       "subject_id                                                         \n",
       "http://www.wikidata.org/entity/Q3795587  color  Milica Gedeonová   \n",
       "\n",
       "predicate_label                                country of origin     director  \\\n",
       "subject_id                                                                      \n",
       "http://www.wikidata.org/entity/Q3795587  Germany, Czech Republic  Saša Gedeon   \n",
       "\n",
       "predicate_label                         director of photography  film editor  \\\n",
       "subject_id                                                                     \n",
       "http://www.wikidata.org/entity/Q3795587           Štěpán Kučera  Petr Turyna   \n",
       "\n",
       "predicate_label                          ...     make-up artist  \\\n",
       "subject_id                               ...                      \n",
       "http://www.wikidata.org/entity/Q3795587  ...  Michaela Belíková   \n",
       "\n",
       "predicate_label                                  node description  \\\n",
       "subject_id                                                          \n",
       "http://www.wikidata.org/entity/Q3795587  1999 film by Saša Gedeon   \n",
       "\n",
       "predicate_label                                         name  \\\n",
       "subject_id                                                     \n",
       "http://www.wikidata.org/entity/Q3795587  Return of the Idiot   \n",
       "\n",
       "predicate_label                                                      nominated for  \\\n",
       "subject_id                                                                           \n",
       "http://www.wikidata.org/entity/Q3795587  European Film Award for Best Screenwriter   \n",
       "\n",
       "predicate_label                         original language of film or TV show  \\\n",
       "subject_id                                                                     \n",
       "http://www.wikidata.org/entity/Q3795587                                Czech   \n",
       "\n",
       "predicate_label                                     participant in  \\\n",
       "subject_id                                                           \n",
       "http://www.wikidata.org/entity/Q3795587  12th European Film Awards   \n",
       "\n",
       "predicate_label                                                production company  \\\n",
       "subject_id                                                                          \n",
       "http://www.wikidata.org/entity/Q3795587  Negativ Film Productions, Česká televize   \n",
       "\n",
       "predicate_label                         release date publication screenwriter  \\\n",
       "subject_id                                                                      \n",
       "http://www.wikidata.org/entity/Q3795587               1999-02-25  Saša Gedeon   \n",
       "\n",
       "predicate_label                                            winner  \n",
       "subject_id                                                         \n",
       "http://www.wikidata.org/entity/Q3795587  Czech Lion for Best Film  \n",
       "\n",
       "[1 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicate_label</th>\n",
       "      <th>IMDb ID</th>\n",
       "      <th>assessment</th>\n",
       "      <th>award received</th>\n",
       "      <th>cast member</th>\n",
       "      <th>color</th>\n",
       "      <th>costume designer</th>\n",
       "      <th>country of origin</th>\n",
       "      <th>director</th>\n",
       "      <th>director of photography</th>\n",
       "      <th>film editor</th>\n",
       "      <th>...</th>\n",
       "      <th>make-up artist</th>\n",
       "      <th>node description</th>\n",
       "      <th>name</th>\n",
       "      <th>nominated for</th>\n",
       "      <th>original language of film or TV show</th>\n",
       "      <th>participant in</th>\n",
       "      <th>production company</th>\n",
       "      <th>release date publication</th>\n",
       "      <th>screenwriter</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://www.wikidata.org/entity/Q3795587</th>\n",
       "      <td>tt0145929</td>\n",
       "      <td>reverse Mako Mori test</td>\n",
       "      <td>Czech Lion Awards</td>\n",
       "      <td>Petr Vydra, Zdena Hadrbolcová, Jiří Macháček, ...</td>\n",
       "      <td>color</td>\n",
       "      <td>Milica Gedeonová</td>\n",
       "      <td>Germany, Czech Republic</td>\n",
       "      <td>Saša Gedeon</td>\n",
       "      <td>Štěpán Kučera</td>\n",
       "      <td>Petr Turyna</td>\n",
       "      <td>...</td>\n",
       "      <td>Michaela Belíková</td>\n",
       "      <td>1999 film by Saša Gedeon</td>\n",
       "      <td>Return of the Idiot</td>\n",
       "      <td>European Film Award for Best Screenwriter</td>\n",
       "      <td>Czech</td>\n",
       "      <td>12th European Film Awards</td>\n",
       "      <td>Negativ Film Productions, Česká televize</td>\n",
       "      <td>1999-02-25</td>\n",
       "      <td>Saša Gedeon</td>\n",
       "      <td>Czech Lion for Best Film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:22.954863Z",
     "start_time": "2024-10-16T17:20:22.946496Z"
    }
   },
   "cell_type": "code",
   "source": "context_df_movie.columns",
   "id": "a3d0aa661e75fcee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IMDb ID', 'assessment', 'award received', 'cast member', 'color',\n",
       "       'costume designer', 'country of origin', 'director',\n",
       "       'director of photography', 'film editor', 'genre', 'inspired by',\n",
       "       'instance of', 'main subject', 'make-up artist', 'node description',\n",
       "       'name', 'nominated for', 'original language of film or TV show',\n",
       "       'participant in', 'production company', 'release date publication',\n",
       "       'screenwriter', 'winner'],\n",
       "      dtype='object', name='predicate_label')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:23.021289Z",
     "start_time": "2024-10-16T17:20:23.007462Z"
    }
   },
   "cell_type": "code",
   "source": "context_df_person.columns",
   "id": "f131f02b3a8c3a50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object', name='predicate_label')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:23.274383Z",
     "start_time": "2024-10-16T17:20:23.267508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = 'input/glove.6B.zip'\n",
    "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "\n",
    "if not os.path.exists(input_dir):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    with open(input_dir, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"File already exists, skipped download.\")"
   ],
   "id": "63a08a0603be6a2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipped download.\n"
     ]
    }
   ],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:23.294167Z",
     "start_time": "2024-10-16T17:20:23.289123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zip_file_path = 'input/glove.6B.zip'\n",
    "extract_to_path = 'exports/glove.6B'\n",
    "\n",
    "if not os.path.exists(extract_to_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to_path)\n",
    "    print(\"Unzipping complete!\")\n",
    "else:\n",
    "    print(\"Out dir already exists, skipped unzipping.\")"
   ],
   "id": "2a0f254a37c9a948",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out dir already exists, skipped unzipping.\n"
     ]
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:37.267318Z",
     "start_time": "2024-10-16T17:20:23.503448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Load the GloVe embeddings (300-dimensional)\n",
    "glove_embeddings = load_glove_embeddings(\"exports/glove.6B/glove.6B.300d.txt\")"
   ],
   "id": "c7480ef7d1a7759",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:37.451522Z",
     "start_time": "2024-10-16T17:20:37.445444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def embed_phrase(phrase, embeddings):\n",
    "    words = phrase.split()\n",
    "    word_vectors = [embeddings[word.lower()] for word in words if word.lower() in embeddings]\n",
    "    \n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(300)  # Return zero vector if no words have embeddings\n",
    "    \n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Embed column names of knowledge graph db\n",
    "column_embeddings = {col: embed_phrase(col, glove_embeddings) for col in context_df_person.columns}"
   ],
   "id": "92ce6e4a8bab828f",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:37.665266Z",
     "start_time": "2024-10-16T17:20:37.658730Z"
    }
   },
   "cell_type": "code",
   "source": "column_embeddings",
   "id": "65587fe9be893d04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:37.887037Z",
     "start_time": "2024-10-16T17:20:37.881021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "id": "b1f51487ce3c58d5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:38.105104Z",
     "start_time": "2024-10-16T17:20:38.099751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_query(query):\n",
    "    \n",
    "    person_list = [p.split(\" \") for p in person][0] if len(person) else []\n",
    "    movie_list = [m.split(\" \") for m in movies][0] if len(movies) else []\n",
    "        \n",
    "    if not len(query):\n",
    "        return []\n",
    "    \n",
    "    relevant = []\n",
    "    for word in query.split(\" \"):\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        \n",
    "        if word in person_list:            \n",
    "            continue\n",
    "        \n",
    "        if word in movie_list:\n",
    "            continue\n",
    "        \n",
    "        relevant.append(word)\n",
    "        \n",
    "    return relevant\n",
    "    "
   ],
   "id": "f72ff1c38edcb426",
   "outputs": [],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:38.313372Z",
     "start_time": "2024-10-16T17:20:38.307150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_query = filter_query(query)\n",
    "query_embeddings = [embed_phrase(word, glove_embeddings) for word in filtered_query]\n"
   ],
   "id": "5fd557218b67556c",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:38.506565Z",
     "start_time": "2024-10-16T17:20:38.500101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_sim(vec1, vec2):\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 \n",
    "    \n",
    "    return np.dot(vec1, vec2) / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def find_closest_columns(query_embeddings, column_embeddings, top_n=5):\n",
    "    column_similarities = {}\n",
    "\n",
    "    for col, col_vec in column_embeddings.items():\n",
    "        similarities = [cosine_sim(col_vec, q_vec) for q_vec in query_embeddings if np.linalg.norm(q_vec) > 0]\n",
    "        column_similarities[col] = np.mean(similarities) if similarities else -1\n",
    "\n",
    "    sorted_columns = sorted(column_similarities.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    return [col for col, sim in sorted_columns[:top_n]]\n",
    "\n",
    "top_columns = find_closest_columns(query_embeddings, column_embeddings, top_n=5)\n",
    "\n",
    "print(\"Top columns:\", top_columns)"
   ],
   "id": "722b0cf94ae3ac97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top columns: []\n"
     ]
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:38.703759Z",
     "start_time": "2024-10-16T17:20:38.698247Z"
    }
   },
   "cell_type": "code",
   "source": "context_df = pd.concat([context_df_person, context_df_movie], axis=0)",
   "id": "1d5f671d2ea71901",
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:20:38.923656Z",
     "start_time": "2024-10-16T17:20:38.915003Z"
    }
   },
   "cell_type": "code",
   "source": "context_df[top_columns]",
   "id": "7c34a460909553e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [http://www.wikidata.org/entity/Q3795587]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicate_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://www.wikidata.org/entity/Q3795587</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-16T17:20:39.138998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Introduce a swift llm that can generate the answer based on the context_df\n",
    "# Load pre-trained DistilBERT model for question answering\n",
    "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", top_k=1)"
   ],
   "id": "801a70527d2cce60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:19:50.762645Z",
     "start_time": "2024-10-16T17:19:50.638028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Context and query\n",
    "context = \"\"\n",
    "for index, row in context_df.iterrows():\n",
    "    row_context = \" \".join([f\"{col}: {row[col]}\" for col in context_df[top_columns].columns])\n",
    "    context += row_context + \" \"\n",
    "\n",
    "# Generate the answer\n",
    "output = qa_model(question=query, context=context)\n",
    "\n",
    "answer_str = str()\n",
    "if isinstance(output, list):\n",
    "    answer_str = \", \".join([result['answer'] for result in output])\n",
    "elif isinstance(output, dict):\n",
    "    answer_str = output['answer']\n",
    "\n",
    "if not answer_str:\n",
    "    answer_str = \"No answer found.\""
   ],
   "id": "5f18fa17907efff1",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:19:53.129938Z",
     "start_time": "2024-10-16T17:19:53.116217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"DB:\\n{json.dumps(context_df_movie.to_dict(), indent=2)}\\n\")\n",
    "print(f\"Columns:\\n{context_df[top_columns]}\\n\")\n",
    "print(f\"Context:\\n{context}\\n\")"
   ],
   "id": "b77d4565734baccb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB:\n",
      "{}\n",
      "\n",
      "Columns:\n",
      "predicate_label                       instance of place of birth  \\\n",
      "subject_id                                                         \n",
      "http://www.wikidata.org/entity/Q13909       human    Los Angeles   \n",
      "\n",
      "predicate_label                                    country of citizenship  \\\n",
      "subject_id                                                                  \n",
      "http://www.wikidata.org/entity/Q13909  Cambodia, United States of America   \n",
      "\n",
      "predicate_label                       ancestral home  \\\n",
      "subject_id                                             \n",
      "http://www.wikidata.org/entity/Q13909        Germany   \n",
      "\n",
      "predicate_label                                                    movies cast role play  \n",
      "subject_id                                                                                \n",
      "http://www.wikidata.org/entity/Q13909  Changeling, George Wallace, Playing God, Foxfi...  \n",
      "\n",
      "Context:\n",
      "instance of: human place of birth: Los Angeles country of citizenship: Cambodia, United States of America ancestral home: Germany movies cast role play: Changeling, George Wallace, Playing God, Foxfire, Women Make Film, Sky Captain and the World of Tomorrow, Maleficent, Hell's Kitchen, Gone in 60 Seconds, The Fever, Original Sin, Without Evidence, Wanted, By the Sea, Pushing Tin, Alexander, A Mighty Heart, Playing by Heart, Mr. & Mrs. Smith, Gia, Hackers, Life or Something Like It, Girl, Interrupted, The Good Shepherd, The Bone Collector, Salt, Exit Through the Gift Shop, Cyborg 2, Taking Lives, Beyond Borders, Lara Croft: Tomb Raider – The Cradle of Life, Mojave Moon, True Women, Eternals, Maleficent: Mistress of Evil, Beowulf, Lara Croft: Tomb Raider, The Tourist, Love Is All There Is \n",
      "\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T17:19:55.550344Z",
     "start_time": "2024-10-16T17:19:55.539827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"LLM output:\\n{output}\\n\")\n",
    "print(f\"Question:\\n{query}\\n\")\n",
    "print(f\"Answer:\\n{answer_str}\")"
   ],
   "id": "6f29d0fd3cbd3b55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output:\n",
      "{'score': 0.4058759808540344, 'start': 35, 'end': 46, 'answer': 'Los Angeles'}\n",
      "\n",
      "Question:\n",
      "Where was Angela Jolie born?\n",
      "\n",
      "Answer:\n",
      "Los Angeles\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5879f3a06f307334"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
