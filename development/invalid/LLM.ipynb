{
 "cells": [
  {
   "cell_type": "code",
   "id": "b90198b2b30f28f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T20:28:12.545614Z",
     "start_time": "2024-10-14T20:28:11.331320Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinbrundler/Desktop/ATAI/movie-bot/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T20:28:16.556642Z",
     "start_time": "2024-10-14T20:28:13.001305Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3597e711-ba07-44de-896c-aa0dc506cf64",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T20:36:04.999105Z",
     "start_time": "2024-10-14T20:35:46.052905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"When was Angelina Jolie born?\"\n",
    "columns = ['placeofbirth', 'significantevent', 'ancestralhome']\n",
    "prompt = f\"Query: {query}\\n\\nColumns:\\n{', '.join(columns)}\\n\\nWhich columns are relevant to answer the query?\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=30)\n",
    "\n",
    "relevant_columns = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Relevant Columns:\", relevant_columns)"
   ],
   "id": "f30c37adc9b3b18a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Columns: Query: When was Angelina Jolie born?\n",
      "\n",
      "Columns:\n",
      "placeofbirth, significantevent, ancestralhome\n",
      "\n",
      "Which columns are relevant to answer the query?\n",
      "\n",
      "Response:The relevant columns to answer the query about Angelina Jolie's birth date are:\n",
      "\n",
      "- placeofbirth\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "d3a24292-11aa-44aa-a144-2fb994342bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:21:33.216824Z",
     "start_time": "2024-10-14T17:21:33.212839Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "def execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time() \n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_duration = end_time - start_time\n",
    "        print(f\"Execution time for {func.__name__}: {execution_duration:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:21:34.876079Z",
     "start_time": "2024-10-14T17:21:34.871573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_sparql(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a natural language query and converts it to a SPARQL query using GPT-J-6B.\n",
    "    \"\"\"\n",
    "    \n",
    "    schema_ddis = \"<http://ddis.ch/atai/>\"\n",
    "    schema_wd = \"<http://www.wikidata.org/entity/>\"\n",
    "    schema_wdt = \"<http://www.wikidata.org/prop/direct/>\"\n",
    "    schema_schema = \"<http://schema.org/>\"\n",
    "    \n",
    "    # Format the prompt to help guide the LLM\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate SPARQL query\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_length=50,  # Adjust based on expected query length\n",
    "        num_beams=5,     # Beam search to improve output quality\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode and clean up output\n",
    "    generated_sparql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Post-processing: Extract the generated SPARQL part\n",
    "    sparql_start = \"The SPARQL query is:\"\n",
    "    if sparql_start in generated_sparql: generated_sparql = generated_sparql.split(sparql_start)[-1].strip()\n",
    "    \n",
    "    return generated_sparql"
   ],
   "id": "c685afdda5a424da",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "7c0a0262b185117a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:21:36.496357Z",
     "start_time": "2024-10-14T17:21:36.492134Z"
    }
   },
   "source": [
    "@execution_time\n",
    "def generate_answer(query, information):\n",
    "    try:\n",
    "        system_prompt = (\n",
    "            \"You are a knowledgeable assistant specializing in movies and well-known individuals. Your task is to answer \"\n",
    "            \"the following question as accurately and concise as possible, based on the provided context.\"\n",
    "        )\n",
    "                \n",
    "        context_parts = [system_prompt, f\"Question: {query}\\n\\n\", \"Retrieved Information:\\n\\n\"]\n",
    "        \n",
    "        for entity_id, data in information.items():\n",
    "            entity_name = data.get('entity_name', 'Unknown')\n",
    "            context_parts.append(f\"Entity: {entity_name} ({entity_id})\\n\")\n",
    "            for prop, values in data.items():\n",
    "                values = values if isinstance(values, list) else [values]\n",
    "                val_str = ', '.join(values)\n",
    "                context_parts.append(f\" - {prop}: {val_str}\\n\")\n",
    "            context_parts.append(\"\\n\")\n",
    "        \n",
    "        context_parts.append(\"Answer:\")\n",
    "        context_str = ''.join(context_parts)\n",
    "        \n",
    "        inputs = tokenizer(context_str, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens = 70,\n",
    "                num_return_sequences=1,       # Single answer\n",
    "                temperature=1.0,              # Lower temperature for more focused answers\n",
    "                top_p=0.9                     # Nucleus sampling for a more diverse yet concise response\n",
    "            )\n",
    "        \n",
    "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        answer = answer.split(\"Answer:\")[-1].strip()\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return \"I'm sorry, I encountered an error while processing your request.\""
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:22:25.410931Z",
     "start_time": "2024-10-14T17:21:53.243296Z"
    }
   },
   "cell_type": "code",
   "source": "generate_sparql(\"Who directed Inception?\")",
   "id": "b5a421bedccfb1e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Who directed Inception?\\nInception, directed by Christopher Nolan, is a 2010 science fiction heist thriller film that explores the concept of shared dreaming and the manipulation of the subconscious mind. The'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf3fab8e60cfbfd3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
